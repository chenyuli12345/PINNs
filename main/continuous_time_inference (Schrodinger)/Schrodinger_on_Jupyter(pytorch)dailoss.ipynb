{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries, set the gpu and random seed\n",
    "\n",
    "#下面这行代码，是为了把自己编写的代码文件当作一共模块导入，这里是把Utilities文件夹中的plotting.py文件当作python的模块导入，对应的是下面的from plotting import newfig, savefig。路径要随着不同设备的系统做相应的修改\n",
    "import sys #导入sys模块。sys模块提供了一些变量和函数，用于与 Python解释器进行交互和访问。例如，sys.path 是一个 Python 在导入模块时会查找的路径列表，sys.argv 是一个包含命令行参数的列表，sys.exit() 函数可以用于退出 Python 程序。导入 sys 模块后，你就可以在你的程序中使用这些变量和函数了。\n",
    "sys.path.insert(0, '../../Utilities/') #在 Python的sys.path列表中插入一个新的路径。sys.path是一个 Python 在导入模块时会查找的路径列表。新的路径'../../Utilities/'相对于当前脚本的路径。当你尝试导入一个模块时，Python 会在 sys.path 列表中的路径下查找这个模块。通过在列表开始位置插入一个路径，你可以让 Python 优先在这个路径下查找模块。这在你需要导入自定义模块或者不在 Python 标准库中的模块时非常有用。\n",
    "\n",
    "import torch\n",
    "#collections是python一个内置模块，提供了一些有用的数据结构\n",
    "from collections import OrderedDict  #这个类是字典dict的一个子类，用于创建有序的字典。普通字典中元素顺序是无序的，在OrderedDict中元素的顺序是有序的，元素的顺序是按照它们被添加到字典中的顺序决定的。\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#下面的`scipy`是一个用于科学计算和技术计算的Python库，提供了许多高级的数学函数和便利的操作，包括数值积分、插值、优化、图像处理、统计等。\n",
    "import scipy.io #导入了scipy库中的io模块。scipy.io模块包含了一些用于文件输入/输出的函数，例如读取和写入.mat文件（MATLAB格式）。\n",
    "from scipy.interpolate import griddata#`scipy.interpolate`是`scipy`库中的一个模块，提供了许多插值工具，用于在给定的离散数据点之间进行插值和拟合。`griddata`是这个模块中的一个函数，用于在无规则的数据点上进行插值。它使用方法如下：\n",
    "#griddata(points, values, xi, method='linear', fill_value=nan, rescale=False)；\n",
    "   # `points`： ndarray of floats, shape (n, D)。表示数据点的坐标。`values`： ndarray of float or complex, shape (n,)。表示数据点的值。`xi`： ndarray of float, shape (M, D)。表示插值点的坐标。`method`： 插值方法，可选'linear'、'nearest'、'cubic'。默认为'linear'。\n",
    "   #`fill_value`： 在插值范围外的点的值。默认为nan。`rescale`： 是否对坐标点进行重标定，以提高数值稳定性。默认为False。\n",
    "   #返回值：ndarray，shape (M,) or (M, 1)。插值点的值。这个函数可以用于从散列的数据点创建一个连续的函数，这对于处理实际数据非常有用，因为实际数据通常是不规则或者不完整的。\n",
    "from pyDOE import lhs #`pyDOE`是一个Python库，用于设计实验。它提供了一些函数来生成各种设计，如因子设计、拉丁超立方设计等。`lhs`是库中的一个函数，全名为\"Latin Hypercube Sampling\"，拉丁超立方采样。这是一种统计方法，用于生成一个近似均匀分布的多维样本点集。它在参数空间中生成一个非常均匀的样本，这对于高维数值优化问题非常有用，因为它可以更好地覆盖参数空间。\n",
    "#`lhs`函数的基本用法如下：lhs(n, samples=1000):其中，`n`是参数的数量，`samples`是想生成的样本点的数量。这个函数会返回一个形状为(samples, n)的数组，每一行都是一个n维的样本点，所有的样本点都在[0, 1]范围内。\n",
    "from plotting_torch import newfig, savefig #从自定义的plotting.py文件中导入了newfig和savefig函数。这两个函数用于创建和保存图形。这两个函数的定义在plotting.py文件中\n",
    "from mpl_toolkits.mplot3d import Axes3D #`mpl_toolkits.mplot3d`是`matplotlib`库的一个模块，用于创建三维图形。`Axes3D`是`mpl_toolkits.mplot3d`模块中的一个类，用于创建一个三维的坐标轴。可以在这个坐标轴上绘制三维的图形，如曲线、曲面等。\n",
    "import time #一个内置模块，用于处理时间相关的操作。\n",
    "import matplotlib.gridspec as gridspec #是`matplotlib`库的一个模块，用于创建一个网格布局来放置子图。在`matplotlib`中可以创建一个或多个子图（subplot），每个子图都有自己的坐标轴，并可以在其中绘制图形。`gridspec`模块提供了一个灵活的方式来创建和放置子图。\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable #`mpl_toolkits.axes_grid1`是`matplotlib`库的一个模块，提供了一些高级的工具来控制matplotlib图形中的坐标轴和颜色条。`make_axes_locatable`是模块中的一个函数，用于创建一个可分割的坐标轴。可以在这个坐标轴的四个方向（上、下、左、右）添加新的坐标轴或颜色条。\n",
    "\n",
    "\n",
    "np.random.seed(1234) #这里有变化，仅需要设置numpy的随机数生成器的种子。设置随机数生成器的种子可以确保每次运行程序时，NumPy生成的随机数序列都是一样的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA support \n",
    "\n",
    "#设置pytorch的设备，代表了在哪里执行张量积算，设备可以是cpu或者cuda（gpu），并将这个做运算的设备对象存储在变量device中，后续张量计算回在这个设备上执行\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class DNN(torch.nn.Module):\n",
    "    #第一个方法\n",
    "    def __init__(self, layers):\n",
    "        super(DNN, self).__init__() #调用父类的__init__方法进行初始化\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1 #定义名为depth的属性，表示神经网络的深度，等于层数-1\n",
    "        \n",
    "        # set up layer order dict\n",
    "        self.activation = torch.nn.Tanh #设置激活函数为tanh\n",
    "         \n",
    "        layer_list = list() #定义一个空列表layer_list\n",
    "        for i in range(self.depth - 1):  #循环depth次\n",
    "            #将每一层（全连接层）添加到layer_list中\n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            #将每一层的激活函数添加到layer_list中\n",
    "            layer_list.append(('activation_%d' % i, self.activation()))\n",
    "\n",
    "        #循环结束后，将最后一层的线性变换添加到layer_list中（因为没有激活函数了）\n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        #然后使用OrderedDict将layer_list中的元素转换为有序字典\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers，将layerDict转换为一个神经网络模型，赋值给self.layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "    \n",
    "    #第二个方法，定义了模型的前向传播过程\n",
    "    def forward(self, x):  #接收输入x\n",
    "        out = self.layers(x) #将输入x传入神经网络模型self.layers中，得到输出out\n",
    "        return out #返回输出out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the class of PINN\n",
    "\n",
    "#定义了一个名为`PhysicsInformedNN'的类，用于实现基于物理的神经网络。\n",
    "class PhysicsInformedNN:\n",
    "    # Initialize the class\n",
    "    def __init__(self, x0, u0, v0, tb, X_f, layers, lb, ub): #这个类包含的第一个方法__init__，这是一个特殊的方法，也就是这个类的构造函数，用于初始化新创建的对象，接受了几个参数\n",
    "        \n",
    "        \n",
    "        #`numpy.concatenate`是一个用于数组拼接的函数。它可以将多个数组沿指定的轴拼接在一起，形成一个新的数组：numpy.concatenate((a1,a2, ...), axis=0)其中，`a1,a2, ...`是需要拼接的数组（只能接受数组或序列类型的参数，且参数形状必须相同），可以是多个。`axis`参数用于指定拼接的轴向，`axis=0`表示沿着第一个轴（即行）进行拼接，不指定`axis`参数默认值是0。\n",
    "        X0 = np.concatenate((x0,0*x0), 1) # [x0, 0],将x0和0*x0两个数组在第二个维度（即列）上进行了合并。0*x0会生成一个与x0形状相同，但所有元素都为0的数组。因此，X0的结果是一个新的二维数组，其中第一列是x0的值，第二列全为0\n",
    "        X_lb = np.concatenate((0*tb+lb[0],tb), 1) # [lb[0], tb],将0*tb+lb[0]和tb两个数组在第二个维度（即列）上进行了合并。0*tb+lb[0]会生成一个与tb形状相同，但所有元素都为lb[0]的数组。因此，X_lb的结果是一个新的二维数组，其中第一列全为lb[0]的值，第二列是tb的值。\n",
    "        X_ub = np.concatenate((0*tb+ub[0],tb), 1) # [ub[0], tb],同上生成一个与tb形状相同，但所有元素都为ub[0]的数组。因此，X_ub的结果是一个新的二维数组，其中第一列全为ub[0]的值，第二列是tb的值\n",
    "        \n",
    "        #Python使用self关键字来表示类的实例。当在类的方法中定义一个变量时，例如lb和ub，这些变量只在该方法内部可见，也就是说它们的作用域仅限于该方法。当方法执行完毕后，这些变量就会被销毁，无法在其他方法中访问它们。但如果希望在类的其他方法中也能访问这些变量就需要将它们保存为类的实例属性。这就是self.lb和self.ub的作用。\n",
    "            #通过将lb和ub赋值给self.lb和self.ub，就可以在类的其他方法中通过self.lb和self.ub来访问这些值。总的来说，self.lb和self.ub是类的实例属性，它们的作用域是整个类，而不仅仅是定义它们的方法。\n",
    "        self.lb = torch.tensor(lb).float().to(device) #将传入的lb和ub参数的值存储在实例中，以便后续使用。这样可以在类的其他方法中通过self.lb和self.ub来访问这些值。\n",
    "        self.ub = torch.tensor(ub).float().to(device)\n",
    "\n",
    "\n",
    "        self.x0 = torch.tensor(X0[:,0:1], requires_grad=True).float().to(device) #将X0的第一列赋值给self.x0（:表示取所有行,0：1实际上表示取第一列，因为python是左闭右开的）,将X0的第二列赋值给self.t0。这样可以在类的其他方法中通过self.x0和self.t0来访问这些值。\n",
    "        self.t0 = torch.tensor(X0[:,1:2], requires_grad=True).float().to(device) #将x0的第二列赋值给self.t0\n",
    "\n",
    "        self.x_lb = torch.tensor(X_lb[:,0:1], requires_grad=True).float().to(device) #将X_lb的第一列赋值给self.x_lb\n",
    "        self.t_lb = torch.tensor(X_lb[:,1:2], requires_grad=True).float().to(device) #将X_lb的第二列赋值给self.t_lb\n",
    "\n",
    "        self.x_ub = torch.tensor(X_ub[:,0:1], requires_grad=True).float().to(device) #将X_ub的第一列赋值给self.x_ub\n",
    "        self.t_ub = torch.tensor(X_ub[:,0:1], requires_grad=True).float().to(device) #将X_ub的第二列赋值给self.t_ub\n",
    "        \n",
    "        self.x_f = torch.tensor(X_f[:,0:1], requires_grad=True).float().to(device) #将X_f的第一列赋值给self.x_f\n",
    "        self.t_f = torch.tensor(X_f[:,1:2], requires_grad=True).float().to(device) #将X_f的第二列赋值给self.t_f\n",
    "        \n",
    "        self.u0 = torch.tensor(u0).float().to(device) #将传入的u0和v0参数的值存储在实例中，以便后续使用。这样可以在类的其他方法中通过self.u0和self.v0来访问这些值。\n",
    "        self.v0 = torch.tensor(v0).float().to(device)\n",
    "        \n",
    "        # Initialize NNs \n",
    "        self.layers = layers #将传入的layers参数的值存储在实例中，以便后续使用。这样可以在类的其他方法中通过self.layers来访问这些值。\n",
    "        \n",
    "        \n",
    "        # deep neural networks\n",
    "        self.dnn = DNN(layers).to(device) #创建一个DNN类的实例，传入layers参数来实现神经网络的初始化，然后将这个实例移动到指定的设备上\n",
    "\n",
    "\n",
    "\n",
    "        # optimizers: using the same settings，这里是使用pytorch库进行优化的部分\n",
    "        #创建优化器optimizer，使用LBFGS算法，具体每个参数意义见下方\n",
    "        self.optimizer = torch.optim.LBFGS(\n",
    "            self.dnn.parameters(), #要优化的参数，这里返回的是一个生成器，包含了self.dnn中的所有参数（神经网络权重、偏置以及两个新加的变量）\n",
    "            lr=1.0,  #学习率设置为1\n",
    "            max_iter=50000,  #最大迭代次数为50000\n",
    "            max_eval=50000,  #最大评估次数为50000\n",
    "            history_size=50, #历史大小为50，即用于计算Hessian矩阵近似的最近几步的信息\n",
    "            tolerance_grad=1e-5,  #优化的第一个停止条件，当梯度的L2范数小于1e-5时停止优化\n",
    "            tolerance_change=1.0 * np.finfo(float).eps, #优化的第二个停止条件，当优化的目标函数值的变化小于1.0 * np.finfo(float).eps时停止优化\n",
    "            line_search_fn=\"strong_wolfe\"       # 制定了用于一维搜索的方法，这里表示用强Wolfe条件\n",
    "        )\n",
    "        #创建第二个优化器，括号内为要优化的参数，使用Adam优化方法\n",
    "        self.optimizer_Adam = torch.optim.Adam(self.dnn.parameters())\n",
    "                \n",
    "\n",
    "        self.iter = 0 #记录迭代次数 \n",
    "\n",
    "        self.loss_value = [] #创建一个空列表，用于存储损失值\n",
    "\n",
    "    \n",
    "    \n",
    "    #pytorch中\n",
    "    #定义了一个名为net_u的函数/方法，用于计算神经网络的输出。这个方法接受两个参数，分别是x和t，其中x是输入数据，t是时间数据。最后返回神经网络的输出。     \n",
    "    def net_uv(self, x, t):  \n",
    "        uv = self.dnn(torch.cat([x, t], dim=1))  #（第一个参数将输入的两个参数x和t在第二个维度（列）上进行拼接，形成一个新的张量）调用DNN，根据两个参数权重和偏置，以及新得到的张量，计算神经网络的输出u\n",
    "        #将uv（是一个二维张量）的第一列赋值给u，第二列赋值给v\n",
    "        u=uv[:,0:1]\n",
    "        v=uv[:,1:2]\n",
    "\n",
    "        u_x = torch.autograd.grad(\n",
    "            u, x, \n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        v_x = torch.autograd.grad(\n",
    "            v, x, \n",
    "            grad_outputs=torch.ones_like(v),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "\n",
    "        return u,v,u_x,v_x #返回神经网络的输出u和v，以及u关于x的梯度u_x和v关于x的梯度v_x\n",
    "\n",
    "\n",
    "    #定义了一个名为net_f的函数/方法，用于计算论文中的f。这个方法接受两个参数，分别是x和t，其中x是输入数据，t是时间数据。最后返回计算得到的f。\n",
    "    def net_f_uv(self, x, t):\n",
    "        \"\"\" The pytorch autograd version of calculating residual \"\"\"\n",
    "\n",
    "        u,v,u_x,v_x=self.net_uv(x,t) #调用上面的函数/方法，计算神经网络的输出（两个）以及输出关于输入x的梯度（两个）\n",
    "        \n",
    "        #计算u关于t的梯度，也就是u关于t的导数，这里使用了pytorch的自动求导功能\n",
    "        u_t = torch.autograd.grad(\n",
    "            u, t,  #输入的张量，要计算u关于t的导数\n",
    "            grad_outputs=torch.ones_like(u), #生成一个与u形状相同，所有元素均为1的张量，这个参数用于指定向量-雅可比积的像两部分\n",
    "            retain_graph=True, #表示计算完梯度之后保留计算图若需要多次计算梯度，则需要设置改参数为True\n",
    "            create_graph=True #创建梯度的计算图，使我们能够计算高阶导数\n",
    "        )[0] #这个函数的返回值是一个元组，其中包含了每个输入张量的梯度。这里只关心第一个输入张量u的梯度，所以我们使用[0]来获取这个梯度。？？？？又说只有一个梯度\n",
    "        v_t = torch.autograd.grad(\n",
    "            v, t, \n",
    "            grad_outputs=torch.ones_like(v),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        u_xx = torch.autograd.grad(\n",
    "            u_x, x, \n",
    "            grad_outputs=torch.ones_like(u_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        v_xx = torch.autograd.grad(\n",
    "            v_x, x, \n",
    "            grad_outputs=torch.ones_like(v_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        f_u=u_t+0.5*v_xx+(u**2+v**2)*v    #计算f_u,定义见论文\n",
    "        f_v=v_t-0.5*u_xx-(u**2+v**2)*u   #计算f_v,定义见论文\n",
    "        return f_u, f_v  #返回计算得到的f_u和f_v\n",
    "\n",
    "\n",
    "    def loss_func(self):\n",
    "        self.optimizer.zero_grad() #清除之前计算的梯度（在PyTorch中，梯度会累积，所以在每次新的优化迭代之前，我们需要清除之前的梯度）\n",
    "\n",
    "        u0_pred, v0_pred, _ , _ = self.net_uv(self.x0, self.t0) #是调用net_uv函数,将self.x0_tf和self.t0_tf作为参数传入,然后将返回的前两个结果赋值给self.u0_pred和self.v0_pred。后两个_是Python惯用法，表示不关心net_uv函数返回的后两个结果。\n",
    "        u_lb_pred, v_lb_pred, u_x_lb_pred, v_x_lb_pred = self.net_uv(self.x_lb, self.t_lb) #同上，不过这里函数返回的后两个结果会赋值给self.u_x_lb_pred和self.v_x_lb_pred。\n",
    "        u_ub_pred, v_ub_pred, u_x_ub_pred, v_x_ub_pred = self.net_uv(self.x_ub, self.t_ub) #同上\n",
    "        f_u_pred, f_v_pred = self.net_f_uv(self.x_f, self.t_f) #调用net_f_uv函数,将self.x_f_tf和self.t_f_tf作为参数传入,然后将返回的结果赋值给self.f_u_pred和self.f_v_pred。\n",
    "\n",
    "        loss = torch.mean((self.u0 - u0_pred) ** 2)  + \\\n",
    "                    torch.mean((self.v0 - v0_pred) ** 2) + \\\n",
    "                    torch.mean((u_lb_pred - u_ub_pred) ** 2) + \\\n",
    "                    torch.mean((v_lb_pred - v_ub_pred) ** 2) + \\\n",
    "                    torch.mean((u_x_lb_pred - u_x_ub_pred) ** 2) + \\\n",
    "                    torch.mean((v_x_lb_pred - v_x_ub_pred) ** 2) + \\\n",
    "                    torch.mean(f_u_pred ** 2) + \\\n",
    "                    torch.mean(f_v_pred ** 2)\n",
    "        loss.backward() #被调用以计算损失函数关于神经网络参数的梯度。这个梯度将被用于优化器来更新神经网络参数\n",
    "        \n",
    "        self.iter += 1 #每调用一次损失函数，迭代次数加1\n",
    "\n",
    "\n",
    "        self.loss_value.append(loss) #将计算得到的loss值添加到self.loss_value列表中\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        if self.iter % 100 == 0:\n",
    "            print(\n",
    "                'Iter %d, Loss: %e' % \n",
    "                (\n",
    "                    self.iter,\n",
    "                    loss#这里使用了detach()方法，将lambda_2从计算图中分离出来，这样就不会计算lambda_2的梯度，只是将lambda_2的值返回？？？why\n",
    "                ) #每100次迭代，打印一次迭代次数、总的loss、loss_u和loss_f\n",
    "            )\n",
    "        return loss #返回loss\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    #定义了一个名为train的函数/方法，用于训练神经网络。这个方法接受一个参数nIter，表示训练的迭代次数。\n",
    "    def train(self, nIter):\n",
    "        self.dnn.train()#将神经网络设置为训练模式而不是评估模式\n",
    "\n",
    "        #先使用Adam优化器优化nIter次\n",
    "        for epoch in range(nIter):\n",
    "            u0_pred, v0_pred, _ , _ = self.net_uv(self.x0, self.t0) #是调用net_uv函数,将self.x0_tf和self.t0_tf作为参数传入,然后将返回的前两个结果赋值给self.u0_pred和self.v0_pred。后两个_是Python惯用法，表示不关心net_uv函数返回的后两个结果。\n",
    "            u_lb_pred, v_lb_pred, u_x_lb_pred, v_x_lb_pred = self.net_uv(self.x_lb, self.t_lb) #同上，不过这里函数返回的后两个结果会赋值给self.u_x_lb_pred和self.v_x_lb_pred。\n",
    "            u_ub_pred, v_ub_pred, u_x_ub_pred, v_x_ub_pred = self.net_uv(self.x_ub, self.t_ub) #同上\n",
    "            f_u_pred, f_v_pred = self.net_f_uv(self.x_f, self.t_f) #调用net_f_uv函数,将self.x_f_tf和self.t_f_tf作为参数传入,然后将返回的结果赋值给self.f_u_pred和self.f_v_pred。\n",
    "\n",
    "            loss = torch.mean((self.u0 - u0_pred) ** 2)  + \\\n",
    "                    torch.mean((self.v0 - v0_pred) ** 2) + \\\n",
    "                    torch.mean((u_lb_pred - u_ub_pred) ** 2) + \\\n",
    "                    torch.mean((v_lb_pred - v_ub_pred) ** 2) + \\\n",
    "                    torch.mean((u_x_lb_pred - u_x_ub_pred) ** 2) + \\\n",
    "                    torch.mean((v_x_lb_pred - v_x_ub_pred) ** 2) + \\\n",
    "                    torch.mean(f_u_pred ** 2) + \\\n",
    "                    torch.mean(f_v_pred ** 2)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            self.optimizer_Adam.zero_grad() #清除该优化器之前计算的梯度（在PyTorch中，梯度会累积，所以在每次新的优化迭代之前，我们需要清除之前的梯度）\n",
    "            loss.backward() #被调用以计算损失函数关于神经网络参数的梯度。这个梯度将被用于优化器来更新神经网络参数\n",
    "            self.optimizer_Adam.step()  #使用之前的优化器self.optimizer_Adam，调用step方法(执行一步优化算法)，传入损失函数self.loss_func，进行优化\n",
    "\n",
    "\n",
    "\n",
    "            self.loss_value.append(loss) #将计算得到的loss值添加到self.loss_value列表中\n",
    "\n",
    "\n",
    "            \n",
    "            if epoch % 100 == 0:\n",
    "                print(\n",
    "                    'It: %d, Loss: %.3e' % \n",
    "                    (\n",
    "                        epoch, \n",
    "                        loss\n",
    "                    ) #每100次迭代，打印一次迭代次数、总的loss\n",
    "                )\n",
    "\n",
    "\n",
    "        # Backward and optimize，用LBFGS优化器进行进一步优化\n",
    "        self.optimizer.step(self.loss_func)  #使用之前的优化器self.optimizer，调用step方法(执行一步优化算法)，传入计算损失函数的方法self.loss_func，进行优化   \n",
    "\n",
    "                                    \n",
    "    #定义了一个名为predict的函数/方法，用于预测神经网络的输出。这个方法接受一个参数X_star，表示输入数据。最后返回预测的两个输出和两个输出的梯度。\n",
    "    def predict(self, X):\n",
    "        x = torch.tensor(X[:, 0:1], requires_grad=True).float().to(device) #从输入中得到x和t（第一列和第二列），是张量，需要计算梯度，转换为浮点数类型，并将张量移动到指定设备上\n",
    "        t = torch.tensor(X[:, 1:2], requires_grad=True).float().to(device)\n",
    "\n",
    "        self.dnn.eval() #将神经网络切换为评估模式\n",
    "        u, v, _, _ = self.net_uv(x, t) #调用之前定义的函数得到神经网络的输出u,以及f\n",
    "        f_u, f_v = self.net_f_uv(x, t) \n",
    "\n",
    "        u = u.detach().cpu().numpy() #将张量u和v先从计算图中分离出来，然后转换为numpy数组，最后将这个数组移动到cpu上\n",
    "        v = v.detach().cpu().numpy()\n",
    "        f_u = f_u.detach().cpu().numpy()\n",
    "        f_v = f_v.detach().cpu().numpy()\n",
    "        return u, v, f_u, f_v \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0, Loss: 8.143e-01\n",
      "It: 100, Loss: 9.758e-02\n",
      "It: 200, Loss: 6.762e-02\n",
      "It: 300, Loss: 6.009e-02\n",
      "It: 400, Loss: 5.742e-02\n",
      "It: 500, Loss: 5.541e-02\n",
      "It: 600, Loss: 5.317e-02\n",
      "It: 700, Loss: 5.106e-02\n",
      "It: 800, Loss: 4.905e-02\n",
      "It: 900, Loss: 4.615e-02\n",
      "It: 1000, Loss: 4.654e-02\n",
      "It: 1100, Loss: 4.112e-02\n",
      "It: 1200, Loss: 4.142e-02\n",
      "It: 1300, Loss: 4.275e-02\n",
      "It: 1400, Loss: 4.791e-02\n",
      "It: 1500, Loss: 3.513e-02\n",
      "It: 1600, Loss: 3.450e-02\n",
      "It: 1700, Loss: 3.307e-02\n",
      "It: 1800, Loss: 3.199e-02\n",
      "It: 1900, Loss: 3.148e-02\n",
      "It: 2000, Loss: 3.360e-02\n",
      "It: 2100, Loss: 3.688e-02\n",
      "It: 2200, Loss: 4.316e-02\n",
      "It: 2300, Loss: 2.834e-02\n",
      "It: 2400, Loss: 3.982e-02\n",
      "It: 2500, Loss: 7.751e-02\n",
      "It: 2600, Loss: 2.463e-02\n",
      "It: 2700, Loss: 2.375e-02\n",
      "It: 2800, Loss: 2.260e-02\n",
      "It: 2900, Loss: 2.182e-02\n",
      "It: 3000, Loss: 2.887e-02\n",
      "It: 3100, Loss: 2.088e-02\n",
      "It: 3200, Loss: 2.003e-02\n",
      "It: 3300, Loss: 5.527e-02\n",
      "It: 3400, Loss: 1.960e-02\n",
      "It: 3500, Loss: 1.742e-02\n",
      "It: 3600, Loss: 1.776e-02\n",
      "It: 3700, Loss: 1.670e-02\n",
      "It: 3800, Loss: 1.584e-02\n",
      "It: 3900, Loss: 1.579e-02\n",
      "It: 4000, Loss: 2.390e-02\n",
      "It: 4100, Loss: 7.106e-02\n",
      "It: 4200, Loss: 1.392e-02\n",
      "It: 4300, Loss: 1.380e-02\n",
      "It: 4400, Loss: 1.466e-02\n",
      "It: 4500, Loss: 2.145e-02\n",
      "It: 4600, Loss: 1.221e-02\n",
      "It: 4700, Loss: 1.188e-02\n",
      "It: 4800, Loss: 1.155e-02\n",
      "It: 4900, Loss: 1.782e-02\n",
      "It: 5000, Loss: 1.089e-02\n",
      "It: 5100, Loss: 1.045e-02\n",
      "It: 5200, Loss: 1.050e-02\n",
      "It: 5300, Loss: 9.650e-03\n",
      "It: 5400, Loss: 9.948e-03\n",
      "It: 5500, Loss: 9.174e-03\n",
      "It: 5600, Loss: 9.525e-03\n",
      "It: 5700, Loss: 2.188e-02\n",
      "It: 5800, Loss: 5.973e-02\n",
      "It: 5900, Loss: 8.102e-03\n",
      "It: 6000, Loss: 2.839e-02\n",
      "It: 6100, Loss: 7.650e-03\n",
      "It: 6200, Loss: 7.973e-03\n",
      "It: 6300, Loss: 8.313e-03\n",
      "It: 6400, Loss: 7.414e-03\n",
      "It: 6500, Loss: 3.001e-02\n",
      "It: 6600, Loss: 6.619e-03\n",
      "It: 6700, Loss: 6.460e-03\n",
      "It: 6800, Loss: 6.337e-03\n",
      "It: 6900, Loss: 6.540e-03\n",
      "It: 7000, Loss: 1.234e-02\n",
      "It: 7100, Loss: 6.694e-03\n",
      "It: 7200, Loss: 5.626e-03\n",
      "It: 7300, Loss: 5.600e-03\n",
      "It: 7400, Loss: 6.527e-03\n",
      "It: 7500, Loss: 6.013e-03\n",
      "It: 7600, Loss: 1.043e-02\n",
      "It: 7700, Loss: 4.919e-03\n",
      "It: 7800, Loss: 4.813e-03\n",
      "It: 7900, Loss: 4.789e-03\n",
      "It: 8000, Loss: 4.658e-03\n",
      "It: 8100, Loss: 4.794e-03\n",
      "It: 8200, Loss: 4.264e-03\n",
      "It: 8300, Loss: 4.272e-03\n",
      "It: 8400, Loss: 4.059e-03\n",
      "It: 8500, Loss: 4.087e-03\n",
      "It: 8600, Loss: 4.003e-03\n",
      "It: 8700, Loss: 1.380e-02\n",
      "It: 8800, Loss: 3.653e-03\n",
      "It: 8900, Loss: 3.618e-03\n",
      "It: 9000, Loss: 3.852e-03\n",
      "It: 9100, Loss: 5.808e-03\n",
      "It: 9200, Loss: 3.333e-03\n",
      "It: 9300, Loss: 3.329e-03\n",
      "It: 9400, Loss: 1.090e-02\n",
      "It: 9500, Loss: 3.074e-03\n",
      "It: 9600, Loss: 3.045e-03\n",
      "It: 9700, Loss: 3.201e-03\n",
      "It: 9800, Loss: 5.434e-03\n",
      "It: 9900, Loss: 4.890e-03\n",
      "It: 10000, Loss: 2.918e-03\n",
      "It: 10100, Loss: 2.683e-03\n",
      "It: 10200, Loss: 2.684e-03\n",
      "It: 10300, Loss: 3.037e-03\n",
      "It: 10400, Loss: 2.895e-03\n",
      "It: 10500, Loss: 4.675e-03\n",
      "It: 10600, Loss: 2.086e-02\n",
      "It: 10700, Loss: 2.391e-02\n",
      "It: 10800, Loss: 9.221e-03\n",
      "It: 10900, Loss: 7.903e-03\n",
      "It: 11000, Loss: 2.148e-03\n",
      "It: 11100, Loss: 2.259e-03\n",
      "It: 11200, Loss: 3.045e-03\n",
      "It: 11300, Loss: 2.844e-03\n",
      "It: 11400, Loss: 3.813e-02\n",
      "It: 11500, Loss: 1.982e-03\n",
      "It: 11600, Loss: 1.946e-03\n",
      "It: 11700, Loss: 2.208e-03\n",
      "It: 11800, Loss: 2.074e-03\n",
      "It: 11900, Loss: 1.933e-03\n",
      "It: 12000, Loss: 2.882e-03\n",
      "It: 12100, Loss: 3.767e-02\n",
      "It: 12200, Loss: 1.681e-03\n",
      "It: 12300, Loss: 1.686e-03\n",
      "It: 12400, Loss: 1.646e-03\n",
      "It: 12500, Loss: 1.679e-03\n",
      "It: 12600, Loss: 2.144e-03\n",
      "It: 12700, Loss: 7.397e-03\n",
      "It: 12800, Loss: 2.769e-03\n",
      "It: 12900, Loss: 1.496e-03\n",
      "It: 13000, Loss: 1.469e-03\n",
      "It: 13100, Loss: 1.459e-03\n",
      "It: 13200, Loss: 1.784e-03\n",
      "It: 13300, Loss: 1.354e-03\n",
      "It: 13400, Loss: 1.396e-03\n",
      "It: 13500, Loss: 1.352e-03\n",
      "It: 13600, Loss: 1.335e-03\n",
      "It: 13700, Loss: 1.335e-03\n",
      "It: 13800, Loss: 2.544e-03\n",
      "It: 13900, Loss: 1.536e-03\n",
      "It: 14000, Loss: 1.249e-03\n",
      "It: 14100, Loss: 1.937e-03\n",
      "It: 14200, Loss: 1.350e-02\n",
      "It: 14300, Loss: 2.525e-03\n",
      "It: 14400, Loss: 1.290e-03\n",
      "It: 14500, Loss: 1.354e-03\n",
      "It: 14600, Loss: 2.092e-03\n",
      "It: 14700, Loss: 1.886e-03\n",
      "It: 14800, Loss: 1.049e-03\n",
      "It: 14900, Loss: 1.107e-03\n",
      "It: 15000, Loss: 1.078e-03\n",
      "It: 15100, Loss: 1.191e-03\n",
      "It: 15200, Loss: 1.038e-03\n",
      "It: 15300, Loss: 1.123e-03\n",
      "It: 15400, Loss: 1.290e-03\n",
      "It: 15500, Loss: 1.176e-03\n",
      "It: 15600, Loss: 1.528e-02\n",
      "It: 15700, Loss: 1.292e-03\n",
      "It: 15800, Loss: 9.197e-04\n",
      "It: 15900, Loss: 1.553e-03\n",
      "It: 16000, Loss: 1.442e-03\n",
      "It: 16100, Loss: 8.826e-04\n",
      "It: 16200, Loss: 1.085e-03\n",
      "It: 16300, Loss: 5.473e-03\n",
      "It: 16400, Loss: 7.807e-03\n",
      "It: 16500, Loss: 8.272e-04\n",
      "It: 16600, Loss: 1.669e-03\n",
      "It: 16700, Loss: 8.327e-04\n",
      "It: 16800, Loss: 2.808e-03\n",
      "It: 16900, Loss: 1.964e-03\n",
      "It: 17000, Loss: 7.607e-04\n",
      "It: 17100, Loss: 2.180e-02\n",
      "It: 17200, Loss: 7.821e-03\n",
      "It: 17300, Loss: 8.681e-04\n",
      "It: 17400, Loss: 5.152e-03\n",
      "It: 17500, Loss: 7.391e-04\n",
      "It: 17600, Loss: 5.223e-03\n",
      "It: 17700, Loss: 3.110e-03\n",
      "It: 17800, Loss: 1.124e-03\n",
      "It: 17900, Loss: 4.271e-03\n",
      "It: 18000, Loss: 6.465e-04\n",
      "It: 18100, Loss: 6.291e-04\n",
      "It: 18200, Loss: 6.238e-04\n",
      "It: 18300, Loss: 6.401e-04\n",
      "It: 18400, Loss: 7.244e-04\n",
      "It: 18500, Loss: 7.377e-04\n",
      "It: 18600, Loss: 1.506e-03\n",
      "It: 18700, Loss: 5.723e-04\n",
      "It: 18800, Loss: 1.018e-03\n",
      "It: 18900, Loss: 2.577e-03\n",
      "It: 19000, Loss: 1.960e-02\n",
      "It: 19100, Loss: 2.654e-03\n",
      "It: 19200, Loss: 1.192e-03\n",
      "It: 19300, Loss: 9.387e-04\n",
      "It: 19400, Loss: 6.914e-04\n",
      "It: 19500, Loss: 4.405e-03\n",
      "It: 19600, Loss: 1.720e-03\n",
      "It: 19700, Loss: 5.489e-04\n",
      "It: 19800, Loss: 4.807e-04\n",
      "It: 19900, Loss: 4.575e-04\n",
      "It: 20000, Loss: 4.752e-04\n",
      "It: 20100, Loss: 5.343e-04\n",
      "It: 20200, Loss: 4.764e-04\n",
      "It: 20300, Loss: 4.458e-04\n",
      "It: 20400, Loss: 4.825e-04\n",
      "It: 20500, Loss: 5.272e-04\n",
      "It: 20600, Loss: 2.294e-02\n",
      "It: 20700, Loss: 7.618e-03\n",
      "It: 20800, Loss: 4.394e-04\n",
      "It: 20900, Loss: 5.483e-04\n",
      "It: 21000, Loss: 2.047e-03\n",
      "It: 21100, Loss: 7.825e-03\n",
      "It: 21200, Loss: 1.501e-02\n",
      "It: 21300, Loss: 1.074e-02\n",
      "It: 21400, Loss: 4.619e-04\n",
      "It: 21500, Loss: 4.672e-04\n",
      "It: 21600, Loss: 5.201e-04\n",
      "It: 21700, Loss: 4.546e-04\n",
      "It: 21800, Loss: 4.120e-04\n",
      "It: 21900, Loss: 4.752e-04\n",
      "It: 22000, Loss: 5.537e-04\n",
      "It: 22100, Loss: 1.751e-02\n",
      "It: 22200, Loss: 3.710e-04\n",
      "It: 22300, Loss: 3.788e-03\n",
      "It: 22400, Loss: 4.321e-04\n",
      "It: 22500, Loss: 1.501e-03\n",
      "It: 22600, Loss: 4.963e-04\n",
      "It: 22700, Loss: 5.643e-04\n",
      "It: 22800, Loss: 4.757e-04\n",
      "It: 22900, Loss: 4.802e-04\n",
      "It: 23000, Loss: 4.174e-04\n",
      "It: 23100, Loss: 5.297e-04\n",
      "It: 23200, Loss: 3.533e-04\n",
      "It: 23300, Loss: 3.567e-04\n",
      "It: 23400, Loss: 3.382e-04\n",
      "It: 23500, Loss: 4.300e-04\n",
      "It: 23600, Loss: 4.090e-03\n",
      "It: 23700, Loss: 5.230e-04\n",
      "It: 23800, Loss: 7.771e-04\n",
      "It: 23900, Loss: 5.205e-04\n",
      "It: 24000, Loss: 7.465e-04\n",
      "It: 24100, Loss: 1.915e-03\n",
      "It: 24200, Loss: 3.724e-04\n",
      "It: 24300, Loss: 3.124e-04\n",
      "It: 24400, Loss: 3.207e-04\n",
      "It: 24500, Loss: 3.020e-04\n",
      "It: 24600, Loss: 1.882e-02\n",
      "It: 24700, Loss: 1.561e-03\n",
      "It: 24800, Loss: 5.489e-03\n",
      "It: 24900, Loss: 6.355e-03\n",
      "It: 25000, Loss: 1.571e-03\n",
      "It: 25100, Loss: 4.368e-03\n",
      "It: 25200, Loss: 4.848e-04\n",
      "It: 25300, Loss: 2.930e-04\n",
      "It: 25400, Loss: 3.199e-04\n",
      "It: 25500, Loss: 3.333e-04\n",
      "It: 25600, Loss: 3.137e-04\n",
      "It: 25700, Loss: 7.953e-04\n",
      "It: 25800, Loss: 3.005e-04\n",
      "It: 25900, Loss: 4.029e-04\n",
      "It: 26000, Loss: 8.129e-04\n",
      "It: 26100, Loss: 1.028e-03\n",
      "It: 26200, Loss: 7.428e-03\n",
      "It: 26300, Loss: 8.824e-03\n",
      "It: 26400, Loss: 2.438e-03\n",
      "It: 26500, Loss: 2.291e-03\n",
      "It: 26600, Loss: 1.018e-03\n",
      "It: 26700, Loss: 4.740e-04\n",
      "It: 26800, Loss: 4.739e-04\n",
      "It: 26900, Loss: 4.727e-04\n",
      "It: 27000, Loss: 3.470e-04\n",
      "It: 27100, Loss: 6.909e-04\n",
      "It: 27200, Loss: 7.867e-04\n",
      "It: 27300, Loss: 2.665e-03\n",
      "It: 27400, Loss: 2.498e-04\n",
      "It: 27500, Loss: 5.535e-03\n",
      "It: 27600, Loss: 6.110e-03\n",
      "It: 27700, Loss: 7.812e-04\n",
      "It: 27800, Loss: 2.971e-03\n",
      "It: 27900, Loss: 2.047e-02\n",
      "It: 28000, Loss: 2.369e-04\n",
      "It: 28100, Loss: 2.404e-04\n",
      "It: 28200, Loss: 2.506e-04\n",
      "It: 28300, Loss: 2.489e-04\n",
      "It: 28400, Loss: 4.379e-04\n",
      "It: 28500, Loss: 7.326e-04\n",
      "It: 28600, Loss: 2.431e-03\n",
      "It: 28700, Loss: 6.036e-03\n",
      "It: 28800, Loss: 1.386e-03\n",
      "It: 28900, Loss: 2.552e-04\n",
      "It: 29000, Loss: 2.205e-04\n",
      "It: 29100, Loss: 2.355e-04\n",
      "It: 29200, Loss: 2.545e-04\n",
      "It: 29300, Loss: 4.113e-04\n",
      "It: 29400, Loss: 1.209e-03\n",
      "It: 29500, Loss: 4.443e-04\n",
      "It: 29600, Loss: 7.850e-03\n",
      "It: 29700, Loss: 3.815e-04\n",
      "It: 29800, Loss: 1.441e-03\n",
      "It: 29900, Loss: 3.732e-04\n",
      "It: 30000, Loss: 2.570e-04\n",
      "It: 30100, Loss: 2.902e-04\n",
      "It: 30200, Loss: 2.669e-04\n",
      "It: 30300, Loss: 8.576e-04\n",
      "It: 30400, Loss: 8.046e-04\n",
      "It: 30500, Loss: 1.015e-03\n",
      "It: 30600, Loss: 2.054e-04\n",
      "It: 30700, Loss: 2.169e-04\n",
      "It: 30800, Loss: 2.038e-04\n",
      "It: 30900, Loss: 2.116e-04\n",
      "It: 31000, Loss: 3.711e-03\n",
      "It: 31100, Loss: 1.172e-03\n",
      "It: 31200, Loss: 2.468e-04\n",
      "It: 31300, Loss: 4.168e-04\n",
      "It: 31400, Loss: 2.586e-04\n",
      "It: 31500, Loss: 2.512e-04\n",
      "It: 31600, Loss: 8.882e-03\n",
      "It: 31700, Loss: 2.498e-04\n",
      "It: 31800, Loss: 2.151e-04\n",
      "It: 31900, Loss: 1.996e-04\n",
      "It: 32000, Loss: 2.204e-04\n",
      "It: 32100, Loss: 3.208e-03\n",
      "It: 32200, Loss: 5.132e-04\n",
      "It: 32300, Loss: 7.945e-04\n",
      "It: 32400, Loss: 3.284e-04\n",
      "It: 32500, Loss: 5.533e-03\n",
      "It: 32600, Loss: 2.933e-04\n",
      "It: 32700, Loss: 2.105e-04\n",
      "It: 32800, Loss: 2.053e-04\n",
      "It: 32900, Loss: 2.168e-04\n",
      "It: 33000, Loss: 1.786e-04\n",
      "It: 33100, Loss: 1.997e-04\n",
      "It: 33200, Loss: 1.887e-04\n",
      "It: 33300, Loss: 3.668e-03\n",
      "It: 33400, Loss: 9.458e-03\n",
      "It: 33500, Loss: 3.594e-04\n",
      "It: 33600, Loss: 1.746e-04\n",
      "It: 33700, Loss: 1.553e-03\n",
      "It: 33800, Loss: 7.815e-04\n",
      "It: 33900, Loss: 6.690e-03\n",
      "It: 34000, Loss: 4.201e-04\n",
      "It: 34100, Loss: 6.601e-04\n",
      "It: 34200, Loss: 5.233e-04\n",
      "It: 34300, Loss: 2.839e-03\n",
      "It: 34400, Loss: 2.028e-04\n",
      "It: 34500, Loss: 9.243e-04\n",
      "It: 34600, Loss: 4.810e-04\n",
      "It: 34700, Loss: 2.212e-04\n",
      "It: 34800, Loss: 1.685e-04\n",
      "It: 34900, Loss: 2.081e-04\n",
      "It: 35000, Loss: 9.508e-03\n",
      "It: 35100, Loss: 1.104e-03\n",
      "It: 35200, Loss: 2.660e-04\n",
      "It: 35300, Loss: 6.738e-04\n",
      "It: 35400, Loss: 2.087e-04\n",
      "It: 35500, Loss: 1.801e-04\n",
      "It: 35600, Loss: 1.625e-04\n",
      "It: 35700, Loss: 1.819e-04\n",
      "It: 35800, Loss: 1.599e-04\n",
      "It: 35900, Loss: 8.323e-03\n",
      "It: 36000, Loss: 4.031e-04\n",
      "It: 36100, Loss: 1.879e-04\n",
      "It: 36200, Loss: 8.377e-04\n",
      "It: 36300, Loss: 2.658e-04\n",
      "It: 36400, Loss: 5.904e-03\n",
      "It: 36500, Loss: 2.758e-04\n",
      "It: 36600, Loss: 1.690e-03\n",
      "It: 36700, Loss: 6.578e-04\n",
      "It: 36800, Loss: 2.258e-04\n",
      "It: 36900, Loss: 2.026e-04\n",
      "It: 37000, Loss: 8.551e-03\n",
      "It: 37100, Loss: 3.658e-04\n",
      "It: 37200, Loss: 1.688e-04\n",
      "It: 37300, Loss: 1.534e-04\n",
      "It: 37400, Loss: 2.328e-04\n",
      "It: 37500, Loss: 3.381e-03\n",
      "It: 37600, Loss: 2.244e-03\n",
      "It: 37700, Loss: 1.775e-03\n",
      "It: 37800, Loss: 2.011e-04\n",
      "It: 37900, Loss: 1.606e-04\n",
      "It: 38000, Loss: 3.791e-04\n",
      "It: 38100, Loss: 1.132e-03\n",
      "It: 38200, Loss: 3.260e-04\n",
      "It: 38300, Loss: 1.464e-04\n",
      "It: 38400, Loss: 1.429e-04\n",
      "It: 38500, Loss: 1.470e-04\n",
      "It: 38600, Loss: 1.699e-04\n",
      "It: 38700, Loss: 1.756e-04\n",
      "It: 38800, Loss: 3.132e-04\n",
      "It: 38900, Loss: 9.601e-04\n",
      "It: 39000, Loss: 1.408e-04\n",
      "It: 39100, Loss: 1.385e-04\n",
      "It: 39200, Loss: 5.189e-03\n",
      "It: 39300, Loss: 2.570e-03\n",
      "It: 39400, Loss: 1.316e-03\n",
      "It: 39500, Loss: 1.725e-04\n",
      "It: 39600, Loss: 1.607e-04\n",
      "It: 39700, Loss: 1.407e-04\n",
      "It: 39800, Loss: 3.181e-04\n",
      "It: 39900, Loss: 1.473e-04\n",
      "It: 40000, Loss: 3.010e-04\n",
      "It: 40100, Loss: 1.565e-03\n",
      "It: 40200, Loss: 5.536e-04\n",
      "It: 40300, Loss: 7.363e-04\n",
      "It: 40400, Loss: 8.862e-04\n",
      "It: 40500, Loss: 1.878e-04\n",
      "It: 40600, Loss: 1.522e-04\n",
      "It: 40700, Loss: 2.679e-03\n",
      "It: 40800, Loss: 1.901e-04\n",
      "It: 40900, Loss: 1.445e-03\n",
      "It: 41000, Loss: 4.519e-04\n",
      "It: 41100, Loss: 4.804e-04\n",
      "It: 41200, Loss: 3.283e-04\n",
      "It: 41300, Loss: 1.597e-04\n",
      "It: 41400, Loss: 5.485e-04\n",
      "It: 41500, Loss: 3.520e-03\n",
      "It: 41600, Loss: 2.552e-04\n",
      "It: 41700, Loss: 2.021e-03\n",
      "It: 41800, Loss: 7.137e-04\n",
      "It: 41900, Loss: 1.301e-03\n",
      "It: 42000, Loss: 2.128e-04\n",
      "It: 42100, Loss: 3.510e-03\n",
      "It: 42200, Loss: 4.488e-03\n",
      "It: 42300, Loss: 2.080e-04\n",
      "It: 42400, Loss: 5.842e-04\n",
      "It: 42500, Loss: 2.442e-04\n",
      "It: 42600, Loss: 2.339e-04\n",
      "It: 42700, Loss: 1.969e-04\n",
      "It: 42800, Loss: 1.779e-04\n",
      "It: 42900, Loss: 1.147e-04\n",
      "It: 43000, Loss: 1.790e-02\n",
      "It: 43100, Loss: 1.101e-04\n",
      "It: 43200, Loss: 1.451e-04\n",
      "It: 43300, Loss: 2.392e-03\n",
      "It: 43400, Loss: 4.227e-03\n",
      "It: 43500, Loss: 1.276e-04\n",
      "It: 43600, Loss: 2.703e-03\n",
      "It: 43700, Loss: 1.753e-04\n",
      "It: 43800, Loss: 1.137e-04\n",
      "It: 43900, Loss: 1.252e-04\n",
      "It: 44000, Loss: 1.112e-04\n",
      "It: 44100, Loss: 1.219e-04\n",
      "It: 44200, Loss: 1.432e-03\n",
      "It: 44300, Loss: 1.754e-04\n",
      "It: 44400, Loss: 3.406e-04\n",
      "It: 44500, Loss: 3.424e-04\n",
      "It: 44600, Loss: 1.332e-04\n",
      "It: 44700, Loss: 1.173e-04\n",
      "It: 44800, Loss: 9.172e-04\n",
      "It: 44900, Loss: 2.235e-04\n",
      "It: 45000, Loss: 2.100e-04\n",
      "It: 45100, Loss: 1.488e-04\n",
      "It: 45200, Loss: 1.211e-04\n",
      "It: 45300, Loss: 2.268e-04\n",
      "It: 45400, Loss: 2.471e-04\n",
      "It: 45500, Loss: 1.033e-03\n",
      "It: 45600, Loss: 1.709e-04\n",
      "It: 45700, Loss: 8.409e-04\n",
      "It: 45800, Loss: 1.103e-04\n",
      "It: 45900, Loss: 1.035e-04\n",
      "It: 46000, Loss: 1.254e-04\n",
      "It: 46100, Loss: 9.234e-04\n",
      "It: 46200, Loss: 1.274e-03\n",
      "It: 46300, Loss: 6.641e-04\n",
      "It: 46400, Loss: 2.093e-04\n",
      "It: 46500, Loss: 1.506e-04\n",
      "It: 46600, Loss: 2.533e-04\n",
      "It: 46700, Loss: 4.879e-04\n",
      "It: 46800, Loss: 2.074e-04\n",
      "It: 46900, Loss: 9.579e-04\n",
      "It: 47000, Loss: 1.096e-04\n",
      "It: 47100, Loss: 2.262e-03\n",
      "It: 47200, Loss: 1.286e-04\n",
      "It: 47300, Loss: 7.097e-03\n",
      "It: 47400, Loss: 2.972e-04\n",
      "It: 47500, Loss: 5.003e-04\n",
      "It: 47600, Loss: 1.597e-04\n",
      "It: 47700, Loss: 1.158e-04\n",
      "It: 47800, Loss: 6.172e-03\n",
      "It: 47900, Loss: 2.442e-04\n",
      "It: 48000, Loss: 3.272e-04\n",
      "It: 48100, Loss: 6.227e-03\n",
      "It: 48200, Loss: 2.401e-03\n",
      "It: 48300, Loss: 8.591e-04\n",
      "It: 48400, Loss: 2.281e-04\n",
      "It: 48500, Loss: 1.995e-04\n",
      "It: 48600, Loss: 1.798e-04\n",
      "It: 48700, Loss: 2.606e-03\n",
      "It: 48800, Loss: 1.560e-03\n",
      "It: 48900, Loss: 7.474e-03\n",
      "It: 49000, Loss: 8.305e-04\n",
      "It: 49100, Loss: 1.669e-04\n",
      "It: 49200, Loss: 1.009e-04\n",
      "It: 49300, Loss: 1.012e-04\n",
      "It: 49400, Loss: 4.828e-03\n",
      "It: 49500, Loss: 3.041e-04\n",
      "It: 49600, Loss: 1.411e-04\n",
      "It: 49700, Loss: 9.145e-05\n",
      "It: 49800, Loss: 2.694e-03\n",
      "It: 49900, Loss: 2.537e-04\n",
      "Iter 100, Loss: 7.174673e-05\n",
      "Iter 200, Loss: 5.972881e-05\n",
      "Iter 300, Loss: 5.104465e-05\n",
      "Iter 400, Loss: 4.483611e-05\n",
      "Iter 500, Loss: 3.944286e-05\n",
      "Iter 600, Loss: 3.525734e-05\n",
      "Iter 700, Loss: 3.183409e-05\n",
      "Iter 800, Loss: 2.862488e-05\n",
      "Iter 900, Loss: 2.537323e-05\n",
      "Iter 1000, Loss: 2.296959e-05\n",
      "Iter 1100, Loss: 2.093011e-05\n",
      "Iter 1200, Loss: 1.925303e-05\n",
      "Iter 1300, Loss: 1.763940e-05\n",
      "Iter 1400, Loss: 1.638738e-05\n",
      "Iter 1500, Loss: 1.529810e-05\n",
      "Iter 1600, Loss: 1.428879e-05\n",
      "Iter 1700, Loss: 1.348070e-05\n",
      "Iter 1800, Loss: 1.291190e-05\n",
      "Iter 1900, Loss: 1.230737e-05\n",
      "Iter 2000, Loss: 1.162434e-05\n",
      "Iter 2100, Loss: 1.101953e-05\n",
      "Iter 2200, Loss: 1.037722e-05\n",
      "Iter 2300, Loss: 9.753754e-06\n",
      "Iter 2400, Loss: 9.230409e-06\n",
      "Iter 2500, Loss: 8.760617e-06\n",
      "Iter 2600, Loss: 8.284777e-06\n",
      "Iter 2700, Loss: 7.866982e-06\n",
      "Iter 2800, Loss: 7.578248e-06\n",
      "Iter 2900, Loss: 7.285771e-06\n",
      "Iter 3000, Loss: 7.036779e-06\n",
      "Iter 3100, Loss: 6.797660e-06\n",
      "Iter 3200, Loss: 6.573746e-06\n",
      "Iter 3300, Loss: 6.378701e-06\n",
      "Iter 3400, Loss: 6.180142e-06\n",
      "Iter 3500, Loss: 6.002219e-06\n",
      "Iter 3600, Loss: 5.859898e-06\n",
      "Iter 3700, Loss: 5.713102e-06\n",
      "Iter 3800, Loss: 5.589799e-06\n",
      "Iter 3900, Loss: 5.427547e-06\n",
      "Iter 4000, Loss: 5.313995e-06\n",
      "Iter 4100, Loss: 5.197151e-06\n",
      "Iter 4200, Loss: 5.066805e-06\n",
      "Iter 4300, Loss: 4.963173e-06\n",
      "Iter 4400, Loss: 4.860766e-06\n",
      "Iter 4500, Loss: 4.765574e-06\n",
      "Iter 4600, Loss: 4.675273e-06\n",
      "Iter 4700, Loss: 4.572953e-06\n",
      "Iter 4800, Loss: 4.478616e-06\n",
      "Iter 4900, Loss: 4.386776e-06\n",
      "Iter 5000, Loss: 4.306615e-06\n",
      "Iter 5100, Loss: 4.222763e-06\n",
      "Iter 5200, Loss: 4.161252e-06\n",
      "Iter 5300, Loss: 4.111083e-06\n",
      "Iter 5400, Loss: 4.054597e-06\n",
      "Iter 5500, Loss: 4.004170e-06\n",
      "Iter 5600, Loss: 3.954386e-06\n",
      "Iter 5700, Loss: 3.909539e-06\n",
      "Iter 5800, Loss: 3.868638e-06\n",
      "Iter 5900, Loss: 3.830728e-06\n",
      "Iter 6000, Loss: 3.778959e-06\n",
      "Training time: 734.5476\n",
      "Error u: 7.239953e-03\n",
      "Error v: 1.603898e-02\n",
      "Error h: 5.764777e-03\n"
     ]
    }
   ],
   "source": [
    "#设置噪声值为0 \n",
    "noise = 0.0   \n",
    "\n",
    "Adam_iter = 50000 #Adam优化器的迭代次数\n",
    "\n",
    "\n",
    "# Doman bounds，定义两个一维数组lb和ub，问题域是一个二维空间，其中 x 的范围是 -5 到 5，t 的范围是 0 到 π/2(竖着的)\n",
    "lb = np.array([-5.0, 0.0])\n",
    "ub = np.array([5.0, np.pi/2])\n",
    "#定义三个整数，分别表示初始条件点数量、边界条件点数量和在问题域内部的点的数量（这些点用于训练神经网络）\n",
    "N0 = 50\n",
    "N_b = 50\n",
    "N_f = 20000\n",
    "#定义一个列表layers，其中包含了神经网络的层数和每一层的神经元数量\n",
    "layers = [2, 100, 100, 100, 100, 2]\n",
    "#读取名为NLS.mat的Matlab文件，文件中的数据存储在data变量中。这里的路径也要随着设备的情况修改    \n",
    "data = scipy.io.loadmat('../Data/NLS.mat')\n",
    "#从data字典中取出变量tt和x的值，并转换为一维数组（flatten方法），最后tongg[:,None]将一维数组转换为二维数组\n",
    "t = data['tt'].flatten()[:,None]\n",
    "x = data['x'].flatten()[:,None]\n",
    "Exact = data['uu'] #从data字典中取出变量uu的值，并赋值给Exact\n",
    "Exact_u = np.real(Exact)  #取Exact的实部，赋值给Exact_u\n",
    "Exact_v = np.imag(Exact)  #取Exact的虚部，赋值给Exact_v\n",
    "Exact_h = np.sqrt(Exact_u**2 + Exact_v**2) #计算复数uu的|uu|\n",
    "#生成一个二位网络，X和T是输出的二维数组\n",
    "X, T = np.meshgrid(x,t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))  #X_star是一个二维数组，其中第一列是X的展平，第二列是T的展平\n",
    "u_star = Exact_u.T.flatten()[:,None] #先对Exact_u进行转置，然后使用flatten方法将其转换为一维数组，最后使用[:,None]将其转换为二维数组\n",
    "v_star = Exact_v.T.flatten()[:,None] #同上，比如Exact_v是m*n二维数组，Exact_v.T是n*m二维数组，Exact_v.T.flatten()是一个长度为n*m的一维数组，Exact_v.T.flatten()[:,None]是一个(n*m)*1的三维数组\n",
    "h_star = Exact_h.T.flatten()[:,None]\n",
    "#上面五行代码的意义见Numpy库的索引的介绍\n",
    "\n",
    "\n",
    "###########################\n",
    "\n",
    "#从0~数组x的行数(256)中随机选择N0个数，replace=False表示不允许重复选择，最后将这N0个数赋值给idx_x\n",
    "idx_x = np.random.choice(x.shape[0], N0, replace=False)\n",
    "#从x中选择N0个对应的行(idx_x对应的行)，最后将这N0行赋值给x0\n",
    "x0 = x[idx_x,:]\n",
    "#从Exact_u中选择N0个对应的行(idx_x对应的行)的第一列元素，最后将这N0个元素赋值给u0\n",
    "u0 = Exact_u[idx_x,0:1]\n",
    "v0 = Exact_v[idx_x,0:1]\n",
    "#从0~数组t的行数中随机选择N_b个数，replace=False表示不允许重复选择，最后将这N_b个数赋值给idx_t\n",
    "idx_t = np.random.choice(t.shape[0], N_b, replace=False)\n",
    "#从t中选择N_b个对应的行(idx_t对应的行)，最后将这N_b行赋值给tb\n",
    "tb = t[idx_t,:]\n",
    "\n",
    "X_f = lb + (ub-lb)*lhs(2, N_f) #lhs函数采用拉丁超采样方法，生成一个近似均匀分布的多维样本点集，返回的是一个形状为（$N_f$，2）的数组，每一行都是一个2维的样本点，所有样本点都在[0,1]范围内，并对该样本集进行缩放，把每个样本从[0,1]区间缩放到[lb,ub]区域内，即得到了指定范围内均匀分布的样本$X_f$。\n",
    "\n",
    "#创建PINN模型并输入各种参数        \n",
    "model = PhysicsInformedNN(x0, u0, v0, tb, X_f, layers, lb, ub)\n",
    "#获取当前时间并赋值给start_time          \n",
    "start_time = time.time()       \n",
    "#训练模型50000次         \n",
    "model.train(Adam_iter)\n",
    "#获取当前时间并减去start_time，得到训练时间并赋值给elapsed\n",
    "elapsed = time.time() - start_time                \n",
    "#打印训练所需时间\n",
    "print('Training time: %.4f' % (elapsed))\n",
    "\n",
    "#用训练好的模型进行预测，返回四个值（均为数组）    \n",
    "u_pred, v_pred, f_u_pred, f_v_pred = model.predict(X_star)\n",
    "#计算u_pred和v_pred的模（平方和的平方根），赋值给h_pred\n",
    "h_pred = np.sqrt(u_pred**2 + v_pred**2)\n",
    "#计算误差（基于2范数）        \n",
    "error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
    "error_v = np.linalg.norm(v_star-v_pred,2)/np.linalg.norm(v_star,2)\n",
    "error_h = np.linalg.norm(h_star-h_pred,2)/np.linalg.norm(h_star,2)\n",
    "#打印误差\n",
    "print('Error u: %e' % (error_u))\n",
    "print('Error v: %e' % (error_v))\n",
    "print('Error h: %e' % (error_h))\n",
    "\n",
    "#使用griddata函数将X_star、u_pred、v_pred和h_pred插值到网格上，得到U_pred、V_pred和H_pred\n",
    "U_pred = griddata(X_star, u_pred.flatten(), (X, T), method='cubic')\n",
    "V_pred = griddata(X_star, v_pred.flatten(), (X, T), method='cubic')\n",
    "H_pred = griddata(X_star, h_pred.flatten(), (X, T), method='cubic')\n",
    "#同上，使用griddata函数将X_star、f_u_pred和f_v_pred插值到网格上，得到FU_pred和FV_pred\n",
    "FU_pred = griddata(X_star, f_u_pred.flatten(), (X, T), method='cubic')\n",
    "FV_pred = griddata(X_star, f_v_pred.flatten(), (X, T), method='cubic')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 539.643x333.518 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#打印误差随迭代次数的变化\n",
    "trainloss = torch.stack(model.loss_value).cpu().detach().numpy()\n",
    "# print(trainloss)\n",
    "# print(trainloss.shape)\n",
    "indices=list(range(len(trainloss)))\n",
    "plt.figure()\n",
    "plt.plot(indices[:Adam_iter],trainloss[:Adam_iter],color='red')\n",
    "plt.plot(indices[Adam_iter:],trainloss[Adam_iter:],color='blue')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "# plt.yscale('log') #设置y轴为对数尺度，这样即使列表中有一些非常大的值，也不会影响其他值的可视化\n",
    "plt.xlim([0,max(indices)]) # 设置x轴的范围\n",
    "plt.ylim([0,0.2]) # 设置y轴的范围\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lcy\\AppData\\Local\\Temp\\ipykernel_122840\\2393817356.py:17: MatplotlibDeprecationWarning: Auto-removal of overlapping axes is deprecated since 3.6 and will be removed two minor releases later; explicitly call ax.remove() as needed.\n",
      "  ax = plt.subplot(gs0[:,:]) #在gs0[:,:] 指定的位置创建了一个子图，并将返回的axes对象赋值给ax。gs0[:,:]表示GridSpec对象gs0的所有行和所有列，所以这行代码创建的子图占据了整个图形。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '$t = 0.98$')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAegAAAE8CAYAAAAL/yI1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABrFUlEQVR4nO2deXwb5Z3/PyP5ymXLMiEhpy1DgHAlcgyFkpDEcu/Cr+AkdFsKLcHesmW3ZSEmgUACheCUttvdtosNtN1td9vESmC77UKxnHATYltJOBIuy0kckkASWXIuX9Lz+0Oe0dwaXdbI/r79mpc1zzzHd575znzmeeaZZzjGGANBEARBEKbCkmkDCIIgCIJQQgJNEARBECaEBJogCIIgTAgJNEEQBEGYEBJogiAIgjAhJNAEQRAEYUJIoAmCIAjChJBAEwRBEIQJIYEmCJMQCAQyktaM5RAEQQJNEKbB4/HA5/NJwurq6lBeXq6brqmpCX6/P+X2bNy4URGmZiNBEOmBBJogTMyyZcvgdDo1t3u9XtjtdjgcDiHM7Xajqakp6bJra2tRX1+fdD4EQSQGCTRBmJiWlhZUV1drbt+wYQNqamokYZs2bZIIdqLYbDYAoBYzQWQIEmiCMDEejwcLFixQ3RYIBFSF2Ov1aqaJlxUrVsDtdqckL4Ig4oMEmiBMjNfrhc/ng9vtRn19vaQ1u3nzZlRWVkri8l3Smzdvhtfr1c3b5/OhqalJyJcvQzwQzOl0oqWlJbU7RRCEIUigCcKkeL1e2Gw2uFwu1NTUoKSkRNKa7ezslLSgnU4nKisr4XK5UFtbq/vsGoi0zmtra1FdXY1ly5ahpqYGbrdbMeAsHQPQCIKIDQk0QZgUj8eD1atXC8+C29raJKIbCASEbTybNm3CsmXLDOW/fPlyAJEbgRUrVgBQij5BEJmDBJogTEpLSwtcLpew7vF4JOs2m03xXnI8z595cd+0aZMw0IzecyYI80ACTRAmpb29XWgx8+IcCATg8XgAAOXl5ZJn0ry42mw2eDweYZ1/ji2Gf/bMb+NbzZs3b1bYYbfbU71rBEEYICfTBhAEocTn80layw6HA3a7HR6PR2jtulwuNDY2Cuv882q32w2HwyG0kDds2AAAaG5uluTHl9Pc3Cy8N11bWyuxw+v16r7mRRBE+iCBJggT4nA4FILa2NioiCNvGcvjABFhlr8qJRZ/PTZt2oS6ujqjZhMEkUKoi5sgspi6urq0vafMd5HToDGCyAwk0ASRxbhcLvj9ft3BXfLBZUbZsGEDGhoakrCOIIhk4BhjLNNGEASh/trUSKQ1YzkEQZBAEwRBEIQpGRODxJYtW4bVq1cDiAx6SaTbbt26dbBarVi7dq0Q9sgjjyAUCgEArFYrQqGQEIffZrVa0draiqqqKqxdu1bIZ9u2bQCA7du3S+KGQiGsW7cuLjuWLFki5MXHefXVVxEKhcBxHJYuXQoAQhnbtm0DY0ywSb4/auXz5Wrto7gejOZpBK1yW1tbYbVasXDhQqFceZ22trbiwIEDKC0txXXXXQer1QoAwv7z6Xnb5PUoDuPTi/f75Zdf1twW61iuW7cOL7/8MpYuXSrU1yOPPIJt27bhuuuuS7i+jCL2I/43AMHmWMdN73zQ8x8+Pu+j4vqXn0+J+lG8to00Rs6leOw0Urdqvp3o+R6P3ydz3TTL8coobAzgdDqZzWZjLpeL9fT0xIz/0EMPsYcfflgStnTpUgZACH/44YeFdf43H0frvzguv6jF0UNcrnhdHMbnVVZWplqWWnnyfLXKNbJvRvM0gla5/L4tXbpUs07F+y/ed3l6rXoUh2ntd6w6ibVfan6RTH3FW69qZRs5bvEea/l2cV1p2ZOoH6XDD1OJkXMpkfxi1W0qz3ej9usdi1TXw2hkTAh0c3OzoXh9fX0sGAyy+++/nwFgq1evZp2dnWz16tUMAFu0aBEDwHJzcxkAtmbNGhYMBlkwGGRr1qxhAJjFYpH85+Pw2/m0enFjLfK81qxZowjjbeXzFi9aNsUqP9Y+JpJnPPsrL1d+PPTiiBet9Gr1KA5T228jdRJrv9SOzUgsaj4Zz3FL1H/kPqp3PiXqR+nww3TUfaLXgETqNpXnezz265VrNJ9AIMC6u7tZKBSSXLPPnj2bkuNx9uzZdEhP0oyJZ9D19fWorKwUJv2XT8bAs27dOqxfv34kTSMIgiAM0t3djRkzZgAA+vr6MG5CMRDuSzrfqVOnoqurCwUFBUnnlUrGhECLKS8vR0dHh+pI1P7+fvT392PDhg2wWq1oaGjA0NAQcnKsuPfelXj11Xa89loHcnNzMDg4hNWr61BfvxIA0NDwNDZsaITFwiEcZsJ/Pg6/nU8LQDNuLOR5rV4dmUhCHLZwYQVefbVDyFuMlk2xyo+1j1q2GdknI/srL5ffR7065eOI0UqvVo/iMHldqm2L51jy+yUmFfUl5vDhz9DUtBm1tcsxbdq5quWL6y+e45ao/8h9VJ7+8OHP8L3v3Y8dO3Yn7Efp8MNUYuRcSiQ/vboFlL6d6PnO52XEfr1jYbQeentPYdasJQgEAigqKhoO60VRURHGz1gGzpIbd53xsPAgzhxqRjAYRGFhYcL5pIXMNuDTT3NzM1u1apWw7nQ6WUdHh26axYsXK7oe+WX9+rtYOLyPrV9/l7DO/16y5Crd/+K4/KIWJxzep7mIyxWvi8P4vMrKZqiWpVaePF+tco3sm9E8jSxa5fL7tmTJVZp1Kt5/8b7L02vVozhMa79j1Ums/VLzi2TqK956VSvbyHGL91jLt4vrSsueRP0oHX6YjrpPxG+SqdtUnu9G7dc7FvHUQyDQxgCwYDAoXKeDwSADwCaV3soKHXckvEwqvVWRt1kY9aO4xXMSA5H3OGN9J9diUZ+/paxsBh5Y+30wMDyw9vsAIIxGXL/+LoRCISxefCUeWPt9/PiRfxfWW1vfxPr1d+GBtd/H+nW/xPr1d2H79rcAAJ7W30rihkIhMGh3aoRCISEv3g4+Lz5s4cIKIe7s2dOwZMlVwvrixVdi+/a3VPPh46iVz8fX2kdxPRjN0wha5ba2vonS0ulYuLBCiCOv09bWN8EYE+ItXnwlAGD79rcQDoeFcK16FIfx6f/ph9/BD//pMUyZUgI23PnEb1OrE6395uMsWXKVUE+8bcnUl5yTJ0+jo+M9VFRcgkmTJijqVeyTfPhD634w/DusmW8oFMb69Xdh7do7AUD4r5VGHn/hwgWS/+L0/f0DuO22b+CHP7zVUN7J2jbS8PaFQmEsXnwl1q69E4888mthPV47jdStmm9H0sZ/vsfj93rXGUD/uinOR+98sFrywFny4qozMWbuQh4TXdz8VIhtbW2oq6uLOXXh4sWLcfDgQXR1dQlhZWUzMHPmVGx/6T/TaithbrzevahcUIO2djeczrmZNicm2WYvkJ02E+mlt/cUim1XSrqh+S7ukvP/ARZrfsJ5h0P9OPHxr0zZxT3qW9AAhK/98P9jUVVVhQcffFAS1tV1CLfd9o2U20YQBEEkjsWSB0sSLWiYuI06JgQ6XvgJL+Rs374DD6z9+xG2hjAXTPTfvCd2lGyzF8hOm4n0ot/FnYxAcyTQ2cX+/fs1wg+DwRzPsUY7HH3HhRiF0PUjMfTqzWrNgcWa+ChuDqGE06YbEmgVGGMoKChAX1/0/bqCgjyEw3RyjRRmvZDl5Fowffq5yMm1mNZGMdlmL5CdNhOZI/kWtHl9jARaBYvFIhFnAOjrG4DVajH18woi/Vx26QU4cNATWckCX8g2e4HstJlIMzp+kPwzaBLorOI73/kOfvGLX0i+sWuzTcK3b/l6yl5/IQiCIIyhd921WHJgTWKiErChxNOmGXrQp4LVapWIMwAEAicjLWj1+Ut0FmI08c47H6F0VjXeeeejTJtiiGyzFzBu88Pr/x2P/lg6E9ujP27Ew+v/PWkbvN59uHn5Pbiy8mY81eTGU01uPPGT32KLuyXpvGPh8x2SlBMI9OKJn/wWT/zkt5J4Ny+/B17vPni9+7D6vp8L4VvcLdjibsFTTW60enakzK4LL/hqSvLh9ydlWC1AThKL1bwyaF7LMkhra6tiKlCbbRK2tb6VQG7xCjotZl4GBwfxySefYXBwMOO2jEZ747HZarVg3UO/HhZphkd/3Ih1D/06wRtp6eJ0XoRly7+Aioq5uKP2JtxRexPuufc2tLe/i6eammOmNxJHL+1NNS5hvdWzAydOBBTxfF2H8MXqO7Dmvp+j/r7vRcJ83fB43sRNNS7cUXsTfrLxNyk7Ls//7cmU7LfNNglLq67CFveLcdqgQa4FLIkFueaVQeriVmHPnj0IBAKYPXs2Dhw4gFmzz8PBA0fw9tsfImziEX9E+mHDx58hJPEFDlymTIpBWPifjgFX6Xjko1XHclY/cDsYwlj30K/x2KNPYWBgEA+t/3usfuD2lJynDGEwMEle9953Gy4s/zpur9WfE+Gpp9wx46ix1e1BxYKLJWV+o2YpTvgDCARPSsJX1d+GG2tcwnoYIXg8b6LINlGIV2SbiBbPG6hyXRW3LXJKHefFrFej+z3POQdNTc34Rs1SQ2Xrlsu3hBPGvAJtXssyCD8Z+4EDBwAABw8cGQ6fCDBGy5hehp2EQRLOWNikS8RgliYbR7KO1ZY1969EXl4uBgYGkZeXizX3r0ydHXzLTRRmK5qIYnshdnXsi5Rf/wu0tuzAmvpfwNfZDTCG1pYdCARO4ummLWht2RG1VSWufPF4duDGm6rUbZGFtbe9h63uFjzdtAVPN20BGIOvsxt2e6EQp9heiGCgV5KutWUHppQsxtNNW7DV3YI7//7HEnue2Pg7bHW3CAsYw66OfbjogusR6OnFro59mFKyGK0tO7DV3YJvLl+lud+7OvZhq7sFrS07cOff/1ixT1r1oH48NEimeztpcU8v1IJW4bbbbsOrr74qmbBk8ZIF+Py189PSYiCyB/HcwNngC9lmLxCfzY/9+GlBnAcGBvHoj5/CmgdS89Wq6H2C0gbeNntJEZa6rgQDwxM/+Q/86t/XYKnrSthsk3D7Hd+QpFeLK6fH36tZntyWRx+/S/h98Zz/h5uWuRTxAeCEPyhZX+q6EmWO6bhpmQs22yRcMf9CfOVL/4B9Hz6Hp5/aCgD4xk1VAIB/+P5jKC2bjvnOi1BWNh0MDPOcF8JZcTGK7YVY6roSPt8n2LLFgxtvqlLsd/PmF1FWPh1Lqq5Esb1QYsd850XYtet9lDmmq1W/6v6rbrNawJIQWcZIoLOKl19+GS+99JIk7KXt7QiHw0L3GzE2Kb9gGv7m+RXKL5iWFb6QbfYCxm3e8OPf4OF1TXhwXS1WP/C94fXI8+jVD3wvaTsijwSYwoYefy/mOS8AQwgMYTz91BYEAifh9wdFcZXptONGCQR6NfaZDXe5R7Zt3bINHW178ejjkQ+b2GwT4fMdRFn5NAQCJ4V4fn8QZWXnqeTJUGQbD4YQyhznocffi55AALu8+4ZvIiLxyxzT0Nq6A/OcFwj7FNkWTc+GH5/w4eKy7rnvFjyw+lf46U/+E/PmX4j/3vSYsK3YPkmyT3roPp5JthVMAp1daH3NirNwkW49YswyceI4LLxuPgBkhS9km72AcZuHQkNYu+4O3Hf/bWAsHPkPhqHQUGr2dfgRgTivnz3xB9xTfwsYC+OZp56D/0QAd9/zLezyfoCO9r3wduzDfOeFYAzo6Qlie2sbvnHTUt24imJVbI+ERW0pLT0PRUUThPVA4CTmzZ+DoqIJeGDNr4XwLt8nWFK1QJEnb5/NNgmBwEkU2yehqGgC5s2fgy7fISG+r/MQbqxZKqwLjzYA2IonCnZBeOwh3W/35hb8269XAQB+8P0G+Dq7hRaz/0QAzoqLDR0r3TgjKNButxsOhwPt7e0AgNra2sTLNQAJtApaM4YxakGPeQ5/cgxP/noL/v7OmzBt+uRMmxOTbLMXMG7z/Q9+FwAk5+R9939HEZYIXb7DcDd70OU7jK1bPOjxn0QgeBK2okn43h3XgyGE+RVzsMv7PlqFtzsYurq6Mc95Pm6/43o88/SzmDf/wphxxZSWnQefrxtljmlC2LbWdmxr3YlA4BRKy6biGzctwTzn+Xh2y3Zs3eJBR/v7+N/nfw6GEEodU3HTsiWCzffUf0uzRb6l2YNi+yRJ+u/d8XX87In/EtLPd87BkionvN696Or6BFuaPZhfcSG6uj7BM08/i++tvB6tnp2w2SZicZVTsd8+3yFs3RKZdKas/DyUOqYK9vh8h3DjssUGW9B6g8S4JAXa2ADPQCCADRs2oKOjAw6HA8XFxWkX6DHxucl4WbduneIZ9HWL5+Oaay/HmgdvSzhfml86+9m960Nce9UdeO2tpzBv/pxMmxOTbLMXyE6bU8XuXR/C2/E+vrfy+rSWw9dvOjD6tsAtN6/D7/+0zlDc3t7TmH7O11Q/N1la8zQsueMTNRfhwTPY714Z1+cmvV4v6uvr0dKS3vfiqQWtgtVqVXzR6uWXduHa665I6lUVmlc4NuZ9XSmC+BWgbOhNyTZ7gey0GdAfyGSUy+c74N7sQRjpnt2KwR8IwGabmOZy1Nne2oG76282fE3UjWdNsos7HEnb29srCc7Pz0d+vvI7001NTWhpaUFzc3PiZRqEBFqFZ555BgCwZs0aPPbYY/jn+27GTx//E/7zd/+He9d8M8PWZYaREk6zd+eEWUj4H44xRaAZekzkr1mZFfEFOJ46Ho38aNUK/OapP+O7K6Mzd6VyBP7uXR+hq+sIfvvUn/FP9yxPWb5GCQROIRDoxXVLrzB8fPXisTwLWF4So7iHz9OZM2dKwh966CGsW7dOEb+2thYOhwP19fVobGxUbE8lJNAqlJWVCe9AAwA/mfrs2VPAxuAFAwAYl3mxSRXJ3GzwQsIMTPxhhh4TviUWxtAItMpSQzx1bCw/s9/2SSm0jcOtK78UnZwjxTdWV8wrw/6jmyJZZ+B6VlRUgOu/cXVcZTOm05OSa40sicIiabu7uyVd3Gqt50AgAJvNBpfLhWXLlmHZsmVwuVyKeKmCBFqF7du345FHHsGDDz4IAPhpw2bc9+Df4Z7VKxAaIYfmOJN19eqdICqYq6taaksyl+vi4gn49m1fQHHxBFO37vj6Ly6eiFtu+wKKiyeqXuTMKF7pq2Pz7KsZ612PTA9V0vWDZKfrHB7FXVhYqPsMuqmpCZ2dnWhoaAAA2O122O32xMs1AA0S0yEvLw+Dg4PIzbWiO7g15fmbScK0GKn7hJEoxiz1bbqbrzRhlkvLSFgxUntqkipVJZ2mnew9gwumflN1kNisf/gjLPlJDBLrP4ODv/pmzEFigUAAHo8HNpsNLS0tKCkpwapVqxIu1wjUglaBH8UdmawfGBwM4cYvP4CrrrkEd9+fuWfQI3lZFzQkBWddqu22pCjDRLI5e7YfB7o+xeyyKRg3TtkFJuStl/kIXmWN2jvS6FVBsjanqnbDKcoolUd7JAXaTPcCg3q9/Mm+Bx0yltZms6GmpgYA0tqtLYYEWoXHH38c/f39WLRoEV555RVUXjMXb7z8Dtrf3Icf3Pd3aSs3nQ2rVGTNcYmdsomcOnp1EdIxI9H9NFr37+87hC9dezdeeO1nuGx+uXa5Kby6JXND8sG+Q/jC5+/Gi6//DJeL7I2HVAmVHuIitOpYN32CNia6a4mUl+iTZGbwPV3dPJLOwUAZaSxkIKRdByzXCpbEM2gWTuL5dZohgVZh3Lhx6O/vxyuvvAIAaHtjLwAgf1w+BkZo3E+qtDpe0dePrr41loDEY4KRlnt8+Rm7algMXlz4m4Mw4heuRI+pkXK0jjOfNsz0b2zSeXGNN2v+FAsxIGTwfDN6WhoRu3jsNVJvRvNL5EYo3iSpPs4j1crWb0FzyT2D1hH/TEMCrUJPTw8cDge6urqEsOmzp+CvHU+jPwWvZaaqpRxvNkbEyoibK+wXZWvEJr04enWjl07zJoHpD1fjy9M6/+Vpw8MX+FCYw1CYi6tXId5LSDx+onXhDYv+J9sSTvTiHs89LWMcQuHIjocZh5BIUI0Ur2ejXnq9utFLl2h5ye4LTypvTBRp4k6hVXbyefSH9VrQw991ThBmsIs7E5BAq7B48WJFGGPAbV9fjV8/+3jayjXc2jOUl2qozlrs9Frx1cRRLa6W4KjHVdaFfL8l+TGdvBJMByj3TWhBs+GL+vCFz0h9ye/tYh1vo616PfiLY6wv9sVDLFGIJQZqZoht48UypNLq1xLSWHlqxjGQTm1/1fZRq3rV6l0tbjz7Fm/eRtIp7DGQjzTP9LVEzw7p5J1njSyJQl3c2cXBgwclrWcAOHzwU4QYEBhI3gm1u4S187bqFGvRudDrdT+rbdNyVXHcuMWTD9OJI99mEW3kf/ECJ+4GV+Yptc0i2RZNJy9Ty7aQShm5eTkAF8lGyFJWJRwXvVDG4zF6N1+J9LxYLBzy8nJgsXAJ99zI901sY1ytY508JXG44TqGVLT00jON3/K4cnvlomK0DLmYGk2nFSfWTYCWeKt16On1Buhvi+0geo9J4ikrXs7oXHeTfgYdIoHOKo4cOaIa7v/Uj8BA6rpDrEa6nA1cVC0qV141K7VEXizwWuWJw62y8vTSS9Jp5CkWVTWh1xJPcbiQl+wiExan54V5uDw18ZbHFQdyAOZeUY73PtN+5U7NNkM3DdKiVLepxdGCr4/58x04GNii2G7k4ilEkRUoFhfF0w4GYHh/FaIjPjacMi+eiy+X1jEfRRyX6WwLC2FK8dUST7UbAbW4esLKlyevW7GIyreJ1+UCGWLq8YymV8tHiKuenW5ZsbZFy0t9S1pPoK1WwJKEknHm1WcSaDX416vkDA0Nwd9vzPn0WrxR5EKnH1tTPFXLV2nlaoovpxnHakh8o5NayvfbwjHNdFZxel40OWVZVlk6IwIrrDNROqG0yC8myou/Klvk6UXbIMtHjLJ8pp4XoNpzILdRLZ08TSROai+G4neXFS1RIY4yjL9wi6/NFmnVCpNzhMURdYRaXh7TsEHIExGRVEvH26i1TU/ghS53cXlM/j+64yHZNnEaXRGW5S0vKxKf09ymFaYWR01EtUQ7lijH01KOpwUu5qyuQHOwGLvgqsIlkTbdkECrMHPmTOzfv18RXjT13JS0oOPxB93ua9X4/C9pIeIy1YRaXo5Vlo9FJb1FEp8p4kXWOU3RF4uxRcNescBHhZ3T3iazkeOYkJdCvBG9OeHjR7U4ehMg2M+Azg+6cW/tT/HEU/+MORdF5+4VC7M8nVxoraLwqEBzw3HEtxHDYcItvjyO6NZIJtR8nPf3HcDKWx/F0/9xPy66eLawXTGTFT9nNxdWiTO8bXgmMsZFpZIJ26Liy2SCJm/tggFh4caIk24D8PEH3bjnjp/iJ03/jPILZ0rS8xd4JksnFkw9EQ5piK44vTAQUCHC2gIbhlK01cRUSzzFceVCqZZO+WxeRXAlwq7YrIijVX6scuQkKsLq5UX+9/VrX3ctOYA1GSUzsQqa2LTModUqYbAYFuhEZVwpyEpb4n2urGWPtGtaPaG0a1vdRovITmXrWCzEbHibsudALvpREedUBFpl23C6XItc/DmVsOG4XFRQ5SIuFm6x/afODmDv2z6cPjOAwbDKjYHQzI4qhbwlzSO+QeCF1sLlCOu8MPPbxOuW4RI5jq99q6SQyHYO4YHPsGf3xwgPjEOBtWS4ZCaa55kX2mHxHZ73OYxQdE5sQZij6/w2YQrG4W0cU05iqWjJInqhFw8I49fPDNfxqbMDGGTSuHIR5PMUC/egirACwGCY02z5itPIRTOstw2QxFHfJ04RR62VrRRmZatcXobauqpYK0LU8zG+LbFWZ6JvqfYPal9Rc6yRbu5EoS7uLCMcDqOgoAB9fX1CmDUvD0OhEHp1HCUWqXp6rdeqjsYxkE8c6XSfM+vYFqvlzadR69oGIsJpkXVpi28CBLHVEGGLzrZcC5OINQDkyOLmWpgwSVEux+HMYGTD6SHg5CAH+Q2JuIwcxY2FdD2HY6Ku/dBw+SHBbosgvrxA5wxvsyLMb2NSoRZGlcMCDhxC4YgPh8J9GAqfiUQBE32Egm8B8x+oiAp1WPg9NLyNF+WwkHpo+IdYxIZ0xNdInFPDT5jODHI4OWARxHMoHBFZcbqhsFJg5XEkAg2lLeLyh8Kc0l4hjVIw9VrXeuIdXddvOavF04qjlU+s+NpxR1aE9RgY0r56WnM4WHMSsxVA9EQ1ISTQKpSXl0u/ZgUgNDCAidNm4HQSAp0NGBF/ZRqdbQbic3GKv0T0ZekUz7LVwkTb5IJsFYknH86/YmnhGLqDEUH8KJiDQX8ucofjCSJuia7LW/VqcXKFcqV2cJxY0IdbpxgQ4iqeayOaDqKwT8/2AMP/u08fA6A+4ljcjcyHhzS6kUPMIqSTtygHWVS0eaGUr4dVwvj1EOPgC0YuS+8HrTh9Iifayg2LhFmjG3pIR4TDTG2bsnWrFUe8DbI4gHJQmhnFM1sZ1GtBW5JsQZv4kk4CrcLrr7+uGv7Zu+/glN77eCkgnhMvrhM6BeWmsrx0kXCvgEZcSeseQM/xAgDAW8cK8PHhAkWvgPhmQJ4np3LzINwgyOLKy5XnLd83rUcYhw/lAQCeP5SHPZMitut1gaq19sIq3blyYYu2qJUiKB9sJX1eq8z7xLGInW3HC/DxkXGq5cptlO+H2n7GK5jpJB5NMPYmh/7Jmery4ik7UcR2DOrM9pWTy8Gam/h1mUsibboxhUD39vbC7/ejtLQ0Lfm73W4AgN/vh8PhiDnR+dCQ+qfNWCiEviRmnTEicPE8K1Id+coMxJEVIm0FqKeXjNyVRWJh7XRqeavFZWGmuU3xzikTp9PaxlTji5HYFta2TZLmzFSU3LYO+wJTYXlHJ6IqaheCFF0cNMYQhM/MQslt6/DX7lmwnMjTTp+xzyQNlyuyn6/jD4NTYdkrtUv+yprQkyA6LZU9NIoihHEminEBFpUwUc+L1jZOVKi8PHEa+cBBeRrxvojHwmiWK4QrB2OqtQz1ytUL0x/bou/Dycwlz4u/nkBbrZHn0AkTR1q32w2/34+Ojo60fwsaMIlAP/bYY9iyZQs++ugjBINBNDc3Y+XKlSnJ2+fzoaWlBY2NjQCA6urqmJWqNYq74JxzMZTgoAog9jUwluDqCasirpoIqghrdJt63mozUcnFVCyicjEUi7cw0lf23FIch98mBAyJCh6emFkYaBwS9XnK+jq5UDgaLoRJ80GYCen4+Mo4oryG88kLnQ/sCgKhgGAbp/5QUpoXX8d8WQzi0U3S/2FxRcnqRJyXzCmY3EkAFMAGvN2pCAdEz66FAF4doLxSC015Uf+9XCmsXPRVK6soL/G6dORdxG7x0HYrh3ycD+zpBdAriiMql8/LKto2vB4SnldYpHlbOGV8tQECfDp5WRwXfV4pE3iLhQlVJxdhiyUal7NIt6mJv/ymg1PZpnYTonazEtmmnKRGerMi3aYm9IpJgjTyUg3Xue7FFG/GPwLREegkR3Ezg2m9Xi8AoLa2FoFAAGVlZejp6Um8YAOYQqArKyvx+OORKTSLioqwcuVKPP300ykRaf77nTw2mw0ej0dVpPv7+9Hf349Zs2apC/TUaUmJcDwCrXKd1W1JapXBi2KsVq5CWFXEWN4qVmvJRoU2mk7QrJAsnVjMFAIrEjeZCEvEd0hDWMVxhzS2DYVF5Q5vU+THJCOhhvqDOPXJDkyaehVyrJNE2/j0fH0PIRQeGE4WGo4yNPx/QFgXtrEhSRzGhhAerjBhcJawLSwaYS39L78aslAfQmf2wzq+FJy1AEp48bBI/8Mi/LZYoiPLI+vW6IC14W386HMLZ42GWfJkcSJNFaslDxw/s8Sw4HGWYVXJsWAodBInj76FidM/h5z8IuEqzuVYRALLCfEl6a0cWI5UvDleYHM4QZiFd1/lIi4qQ34TIBFv3o5h20KiEYucSJABwGJlQnI10QaAsKjlLsThzwWJ+A4/ElBppUcn65FuY2CKVjmTxREjv/RYxAEpel4r7LfBjhu9RxFWKwdrEu8y88eyt7dXEp6fn4/8/OjnTv1+P1paWlBTUwObzQa73Q6v1wun05lw2bEwhUA7nU5UVlZixYoVqKmpQWlpqaK1lyidnZ0oKSkR1u12OwKBgGrcDRs2YP369arbciZORPFlV8S+49PYHmbad5o8kl22KMO0HvWIxVwp4vyFRKMcRERcu4uXE/KNp4taL120LP5iwVRb1ULe8psF8cNMvda1YMBwGC++4jsNrRsDjTgDx3pw4pVm5M+rBFdsV9618OLPmHCBFebUFreO5TsnbyWLKpmTX53UWtJyhsvuD+7Hodeew9RLb0B+UWl0u5Yji4NlDiv2IaWaiMLVwkR5MwuHsKjFLbGH4zDgD+DE683Im38luMnF6sP2eaGRpxfFYXwZvGBz4niyVjInCpcNCBALrryVKjZHLrpqrWXFu/Ei4dXrxtZKJ8S1SLvEteLqtZaVLW8oiKcFrVZGPBi9F8i1JNfFze/3zJkzJeEPPfQQ1q1bJ6y7XC5Jw87v96dVnAGTCHRTUxMef/xxeL1e1NTUoKurC83NzWkrz+/3q4avXr0ad999N77+9a8Ln5rkGTp1Cr3v7UGB6AsGyQ4wSXZgllr5WvH1u885zda9vviLf3M622StOsVzY070W7ot1rN3TbvV0hm4XY91X5iz3w+4gfFXFGN86bma8TiVq1I83YyA9rNUrfhKG4DTviEceg2wXT8DExyRbyur9c7I0avjeI9JvMfCuj8AbAUmXGbDuNJzdO00Vg+xj4VaeKyu31jx1bqaNeOOsIgm++aFaroUDRZTK5/T+XJMroUJb0YkAp93d3c3CgsLhXBx61lOXV0dnnrqqYTLNIopBNrhcKCqqgpVVVW49957sWvXLsXHKhKlvLxc0mLmB4qpwXdpyF+x4jlz5BMUWFPjhBGUeaVqVGk8I66N5Zd4F5IWRk9oI5OvqI2+1twmiqMcKR35z6mOxmY4FhrCxwCcM4cw9fwhxWtafNwcizJvtXeso69iScu3cEwZNhzXqvPeuHRiGQZf7lmsBvCtC8/CcekpALJZqzTEN9JxMNwLItsWed2JU4TxcbXeVRbnoxbGxz06XMfzZw5h8vlDkpHeeiPD+XXl+8hMsa96I7xT9SqUsqz4EqdjdHQyA7ZU80ttdppYda67eSkS6MLCQolAa+F2u1FdXY2ampqEyzSKKQTa5XLh6aefxvLly1FYWIjNmzejvLw8ZXnX19cL6z6fL+YgMV7Q16xZg8ceewyXfftbeOcP/4WhU6cwMTdTL2Zok+xJYuSkVf2ClVqrTzV/JlvXTiN/n1kSJstPMtZIZRv/Xz4DmlgUtSY64ccCWTkmeX/Zd3wQzQAqSgYx57z+hN5xVuuxVYujnPyECen4KpT3FPPwq/ajkefWlZOHcNl50Tnm+doVBI8PF61rzYQlGneneA9a5alB3O9Kf3h8EJsBOEsG4ZjaL4nD5zEky1t8UyBMOiKzX81u9VfI1LeppROH670jrZZGnrdWOjF6n3RM9qbcfFe2KAM6191cK0NuMg2nONLyY5pcLhe8Xi9sNptmgy8VmEKgy8rKJAPCHA5Hynba4XBgxYoVwvD41atXG0772muvAQCOvxt5n4bjgEkjJNCpem9R7S7cqLDK0+u11uTp9d7ZVf2ghkaciAgzRZiwDXx8mcBaouFK0eXjME2BFsTVIp3LO29qARZ98UpcOLUApZNCcQlsjk6caFx+sFZOdFCWMK1n9L9l+NSVT/UpDOwanupz5mQrvva16zDznAthz58xXFvRqT7VZhADgDCGIEzxyQ9kQ3TQGj+7WFiIH9m3obC2MIeG1T+WwHPDdXzR1ALMmBSSTOcZUpk5DJAKNN86Vwq1SOBlYx5CKq105QsCnEoYROmkjq06naeWwEMZR21dL51Weum25AQ+1Vc/ozcVuTnaJaeqBR0Ln8+HZcuWCeuBQCBlY6W04Fi6S8hCHnnkETz44IOK8EV1t+Lald9OWTmGnusYysegCMvC1AY+qs+zLU2vFFhlevW5uKV5qn0pS9nKVHbnRtMrbwTEs37x4XLR1fughXJO7mh8tW1qYXK7tcZDWRB9Lqk33zZU4ggf0uCFGZwsrr5zCTNmC3Nx8/9Dwrog0PxlWfgghnKebgjdyGFFt7X6uDtpq1wswmphkfSczrZo3tHxdkoxlwtkdIrPaLj4AxhiG9Xslv+P5KlslSvjSO0Qb9ebd1vZSo+mj+uDGKphOuKtuUU/z1TRf+o0frrk/yEYDArd0L29vSgqKsItL/wFeRMmJJz3wOnT+P2XvibJ2yyYogVtNkKhEJYuXYpt27YJYeVXzkMeF0JRnrF7yES6nWMJtvb3nNXClGeLnrBqhYn3Q/uLVcrfuuKrYpfu5yZlXbySFqisDPmnKDmV7mB+3copw9TSi38PDg7hVPA0JhVNQG5ejvJzkaL9ZrIfisHYgPDVLG5YGLlhweM4DmFh2LNMdEUjhZRCLF0fHBxCMHAKRbaJyM1VO92ZbE20LrSumSRuRLyZKETaRc7/VryOJ7ZSqGep4Fk5YGhwCCeDpzGxaAJyc3OE+g9zTDHo3SqbjjQyRal0X3JF5UfTD9uv+LoV0+wGj+TLZNuicUKyvHl0RVzUPlKLJ44r3u9oGmV6OdLvSitP+mg69Qz0vk4Vrygn2gLv07nu5lkY8pJoQSOZtGmGBFoFq9UqEWcA6Ny5G5d+7jLY85M/mPGIt9p3nYV8DAisXrixbz2LwhTp+bjG8tH8GhanTCcWXvnzbz3x5ZG0gHXiqAmyOD0nS/fhewdw4+If4dmXfo7L5kfHSUSvccMXc0TF1yKLI76oycsT9lH0SUeFBKscG617uz1vd8J1zd3wvPEzXDFfe1yHmpcpRmOLfitG9KukkYfJW7Za5X743gF8Y/GPsPWln+OSeeXRt7YY5J+Rln5jGgCD8nUl8Q2C8pm7/AZFaS9EYh4VcilhxhR1Im+lA0oxVOvyVrSgRbWkJYhq4q++Xf3mIVaYXt5apLI7/OygtlG5SQo0I4HOLn7zm9+ohr+x9W/49g+/mVCe8Y6e1BNxvXfydb8fbUC8tVvpBkVYJ38toY1sk6bhVLYpRUwZXz8fqWDq5a2WH6cST3HdE0cQiXVkk8r+yw4XX16IaYuu3C49+K7boTAwEMcVU3fCnRjxlK9tS41VS69WHF/fTBYmiaMh2GI7mCgV7zNMdrzUbj7kNkmmj1VsU9tv6bpERCHfpqwBvWfPQj464q+Wj7IMbUdSbzlLb4jiJdFu8Lxc7YR5HJCXxEhZM393hARahSNHjqiGBz7rgS0vMQ9L9JUJY+8fam/Te39f/b1OdTtV30000JIzEkdNaPXyUBNdIa84y49lr1bVagm7eIYmuWYrvnakVtfDQRaoi5Y8XiyhDov+G7k4GhmRondxVhtlbKR1HhVYnWOg4idCffPrar7EMUlcANCaOZIxTrhJVRNh4bdKWmWvgjKWXq+EVhxA2W0ejavXWlYivzFQs8DQYLEkG53xvraZq3PdTfY96DC1oLOLq6++Gi+99JIi/LLKi1CYhlHcRltDQvwU5a2Xj57ox9uy0xY55Ylh9EZAK18jAq8XV/WmRWU737qLJ+94CMPYoxCj08eqzbeeiE2x4DimEA21XgdNvxT1HPCD8PTMVrNJK7443KoSBgDg1GR1OK6B3oJIPPWdMyrGevGFcjVay7HSGSk3kfziLyO+XC0xXrPKS+I1q3BK57ZILSTQKixdulRVoK9edDnGpbDGtFqr8RJv7048NwRGosaKE6u8WOkTvVkwWr7xfBisw3fbVkv0t5hEe9rivUmLN1/xNJWJotcbI7kYG/BrzcstB0Ud6737q9XajWmjfJuB9LFajdod4LHLN2pDQnETvMyk44VSvWOpR0jH+fItDPn0DHrsoDaK+3OLLgMXDiE/g3dbqbqGJzKbULxJUn0TEMkz/ro3KphG7b308lLsPfxHjJ+QL5kwJFHSJcw8l15eivePROxN9SxSYuI9MlrHhUFZx0YE35AIcYmJDi8qsb7HkMiVIV7xTPTqk+pXoJKQw4RSDepcd/OtkSVRWDKfqkwzJNAqqI3i3vHKO7h64WVJDUZIllS1uNVIdreSFZpMC53R5NYcK/KKxseMl04xjAej9iZNgvurJhwJ2WywJR3rWqwqmAbPu2TPzlTNSDESUykl2hJOlFydC1SBlWHcCM0kNtKQQKvwzDPPAIhO9XnXqmX4t43NaP59C+5ZsyLD1iXOSJxS6RCmdNmdiKj7Pj6M+37UiMd/XgfH+dPiKy/+4pKmU2RveZz2pgvx5VDNX5KpY9Xy4rn+GjxI6bikp3OiD57UFTGyoqb3jDnfypLq2aRn0FmOeLYovTu5bCHTjbtMlS//HF8inDnVh5c8u3HmVB+saeifjjUDWLycHbb37Kk+WOWfQhohtIddqZPyOlbJIlMTKOqVmsQnjVNSvpnRu+7mWZIT6BA9g84ubr/9djz44IN47LHHAAD/0hD59OW3b/sCcjJ0kTMnmZZ6Y6RS9CzC/NiiqThNjDA9KCzC75G3IT5GpI61XrMyrYSZ1a6RQe/mMs+S3HvQQya+pJNAq9Da2oqysjLJJy9nl07FK9vfxqr7UzcXt5lJdUvOvMT7jptV+M9xWXD6ZJu9wAjbLBW+bPZ6895cJA8/R70akUFiSbSgDd4DBgIBNDU1AQBWrVqVcHnxkCVn7Mhy4MAB7N+/Xxq2/ygYY1nRako3mWqJmQH++Ftgjd8X0j1kWwXL8IXNwllhyRKBVthM3/MRYDpDwLL55iIWeudaXpLPoIcMpvV4PDhx4gRKSkoSLitesuOMNQkcuKy5yI09RubyNGPmVPz0F/+IGTOn6t7Vm4UZM4btnTE1a26sFDabSnkye7OQLccw1ehdd/MtkSVRjHZx19TUwO/3IxAIJF5YnJDaxAPHCZ/3G9NkoCVoFs49twR1d9Zk2gzDZJu9QHbanBKop0ATvetuXpIzifHvWPf29krC8/PzkZ+fn3C+qYAEWoXZs2fj6NGj6OvrE8IKCvIwc9YUcKYaJDZ2hTJT+P29+Nvzb+KLX74adru5vh2rRrbZC2SnzSlB93Qe2+Ktd93NsST3dk3OcNqZM2dKwh966CGsW7cu8YxTAAm0Cnv27JGIMwD09Q3gnbc/HlUt6LEzECx1dO//DCtvewRvvPU7nGMvzrQ5Mck2e4HstFmN0Txoa6TRu+7mcAw5SUzixKft7u5GYWH0hjDTrWeABFqVs2fPqob3nR0QBrAQYxP+XWqO40zWm6JOttkLZKfNaozE7e9YuQnQbUFz0VZwIuQMH6jCwkKJQJsBEmgVzjvvPMUobgCYet45SH5STCJRzNDi5+/kOVhHrDcluYuwRfQ/W3w3G23ODJk/I0YGvcFxVi65SV6MpvV4PGhpaUEgEIDD4UBNTfrHSZBAqzB79mwEAgHJaD2bbRJmzZqa1Xf0RArgRP9HaLBcMjcmWdMaFQ2Q4veXG/4jCD0/yOGireBEMJrW5XLB5XIlXlACkECrYLVaFUPpA4GTsFqtdMEY40yYMB5Xfe4yTJgwPit8IWvsFd3sTJg4bPPE8Wm7qRgrXcOjBp2bYYvGp1+NYqGpPrOLcFh9MgDG2Jh9D5GIcNGFDrz2+u8zbYZhss1eIHmb9Sbz4DH1zQqhwAwt6ExAAq3Crl27AAAWiwXhcBgWC4dwmGH3rvcxdp76ENmBee/+MwXdRI8+9I5pjiXJQWImdhcTm5Z5+JZ0WPgOHEd/JvjLJF7vPuRar4DXuy+jdkThdBev933kWufB630/ZlyzLNloMy0jsahj5VjSi1mhFrQKFRUV2LZtmyLc6bw4A9YQcjIp0pzof6ZvFoyQbfYC2WkzkV70/CBVE5WYERJoFRYuXAgAEpFesuRKXLuwAmN5mksC0ePPcdnhC9lmL5CdNhPpRW+QGJeT1DcSzPx9BRPfO2QO9endOKxb9wPw39XNxoUgCGK0Ebm+WZNYzHttNO+tQwapqqpSdHFv3/4WXFXfg6f1NxmyKnnM7IjZAl+H2XLTk232AtlpM5Fe9PyAWtBjjM7OTgDAmjVrAACrV9cBAHy+bphlYASRGebOLccHH/4f5s4tz7Qphsg2e4HstJnIHLxAJ7OYFY4x+saZnMWLF8NqteLZZ59FUVERegI7ceM37kIoFML2l/4z0+YRBEGMKXp7T6HYdiWCwaAwX3Zvby+Kiopw5MTfUFg4IYm8T+O8ki9K8jYL1IJWYffu3di2bRsaGhoAABsbnsH27W9hz54PYJbXfYjM0NV1CLfcsgpdXYcybYohss1eIDttJjKHhbMmvZgVEmgV7HY7AOCxxx4DAGzY0DgcXiSJl+n3gelv5P8CPb347//6CwI9vRm3ZTTam60201/6/7SIiGwyXdzmFWjzdr6nkGXLlmH16tUAgE2bNgktYy18Ph8cDge6urqEMJttEm677RuSeI888muEQpHJTKxWC0KhMKxWC9auvVPYZrVa0Nq6A1VVn8PatXdi3bpfwmq1YPv2twAA27b9hyRuKBTGunU/0LSNT7927Z1C2NKltwp58XFefbUdoVBkFrQlS64CAKGM7dvfQjjMBJvk+6NWPl+u1j6K68FonkbQKre1dQesVgsWLlwglCuv09bWHTh48DBKS6dj0aJKWK2R+1F+//n0vG3yehSH8em/+tXrAACNjZvx0Uf7JdvU6kRrv9et+yVeeaUNS5ZcJdTXI4/8Gtu3v4VFiyoTri+jiP2I/w1AsDnWcVPzQyP+w8fnfVRc/3z6I0eOKdLH40fx2jbSGDmX4rHTSN2q+Xai5/srr7QBMOb3escC0L9uGq0HC3JhQa7h+lJLb1rYGMDpdDKbzcZcLhfr6ekxlObhhx9miMyjyACwJUuuYgDY+vV3sXB4H1u//i5hnf/Nx9H6L44rz1eev9YiLle8Lg7j8yorm6FaVqz90SvXyL4ZzdPIolUuv29LllylWafi/Rfvuzy9Vj2Kw/j0CxZcKvkfq05i7ZeaXyRTX/Klvd3NALD2dremH2nZYsT+eP1H7qPy+l+//i5WV7eCAWB1dSsS8qN0+GEqFyPnUiL5xarbVJ7vRu3XOxbx1EMg0MYAsGAwKFyjg8EgA8B6AjtYKPxuwktPYIcib7MwJgS6ubnZULy+vj4WDAbZ/fffL7mY88uiRQsYAJabm8MAsDVr6lgw2MGCwQ62Zk0dA8AsFk7yn4/Db+fT6sWNtcjzWrOmThHG28rnLV60bIpVfqx9TCTPePZXXq78eOjFES9a6dXqURwmr0u1bfEcSz6t2rFJ1fLyy39gANjLL/8hph/Fe9wS9R+5j8rT8zYn40fp8MNULsn4TaJ1m8rzPR779co1mk9398sMAAsEAsL1mhfog90vsUCwPeHlYPdLphXoMTGKu76+HpWVlfD7/QCA2tpa1Xjr1q3D+vXrR9I0giAIwiDd3d2YMWMGAKCvrw9lZWU4evRo0vlOnToVXV1dKCgoSDqvlJLpO4SRxuFwaHZz8y3omTNnstmzZ7MDBw5E7tAOHmSzZ89mhYWFw3eCucN3eWtYMBhkwWCQrVmzZvgO0CL5z8fht/Np9eLGWuR5rVmzRhF2zTXXSPIWL1o2xSo/1j4mkmcwGGTd3d0MAOvu7o6r3EWLFsWsUz6OeNFKr1aP4jB53vfcc09Sx5LPV+3YpGsR17WaT8Zz3BL1Hz6+Wv1rxdXzj1TYls56TvRcimcxUrex6kRus56N8divV67RfAKBAOvu7mahUEhyzT579mxKjtfZs2dHQH3iJ+sFuqGhga1atUqxNDQ0MMYi3durVq0S4judTtbR0WEo72AwKHR98M+kH374YcYYk6zzv5cuXar7XxyXX9Ti6KFlBx/G2wyAlZWVqZalVp48X61yjeyb0TzV6tloufy+LV26VLNOxfsv3nd5erV6lIdp7bf4YhjPsZSXp1Z+OuDrmn+Mo1a2keMW77GWbxfXlXy7PC5v6/33329oHxP1w1SSiE8bvQZo5RerbmPVidr1Ts/vjdifzHVzJI+XWcn6UdyrVq3S3e5wOGCz2YT1QCAAp9MZdzmhUAgPP/ww1q5dCwDC/1AoBAB4+OGHEQqFsHjxYqxduxaPPPKIsN7a2iqkXbduHR5++GFhKtHW1lZJXD6/eOzg81q7di16e3sBAIsWLQLHcZg9ezaWLl0qpF28eDG2bdsWc3+0ytXaR3E9GM3TCFrltra2oqysDAsXLhTiyOu0tbUVjDGUlpZi4cKFWLx4MYDIR1AYY0J6tXqUh/Hpxfs9ODiIV199Fddccw1cLpdmnWjt1+LFi7F06VKhPN62ZOrLKOLjz/skH87PRR/L/kT8h4/H17u4/sXpxXFXrVqFRx991HC9xGvbSGP0XIo3P726VfNtPm28NvKf4VU7J+T2J3PdNMvxyiRj4hm02+0GALS1taGurg4Oh8NQOn6mmqAJZ5jRgmweObLRbrJ5ZCCbiVSQ9S1oI9TU1Ej+GyU/Px8PPfQQ8vPz02FWWiCbR45stJtsHhnIZiIVjIkWNEEQBEFkGzTVJ0EQBEGYEBJogiAIgjAhJNAEQRAEYULGxCCxWPCjvP1+PxwOB1wuV0JxRhqjdvv9fnR0dGDZsmUZtzueenS73bDZbFlj88aNG4U3BOIdkJhq4vFpnkzaHAgE0NTUBED71UkznoNG7TbTOWjEZh6znINjlky+hG0GOjs7WW1trbDucrkSijPSGLGpo6NDmIe8p6eH2Wy2EbNPjXjqsaenhzmdTsPzqKcLozaLP8TidDpHwjRNjNjc09MjTObDGJPEzwT8hEJim8SY8RxkLLbdZjsHGYttM49ZzsGxzJjv4vZ4PJKJTGw2GzweT9xxRhojNvn9frS0tAjb7XY7vF7vSJopIZ563Lx5M1asWDFClmljxGav1yvE8Xq96OjoGEELlRix2WazobGxUfAHcfxMUFNTg/Lycs3tZjwHgdh2m+0cBGLbzGOWc3AsM+YFurOzEyUlJcK63W5HIBCIO85IY8Qml8uFxsZGYd3v9yc0i1qqMFqPXq/XNF1qRmxub2+Hz+eDz+cDANTV1Y2kiQqM1nNDQwMqKipQUVEhfC/drJjxHDSC2c5Bo5jpHBzLjHmBVoP/6lWycUYaPZvq6urw1FNPjaA1xlCz2efzGZ7tLRPIbQ4EArDb7XA6nXA6nWhvb894K0mOWj23tbWho6MDdrsdVVVVGbAqOcx4Duph1nNQDbOfg2OFMS/Q8q4efgBKvHFGmnhscrvdqK6uzvjAJSM2b9y4EUDE5ra2NrS0tGRU7IzY7HA4JGF2u11oTWcCIzbzPuF0OtHS0oIFCxaYostYCzOeg/FglnPQCGY7B8cyY16gXS4X2trahHWfzyd07fBdaHpxMoURu4Hos7uamhp4vd6MCocRm1etWoWamhrU1NTA4XAIIpIpjPqHuF4z7R9GbPb7/bDb7UKc6upqybpZMPM5qIdZz0E9zHoOjmVoqk9IX9+w2+3CXW55eTk6Ojpgs9k042SSWHb7/X5UVFQI8QOBADJ9uI3UNRC5qNXX18PhcKChoSGjrSWj/uH3+xEIBOBwODLuH0Zs3rhxo1DfmfZpj8eDxsZGBAIB1NXVZc05GMtuM56DRuqaj2eWc3CsQgJNEARBECZkzHdxEwRBEIQZIYEmCIIgCBNCAk0QBEEQJoQEmiAIgiBMCAk0QRAEQZgQEmiCIAiCMCEk0ARBEARhQkigCWKU43a7he//EgSRPZBAE8QoZ9OmTTQLFEFkISTQBDHK8Xq9WLBgQabNIAgiTkigCWKU4vV6UV9fDwDYvHkzfZGIILKMnEwbQBBEenA6nfD5fAgEAqitrc20OQRBxAm1oAliFLNp0yYsW7Ys02YQBJEAJNAEMYqh588Ekb2QQBPEKCUQCAAAbDYbPB6PsE4QRHZAAk0QoxSbzQaXywW32w273Q6bzZZpkwiCiAOOMcYybQRBEARBEFKoBU0QBEEQJoQEmiAIgiBMCAk0QRAEQZgQEmiCIAiCMCEk0ARBEARhQkigCYIgCMKEkEATBEEQhAkhgSYIgiAIE0ICTRAEQRAmhASaIAiCIEwICTRBEARBmBASaIIgCIIwISTQBEEQBGFCSKAJgiAIwoSQQBMEQRCECSGBJgiCIAgTQgJNEARBECaEBJogCIIgTAgJNEEQBEGYkJxMG0BE8fl8cLvdcDgc8Pl8qK2thc1mU43r9XoBAE6nEz6fD4FAAE6nU8insbER5eXl6OzsxOrVqzXzIQg58fih2+2Gy+UCAEUc8kMiGeLxQz1f8/l88Hg8sNvt8Pl8qKmpgcPhGLkdSQZGxE1zczNrbGxMeb5Op1P43dnZyWpqajTj1tbWMgAMAHO5XKynp0fY5nA4hPWOjg5WW1ubcluJzGMGP+R9ULw0NDQwxsgPxwpm8EM9X+P9kSeb/JC6uBNg06ZNKb8D8/l8knWHwwGPx6MZv6KiAj09Pejp6UFLS4twt8in4dedTieamppSaithDjLth4FAAM3NzWCMCUtDQwNWrVpFfjiGyLQfxvK1TZs2pdS2kYQEOgG8Xi8WLFiQ0jz5Lhgxdrtd6MpWw2azKbp8AoGAaly9fIjsxAx+WFNTI/x2u93COvnh2CHTfhjL1+x2OyoqKoSu7urq6pTamk5IoOPA6/Wivr4eALB58+aUXmy0nMzv92vGd7vdcLvdqK+vF+44+WfSYpv18iGyD7P4ofjmMBAIwO/3Cy0p8sPRj1n8MJavNTc3AwDKy8vR3Nwsuak0OzRILA7EA7Jqa2tV4wQCAWzYsEE3n5KSEqxatcpQmVqOKh4w4XA4UF1djc7OTjgcDjQ0NKCpqQnLly8XHFd+N0pkL2byQ576+no0NDQI6+SHox+z+GEsX/N4PGhoaIDP50NdXR0AoLGx0VB5GSfDz8CzjpqaGtbS0pLyfBsbGyWDIhhjzGazaZbV0dEh/O7p6WEAWGdnpxDW2dnJOjo6hG3iQWRE9mMWP2Qs4n8Oh0N1G/nh6MZMfqjma52dnWzVqlWSODabTXKtNDPUgo6TWM9bEr1jdLlcqnd1amV5vV5UVVWhp6dHEs7fMfp8PqGr0ev1wul00ustowwz+CFPe3u7qn+RH45+zOKHWr7m8XhQWVkpxHM4HFi9enXMHiHTkOk7hGxC3FJoaWlJeWtA/lqBy+US1js6OoS7vp6eHslrDc3NzZJXEGw2m2BbbW1tWu5wicxhFj/kaWhokMThIT8c3ZjJD7V8Td6CZowp1s0Mxxhjmb5JyCbq6upQXV0Nh8MhTAySKviX7SsrK9HW1iZ52X7ZsmWorKwU7jS9Xi88Hg9sNhs6Ozslz/+amppgt9uFQTv8RBLE6MEsfggAGzduRGdnp6LFQ344+jGLH+r5msfjgdfrFdK6XK6smaiEBJogCIIgTAi9ZkUQBEEQJoQEmiAIgiBMCAk0QRAEQZgQEmiCIAiCMCEZE+hly5bB6/VKposjiJGG/JAwA+SHhBoZm6jE5/OhqqoKCxYsEOZKJYiRhvyQMAPkh4QaGXvNSvzlm3gIh8M4fPgwJk2aBI7j0mAZkUoYYzh58iSmTZsGi8V8T1TID8cG5IeEGYjXDzPWgm5rawMQ/eKI1mTr/f396O/vF9Y/+eQTzJ07N/0GEimlu7sbM2bMyLQZCsgPxxbkh4QZMOqHppiopLy8HB0dHarz9K5btw7r169XhHd3d6OwsHAErCOSobe3FzNnzkQgEEBRUVGmzdGF/HD0Qn5ImIF4/TAjAu12u9HW1iZMT1lRUYGnnnpKdao4+R0jv4PBYJAcMgvo7e1FUVGRKY8X+eHYgfyQMAPx+mFGurgdDofiY+9a87jm5+cjPz9/hCwjxhLkh4QZID8ktMjIaAmn04lAIAC32436+nq0tLRkwgxijEN+SJgB8kNCC1M8g44HM3dVEUpG6/Earfs1Whmtx2u07tdoJd7jZb73DQiCIAiCIIEmCIIgCDNieJDY/v374868tLQ07jQEoQf5IWEGyA+JkcCQQAeDQXR0dMSVMcdxsNvt9FyESBnkh+nn5Ce9yJuYh/yigkybYlrID4mRwpBAFxUV4aabbkq3LQShC/lhetn54F9w+SM1OJozHfk7XsHUiumZNsmUkB8SIwU9gyYIAizMMO2xf0AB+jF7yIcPb3000yYRxJgn7olK9u/fj+bmZrS0tKCnp0cIt9vtqK6uRk1NDT1rIdIO+WFqOdD6MUpDB4X1mR96MmhN9kB+SKSTuAT6vvvuA8dxWL58Oe69917F9l27duHJJ58Ex3HYsGFDyowkCDHkh6nnk2d3olS0Xjb4EQI+P2wOe6ZMMj3kh0TaYQbZuHEjCwQChuIGAgF23333Gc06LoLBIAPAgsFgWvInUkuqjxf5YXrYXvUIY4Bkee93OzNtVsogPyTMQLzHi2YSI9LKaD1eo22/nlnyB0x/6Q/4Ev4mhL3xg//GNf/2zQxalTpG2/HiGa37NVoZsZnEent7E3oXkFBn4GQ/hs4OZtqMrIP8MDVszvs2vowXUAUPnsMNeAL/jH2hOZk2K2sgP0wtJ4+cAgtnVdsxLSQs0I899hiqq6sBRN4LfPrpp1Nm1Fijfd1fcLZwCgITpuHtX76SaXOyCvLD1HDgQOT/NlThG3gO9+IJvN5XkVmjsgjyw9Sx3fUoCqYVo3PcJTj8VnemzckoCQt0ZWUlPvroIwCR9wJXrlxJTpkAfX3AX5/YhzA4nMOOo/Du2xEaCGXarKyB/DB5GAMODg/gnjEjGv7xx5mxJxshP0wN7+0ZQnfrBwCA8wf2Yf/yVRm2KLMkLNBOpxOVlZV44oknhK6dLHucbQqefx5Yd/pe/Ax3AwBKBz/Ge0+9kWGrsgfyw+Q5fhw4ezby+5JLgHPPjfz2+TJnU7ZBfpgafv/HHHwXv8Vf8DUAwIKDW3Dy8MkMW5U5EhbopqYmPP7442CMoaamBiUlJSgvL0+lbWOCF16I/D+A2UKY/79fyJA12Qf5YfIc/1sHjqMEXszHd079GrNnAwDD4CefYbCPenOMQH6YGl54AQjDisOYBgDIwyD2/Wpbhq3KHAkLtMPhQFVVFe699160t7fD4/EgEAik0LSxQVtb5L8HLiGscN+ODFmTfZAfJk/w7QMogR/zsRvTxvVg/Ykf4AzG41NMwaftY/sZoFHID5PnzBngnXciv8XXwzPbxu71MGGBdrlcePrpp9Hb2wsA2Lx5M/x+f8oMGwsM9IXx7juRbrDiudNwxBKZ+7i8px3hoXAmTcsayA+Tp+/D6AxiuefPxviiXIxDHwDAv4cE2gjkh8nz7jsM4eHL3rhFVwrhhR+0ZciizJOwQJeVlWHlypXCu1wOhwMOhyNlho0FDvzXazgydA5asRS1JW4cmFIJAChCL/a/+GGGrcsOyA+Thzt4QPg9ce4ssJkzhfVTew+qJSFkkB8mT3jjE+hCKZ7DDfjaVcdw1HIegLHdYIl7Lm4t7rjjjlRlNWY4sX0PLoAfS7EdQ5NXoK+gEjjyHADg8J/b4PjKRZk1MAshP4yfvE+jIlzinI3T+z8T1gd81IJOBPLD+LG8vRulOIBSHID3ovU4cG4lph79M4oQRJfnI5R96cJMmzji0NesMgjbtUf4Xbz4CkxaskBYH2rblQmTiDFIUSDSgg7BgqnOaSicG21Bc4dIoImRwf7J2wCAQeTg/K9fjDMXR6+HR1/YnSGrMgsJdAaxHYwIdBgcHDdchllfv0LYNn7/3kyZRYwxJp+NtKCPWqcjZ1wuzpkfFehxx6iLm0g/oTP9mH32fQBAZ97FKJycj/HXzBO2n/Z+kCHLMkvKBLqrqwsrVqzA1q1bsXXrVmGwBKFOeGAIpafeBQDszzkfJbMmYPKlU7DS1oyLsA9fZX8FvUYZP+SH8XH62BlMZscAACcmzAIATL50CgaHn34VBakFnQjkh/Fx4Pm9yMUQAODTqZGGyrQV1+JLeB5TcQQ/n/RgJs3LGCkT6EAgAMYYbrzxRtx4441oaxu7I++McGj7R8JI2SOToy3nQ1fV4ANchOM9Vhw6lCnrshfyw/j4tC3aQj5ZHHkX35pnxdGcyJRik/tJoBOB/DA+PmuJPu4bnBu5Hs64tBhv2b6ETzEVu3dnyLAMkzKBnj9/PjZv3iysV1VVpSrrUcmRF6IO2XdhVKDnzYvG2bMHRJyQH8aHf3dUoAeniSbLGR/p5rYzP84cOz3idmU75IfxMdgevdgVXhu5HnJc9Hp4+DBw7FgGDMswCQv0btktDXXhxEf/W9FBYOJnLWKBHqt3jfFAfpgcewucuAHP4S78K3qu/boQfqo4+hyaJiuJDflhchR2Rq+Hs66fJ/y+Itp2GZMNlrgE+umnn8a2bdvQ29uL9vZ2yba2tjaFkxLaTPwo6pAzvj5f+H3F3EHciC14GGtRuqkhE6aZHvLD1PGh/xz8GTfgl7gLBUuuFsK9S+5GFTyYgw/QCZqyUg3yw9TAwgylwd0AgMOW6Zhy6WRh21WOY/gensEv8I84+7tNGbIwc8T1HnRxcTGefPJJeL1ecByHjo4OLFu2DAsWLEBVVRW2bt2KeeImIKEOY5jtjwj0MW4yZlw5Tdg05yILfo9bMB5nsf+D8wHUZ8hI80J+mDoOROcowaxZ0d/Wygps+13k98EjI2pS1kB+mBqOvtmF81gQAHDQPh/TuOi2+ed+gm9iJQDg9df9AFZkwMLMEVcL+qabbsLmzZvx8ccf46abboLL5cKTTz4Jp9OJCy64AC0tLemyc1Tx2WfANeHXcDP+iP+Y8xg4S9QjrXlW+CZcBgCYNdg5pr/kogX5Yeo4KHqLanb0ETREk4mhm3q4VSE/TA0dn85AJXaiFo344Lpaybayr1wsvFFw7pGx18ed8ExiK1aswPz583HTTTcBiHykvKioKGWGjWZ2tnH4EBfiQ1yIGV9TbvfPvAJ4fycsYNj/v+/gsrprRt7ILIH8MDku3Pss+nEe/LZyTJwY7VoUt6YP0qvQMSE/TJydu/PQjkq0oxKu5dJt+YX5+KBgLi7sextl/fvQF+hDga0gM4ZmAEMt6GAwKHzjlGf+/PmSdbkz9vb20kAJDd56K/r7qquU29kV84Tf/m27025PtkB+mFoGTg3g34/XYAeuxnMDX5Fsmzk9jCp48F38BnPe+n2GLDQn5IepJdb18Ni0yEixHITQ9Zf3Rsgqc2BIoIuKitDS0oKtW7caynTLli3YvHmzMHE8ISWWQ5ZUVwi/c3a+MQIWZQfkh6nl8I6DsCLyEYJAifTDDsV2Ds/h/+E3uB3LPno0E+aZFvLD1BEOAzt3Rn5PmSLtueEJXRG9Hn723Ni6Hhru4r7jjjuwa9cuLF++HOXl5aisrITD4YDNZkMgEIDP58POnTvR1dWFuro6oauHkBLqH8LXX74Pk3A1Ppi8EDNnnquIM2fFfJxZOQ7jcRazu1/NgJXmhfwwdRzf6UPp8O+B6VKB5iwcPs2biYkD72PqwEGwMJOMlRjrkB+mBl9LJ/4p8Hu8gkUoqfgcOG68Is65Ny0Eno38znvrVQB3jayRGSSuZ9D8y/fBYBCbN2/Gzp07EQgEYLPZUF5ejrq6OpSVlaXL1lHBvj/twV0DP8VdAN7IXw6OU746kDcxD+8WXw1nzzbMCB3EodcPYMbnZyszG6OQH6aG0+/4hN+WC5SfRjxhK0f5Z+9jPM7iiPcwzlswfSTNMz3kh8lz6Jm/YR3WAwC2W34K4G5FnDnLrkDvtyehECfhOPzqmLpZTGiQWFFREX1OLUE++8OLwm927ULNeL1XLAJe2gYA8DW+iBmfp/qWQ36YHOzjTuH3xMuUAn1mxhzgs78CAI6+8iEJtAbkh4lT8Er0ejjjm+rXQ2ueFR+ccy0qjz+PKeGj+HDrO5hTc/lImZhRUjbV57Zt21KV1ahm6pvR51az7/yqZrzJt0W3jXvh2bTaNJogPzROwScfC78nX6ls6XFz5gi/T3Z8OCI2jRbID2Nz5thpXPHp3wAAn1mm4PzlTu24S6LXw8O/GjvXw4QFev/+/XjiiScER6yoqDA8aGKs0tniw9zTkRmH9hXMx4yF2t1fc2+pwM68z+Nf8E+4178Gx4+PlJXZBflh4px7fB8A4CwKMO1q5SOUSc4LhN/sAxJoPcgP46d93V+EDwbtnfP/wOVYNePOWfX/sBOVWI3H8Hj3t8bMl/4SFugnn3wSjDE8+eSTKCkpQW1tLb2YH4NP/vmnwu8TS5fpxuUsHDb94DX8CP+Cl0PX4pe/TLd12Qn5YWL09/Zj1mCkBX1g3EWw5ikvjlMXRVvQ47pJoPUgP4yPcIih5D+i18PJ39e/Hp63YDr++dqdeByr8bfO8/H88+m20CSwBHG73ZJ1j8fDfD5fotkZJhgMMgAsGAymvaxU4v3pNtaPXMYAdhIT2LEPTsRMs38/Yzk5jAGMTZjAWHv7CBiaYtJ9vMgPE+MD99sRxwLYa6V/pxonNBhipzCeMYDtz3GMsIWphfzQXHhu+FfB//YWzGPhUDhmmq1bhSTs/PMZO3p0BAxNMfEeL8ODxC644AI4nU5UV1djwYIF4DgOvb29wrt99Dk14OAr+9H+yhlsOzoXn3wCHD8O9PYC/71vPuYP7hbi7bruR1g4xx4zv9mzgZUrgSefBE6fBrwLajGpYAf6cyZgIG8SBgoK0XdeKawV83F+7VJMqzgvjXtnDsgPU8Ohd3qQgzI40IXBCy5RjWPJscA38XJcdmoHZg/5EDwYRNEsmh0LID+MBRsK4WP3brzROQVvHJyBI0ci18NwoBcv7TsXVegX4vbft87QqOwbbgAWLADa24GDH/eje9pC+POHMJRTELkeji/CwOw5GHdtBS66cykKZ44CXzWq/HV1dczj8bD6+npWUVHBOI5jdrud/eQnP2G7du1K9IYibsx2x9izez/bcf2jzDfuYsYA9hyuF+7y+OV1XC2seO1VrO/kgOH8T59mrLKSsSVoZYqMZcu74xewbV99gh1973ga9zg+Un28yA81CIfZ8b+1s/avPcR2zKxhr5Vcz77wBcbq6hj73/9lLBSSRl+zJuI243GK/e8fAprZvjz371knytgWfIPtaD4o2dbby1hjI2Pf+hZjS5YwtmLhJ+zli2vZy3/376z7lfS3HuOB/HBk6P6/t9mbn7+bHbOeyxjA1uDHkssUhxAbgkUIeKXy7rjy9/kYO/dcxh7CQ7rXwgHksHa7i73yvd+y3mN96dnZBIj3eCXcxc0YY16vl23cuJFVV1ez4uJitnz58mSyM4QZHLL/xEnWcddv2TvnXKdwjB4UMQuGhKD8fMaeKbiTtY+/lm370uOsvzd+Zzl9mrH/+fKvmS/3AnYW+TGFeoGlg91wA2P/8z+MDRi/F0gLI3G8xqofsnCYHfjzbvbm0tWsu6Bc4gNdmC1xi4oKxt5/P5q0ujq67eBB7SIafx315X/912h4a0MbKymRut4X8IIkoDPvQrb9c/exd3+701AXZjohP0wf/o9PsFdX/BvbN7FCcS1qQZUkaPx4xt7K/TxrK1zKXv/+7xkLx+8Xhz8Js5cuqmNHLVOFx4Zay3HYmW1cH/vOdxjbtk15ozrSjKhAyxnNz1xCQ2G2+1evsdcv+h47iYmqztAx/vPspaqH2cvPn2aHDjHWl6Ybt6GBEAt2B9knb+xnHY8+z15eeD97f9w8xgC2G5czICyYNXkyY/92Qwt7r+m1jFwkM3G8RrMfhsOMvfund9i2a9cyX94czQvThzhfEXznhN+xD7a+y0Ihxmy2SNjUqfrXyB07oulvvTUS9tKtv2EhcOzv8AdJ/v+If9G055B1Jtt2xT+xjp+/zAb7hkakrsSQH6aW071D7KXVL7BXpy9nfchTHO8+5LFXS25gLSueYm+8wdjhw+lrLPSfHmR+Xw/zvfgRe+PerWz75XexgzmljAHsX/CPEtNmzGDsj1/7A/vw/z5KjzExyKhAjwQj6ZB9fYy9+CJjP/oRY4un7lO98HxkvZD99fM/Znv/mvkuvf0vfsAab3mVTZsmNXMXrmAMYAdzyti2ylWs4+cvs4EzgyNikxnu8NPBSO7X6dOM/eUvjH3/+4zdeO6rqn44BAt7c/xS9uyXG9nu5g/ZqcAgO3GCseeeY+ziixmrxZOMAcyXewHzvtwrJL3+ev2yz55lLG/4+lteztieph1sAJGRiwEUsu9+5Sh7803GTp5k7ERXkO3599fZNtejbHfhtZKuTPGyy+pkt94ase3MmbRXH2OM/DA1ZTG2ZQtj3/wmY7fl/7fqsX2nYAH72/W/ZN27M/uYLRwKs3efeoM98HedrKgoauJkfCr4757xV7Ft1Y+x993vjFjjJd7jxTHGmJFn1fKvtxihtLQ07jSx6O3tRVFREYLBYMonnz/pH8TeLfsQ+PMreP/AOKzpvB1nzkS378XFuBjvoxeT0Fb+TYz/h++i8gdXISfXXNPOhULAiy8Cv/sd8PGz76BjUDnrTgBF2DvNhX7nNbB/9WrMudmJcbb8lNuS6uM1Fvzw9PGzeH/Le/D/+TXsPDwDP36/Bn2R10WRg0F8hnNRjADC4LC7cBFOVK2A454bUX7NFNX8gieGcHjmVbj4rBcA4EcxDmMaduJKsDt/gNt/pT1BBAAsWgS8+ipQiCD2cPNQyvYDAF694ge41vuvmgN8jr33Gd7f+GcUPL8VVxzzIA+DAIBf4B/xQ/wCADB+PPClLzL848RncN5XK+C4/lLkjMuNt8piQn4YP6e6e/Bx8y70/vVV/OXYVfj5vi9haCiyzYYeHMNk5CCE45bJeG/+LZhSfxsurLkMnLkuhzh7Fvif/wH+8Afg/P/7V/wL+ydFnG7rbHQ7FoNbeC2mLfs8ZlVfCM6asnm8BOI9XoYEOhgMwuPxxGUIx3FwuVyaRrjdbgCA3++Hw+GAy+UylG+yDskGh3BybzeOew/ieMcBnN57AJauTpx7dA8cfXuRjwEAwLu4BJfhXSGd1Qo0XPKf+Nw1Flyx/kZMPFc5qbsZCR4+jd0PbsX4rX+As8cjfL1ITj/ycMPFH6Fk/ixccglwySXABcXHMWM6Q6HjHCR61qXyAjKq/PD0GQT37Id/z0EE3zmI03sPItf3PqZ8+g5mDnwsHKcXUY0vIjodYm4u0Fi6AXOcE3H+fTWYMs/YyP2D2z7GOVWXYzzOSsLfefL1mN8b/93NL+DiTQ/hKuwUwvZOqMScY68bFtPe7iDe2/hXcM9txYMnfoiWs9cK28rggw/lAIAzGIeuSZej97yLEJ5zEcbNuxCTr7kAk+dNR8FUG/mhjKT9sCeA4O4uBPYcQM+eA+j/4ADGde3F1OPvYMrQYSHe73ArvovfCevFxcB/lK1D6Q1XYO69X4V1XF7cZWeC4+8cwftr/wtTXvw9Ljj7tma8LosDdyzpxMUXA3PnAhdfDJyfdxDnnl+IvHNtCZefFoFONT6fDw0NDWhsbAQAVFdXG36pn9/B53+2AxNCAHf6lLBYzpyC5fRJsGAQ1p4TsPb68T+XPoB91ktx7BjwySfA/P3P4k8DNxoq69LJn2LBV87Fl78MVFcD9thvRpmaE+8fwwe/eAHc8/+Hiw7+DcWsR9jWjzxMwGmERNOz/xR34278HH3Ix/HcaegZPx1nJ5RgcGIxwoXFQHExQoXF6C29HP5LFyE/H8JSeOQDDBadg6GiXHzxi+m5w0+WVPjhnxvexIRBJvXBMycj/4M9sAZOILfXj984f4mDA1MRCABHjgDLujbix4P1Mcs5hQm4ZFoAX/xqDr76VaCqCpg4MbH9ffnza3DdGxuE9SCKMOHsceQU6L9t2dHgQcV91ZKwdxtfx6W1+sKuRV8f0NoKPPtspGVTdfxP+BO+GTPdGYzDwrl+lEwvQEkJMGkS8Llj/4vS3rcBmw3MVgw2bjzYuPHgxo8Dxo0Dxo/H0NQZyDsHqKoavX645ZE3MDEEcKdOgjt9CtYzJ2Hl/fBkENbgCeT1nsDPrtqEwKkc+P3A4cPAPQf/Ef8Q/reY5XTCgS+d34kvfxn48pcjfpiXHZqsyaFXfOj65V8xfvtfcMnxl1EgevWrFUvhQqsk/k5UohLt6OUKcSxvOk6POwdnxp+D/onnYLCwBGGbHdykiThy4WKcmnkxcnMjN9T56Ietpwv9U2bBNm0IS5bE4Ydp62zXobGxka1atUpYr6mpYS0tLYbS8n34JzSeb8mXr+HPkqBFeEnzGV5n/sVs5/k3s53f/Bnb/9wuFh7K8JC/NBIaGGIfbdnDXvnWk+zV829lnok3MKtVWi1/wnJDdfwfuEUR/BnOYWvwY3bBBeZ99pcKPwwaqB8GsPnokAStwB9V451BAXuvwMneuOAWtuPb/8b2/3lPyvzwxAfHJGXtmBrjAfQwZwN9knRvT7o6JfYwxtjgIGPtmz5m267/OXtt5s3sQE6ZZh36YVMEP4Pvxqz7W/FbtnAh+SED2GR8Kgm6G0+oxjuBYtY+YRHbPvdO9vLK/2Rd27vStPfm4NSJPtb2r68zzxca2BtTbmCPjHtUUS2fYrKhOr4dT0mCLsZ7jAFsCVrZzTenaaKSVNLZ2YmSkhJh3W63IxAIqMbt7+9Hf3/0zqa3txcAcAoTYUdvzLLs8Au/J00C8ibPxKsnb8Tpc2aDK5uNwktn49wrSzHTdSEcReOg/KbP6MSSa8X5N16O82+8HEAdAOB0P/Dhh8B77wH79gGWvzqxs6sXRacOYfLAJ7CjRzWvsxinCBuPM6rhZiIVfmgUsR9OmACcOfdStPTdgr7Js4BZs1B46Syc93kHSqvKMXec9pzEyWCfcw5ed9yCz/t+Hwn43u2G0hUU5eOVi2qx6P0mAMDp25XP8BIlJweoWF4OLP+hEObvPo3u1g8ReOsDDLzzAfIO+TA+eBiBgfHIDwGiwwAbAjHLOIPxyMnIlc4YI+mH5+A4jiHyDfqSEsBfVInn+1fi7LmzYC2bDdvlszB14QUovWYaKgpM9jA5jUyw52PBXdcAd0V6ha4GUHcsch3cuxf4YF8Y7/7P11DYcwDnnDmAc4aOYiJOq+Z1GhOkeQ/H60d+3E9oTOO2fr9fNXzDhg1Yv369InyXcwU6rRaECiZiqGAiQuMmIDT8P6d4EnKn2JE3pRh1s6fgnsm9KC4GIj0K5wD4rSK/Pgyir3cwtTuVhcyeHVm+8hUA//x9AN8HELkXPHziLHoPBHDqUABnjgTQdzQILhhASdEs/GxmLwYGIhfP/n6g/S81mHNROb59SS8eeghgI/8kJSHi9cMdl69A3gQ7wuMmIlQwAeFxExAeNxHhCRPBFU5C3hQ78qfZ8fjsKSg8pxeTJkUGRnHcLADKCdb7Bk+jL41uOMP9MF68cQCD51+Ea++9zvAF3rHlAfzt+tMIT52Oax78YtzCEA85RUDZjeXAjeUAviLZ9inrRSAABIPAyZNA6O178NL+5QidCALBILi+M+D6zsIycBbW4f+LKqYgfHkvtm8fvX64c97NyJ9QjKFxk8DGTUBo/ESEx08EGzcBVtsk5E61I/88O/6rdCoKi3tRWBh5FAXMG16k9A+cRP9AKvco+8jPB+bNiywAgEf+Rdg2FAY+8ffh1AE/zhw6gYEjJzDwaQ8Ge8/g+vJLcJ2tF4ODwOAgMP5IDt7y3IwViyeg2NmLP/4xDj9MZ7eBFo2NjayhoUFY1+vS6evrY8FgUFj27t3LANCSZUt3d/dIuZdhyA/H3kJ+SIsZFqN+mJEWtMvlQn19dICMz+fTHLWYn5+P/Pzo6z8TJ07E3r17MXfuXHR3d5tuwEei9Pb2YubMmaNyn/bu3Ytp06Zl2hwF5IdKyA9HHvJDJeSHETIyihuQvlZgt9tRU1NjOG063/3LFLRPmYH8UArtU2YgP5RC+xQhY8+g43FAgkgX5IeEGSA/JNRI/VQpBEEQBEEkTVYKdH5+Ph566CHJs5hsh/Yp+xiN+0f7lH2Mxv2jfYqQsWfQBEEQBEFok5UtaIIgCIIY7ZBAEwRBEIQJIYEmCIIgCBMyKgR62bJl8Hq98Hq9khf+swW32w23242mpqa4P2NnVrL9mMTLaNhf8sPsZzTsL/mhiKTnqTMBTqeT2Ww25nK5WE9PT6bNiYvOzk5WW1srrLtcrgxakzqy+ZgkQrbvL/nh6CDb95f8UMqoaEGvXr0aPT09aGlpgc1my7Q5ceHxeCQ222y2UXHXmM3HJBGyfX/JD0cH2b6/5IdSTPM1q2Roa2sDEP0CTG1tbSbNiYt4PjWXTWTzMUmEbN9f8sPRQbbvL/mhlFEh0A0NDcLv8vJyLF++PCvvHnm0PjWXTYy2YxKL0bi/5IfZx2jc37Hsh6YX6I0bN+LEiROK8JKSEqxatQputxttbW1CBdhsNvh8PjidzpE2NSHKy8sld4h+vx8OhyNzBqWAbD8mcka7DwLkh9kA+WF2ksxxMb1Ar1q1Sne7w+GQ3IkEAoGscsh4PjWXLWT7MZEz2n0QID/MBsgPs5NkjsuomOqT/1RbW1sb6urqsu6OK5lPzZmVbD8m8TIa9pf8MPsZDftLfhhlVAg0QRAEQYw2RsVrVgRBEAQx2iCBJgiCIAgTQgJNEARBECaEBJogCIIgTAgJNEEQBEGYEBJogiAIgjAhJNAEQRAEYUJIoAmCIAjChJBAEwRBEIQJIYEmCIIgCBNi+o9ljHZ8Ph88Hg86OztRV1cHr9eLtrY2rF69Ous/E0dkD+SHhBkgP5TBiIzS2NjIGGOspaWFOZ1OxhhjDoeDdXZ2ZtIsYoxBfkiYAfJDKdSCzjDLly8HAHi9XqxYsQIA0NnZmUmTiDEI+SFhBsgPpdDXrExCRUUFmpub4XA4EAgExmZ3DpFxyA8JM0B+GIEGiWWQpqYm1NfXw+v1wufzCd8I3bx5c4YtI8YS5IeEGSA/VEIt6Azi8Xjg8/lgt9ths9ng8/kAALW1tRm2jBhLkB8SZoD8UAkJNEEQBEGYEOriJgiCIAgTQgJNEARBECaEBJogCIIgTAgJNEEQBEGYEBJogiAIgjAhJNAEQRAEYUJIoAmCIAjChJBAEwRBEIQJIYEmCIIgCBNCAk0QBEEQJoQEmiAIgiBMCAk0QRAEQZgQEmiCIAiCMCEk0ARBEARhQkigCYIgCMKEkEATBEEQhAkhgSYIgiAIE0ICTRAEQRAmhASaIJLA5/Nh2bJlqKiogNvthtvtxsaNG1FeXp5p07IOr9cr1GVTUxOamppQX18Pj8eTcJ4+nw8VFRWSPBI5NnQ8iUyQk2kDCCKbcTgcqK6uRkdHB2pqaoRwp9MJn88Hh8ORknKamppQW1ubkrzMitPpxIoVK9DS0iLZV47j0NnZmVBdOhwOuFwuSVhLS4tuGrW6jpWGINIBtaAJIoUEAgF4vV64XC4EAoGU5dvY2JiyvLINm82W0rqMJfRqdZ2qGy2CiAdqQRNZzYIFwNGj6ct/6lSgvT12PJ/PB7fbjZaWFixbtgxApEXo8XhQV1eHhoYGuFwuVFRUoKGhATU1Naivr0d1dTVaWlpQV1cniIDb7Ybf7wcA2O12QaCamppUW4Qp5Wc/iyyxcDqBP/9ZGnb99YDXq53m7rsjSxw0NTXB5XJJ6rKxsRENDQ1obm6GzWZDfX09Kisr4fP5hLgbN26EzWaD3W6H1+tFdXU1gGg3ekdHB2w2m6G6lqfZuHGjRLBramrg9XpRVVWF5uZmBAIBbNq0Cc3NzXHtK0HIIYEmspqjR4FPPsm0FZEWlriLm8flcgkCDEC4yANASUmJILYNDQ1obGyE1+sVLu4+nw/19fWCEI1IF3dvr7EKnTlTGXbsmH7a3l5DJrS3t8PtdgOI1B+/3y6XSxBdvk6amppQUlIi1H11dTXq6urQ2dkptITF3dNOp1MQV6N1LU7T1NQEAEJ5/I2V0+nEggULYLfb4XK5hBs2NZ8gCKOQQBNZzdSp5sq/pqZG6I7lL9D8c+pNmzYpLthNTU0IBAJCK27Tpk1Ca8/hcIx8K6ywEJg+PXa8yZPVw/TSFhYaMkHrZofH6XQKv/kbHn4QGH+jU1FRIcThb4jkJFLXHR0dQhogMnjM4/EINmmVRRCJQAJNZDVGup9HGpvNBp/PJ4guP1jsxIkTgmg3NTXhxIkTWLVqFbxeL9ra2uD1elFSUoLOzk4hr0AgIFz0A4EAPB5PeltlCXRDC8i7vEeAiooKdHZ2Cj0RfHd2W1ubEEfr+XUidV1RUQGfzyesd3Z2Co80gEg3OUGkChokRhBJ4PP50NLSInTL8q9ZVVdXY8GCBWhqakJ1dTVcLhfq6upwxx13oKmpCQsWLBBEQCzkq1atAgBs3LgRbrdbEIO6ujo0NTWN6haaz+fDpk2b4PP5VF+t8nq98Pl8QjczANTW1qKkpARNTU1Ct3hNTQ1KSkqE4+Hz+YTubj6PzZs3G65rcRq+69vtdqOpqQkVFRXCc2retkAggJaWFmzatCmlg9uIsQfHGGOZNoIgCIIgCCnUgiYIgiAIE0ICTRAEQRAmhASaIAiCIEwICTRBEARBmBASaIIgCIIwISTQBEEQBGFCSKAJgiAIwoSQQBMEQRCECSGBJgiCIAgTQgJNEARBECaEBJogCIIgTAgJNEEQBEGYEBJogiAIgjAhJNAEQRAEYUJIoAmCIAjChPx/A7URS2k3pCAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 539.643x300.166 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######################################################################\n",
    "############################# Plotting ###############################\n",
    "######################################################################    \n",
    "#调用concatenate函数拼接数组\n",
    "X0 = np.concatenate((x0, 0*x0), 1) # (x0, 0)\n",
    "X_lb = np.concatenate((0*tb + lb[0], tb), 1) # (lb[0], tb)\n",
    "X_ub = np.concatenate((0*tb + ub[0], tb), 1) # (ub[0], tb)\n",
    "X_u_train = np.vstack([X0, X_lb, X_ub])  #(X0;X_lb;X_ub)\n",
    "#调用plotting文件中的newfig函数，生成一个宽1英寸、高0.9英寸的图像fig和子图ax\n",
    "fig, ax = newfig(1.0, 0.9) #这里ax是一个axes对象，代表子图，figure是一个figure对象，是一个图形窗口，代表整个图形\n",
    "ax.axis('off') #关闭子图的轴的显示\n",
    "\n",
    "####### Row 0: h(t,x)，绘制第一个子图，展示x,t和|h(t,x)|的关系##################    \n",
    "#创建一个包含子图的网格，1行2列\n",
    "gs0 = gridspec.GridSpec(1,2)  #创建一个1×2的网络，用于存放子图\n",
    "gs0.update(top=1-0.06, bottom=1-1/3, left=0.15, right=0.85, wspace=0) #更新该网络的参数，第一个表示子图的顶部位置为0.94，第二个参数表示子图的底部位置为0.667，第三个表示子图左侧的位置为0.15，第四个参数表示子图的右侧位置为0.85，第五个参数表示子图之间的宽度，0表示子图之间没有空隙\n",
    "ax = plt.subplot(gs0[:,:]) #在gs0[:,:] 指定的位置创建了一个子图，并将返回的axes对象赋值给ax。gs0[:,:]表示GridSpec对象gs0的所有行和所有列，所以这行代码创建的子图占据了整个图形。\n",
    "\n",
    "#绘制热图\n",
    "h = ax.imshow(H_pred.T, interpolation='nearest', cmap='YlGnBu', \n",
    "                extent=[lb[1], ub[1], lb[0], ub[0]], \n",
    "                origin='lower', aspect='auto')  #imshow函数用于显示图像，接受一些参数，第一个参数是图像数据，这里是H_pred的转置；第二个参数是插值方法（用于在像素之间插入新的像素），这里是最邻近插值；\n",
    "                                                #第三个参数是颜色映射，这里是从黄色Yl到绿色Gn再到蓝色Bu；第四个参数是图像的范围，这里lb和ub分别是数据的下界和上界；第五个参数是图像的原点位置，这里表示原点在右下角；第六个参数是图像的纵横比，这里表示调整横纵比以填充整个axes对象\n",
    "                                                #最后的结果返回一个axesimage对象，也就是h，可以通过这个对象进一步设置图像的属性\n",
    "divider = make_axes_locatable(ax)  #使用 make_axes_locatable 函数创建了一个 AxesDivider 对象。这个函数接受一个 Axes 对象作为参数，返回一个 AxesDivider 对象。AxesDivider 对象可以用来管理子图的布局，特别是当你需要在一个图的旁边添加另一个图时。\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05) #使用append_axes方法在原始轴的右侧添加了一个新的轴。append_axes 方法接受三个参数：位置（\"right\"）、大小（\"5%\"）和间距（0.05）。在原始轴的右侧添加了一个新的轴，新轴的大小是原始轴的 5%，新轴与原始轴之间的间距是 0.05 英寸\n",
    "fig.colorbar(h, cax=cax) #使用colorbar方法在新轴上添加了一个颜色条。colorbar 方法接受两个参数：axesimage 对象（h）和新轴（cax）。\n",
    "\n",
    "#绘制散点图\n",
    "ax.plot(X_u_train[:,1], X_u_train[:,0], 'kx', label = 'Data (%d points)' % (X_u_train.shape[0]), markersize = 4, clip_on = False) #在ax上绘制散点图，前两个参数是散点的x坐标和y坐标；kx表示黑色的x（散点形状是x），label是散点的标签，clip_on表示散点可以绘制在轴的边界外\n",
    "\n",
    "\n",
    "#绘制三条虚线\n",
    "line = np.linspace(x.min(), x.max(), 2)[:,None] #生成了一个包含2个等间距的数值的数组，这些数值在 x.min() 到 x.max() 之间。[:,None] 是一个索引操作，用于将一维数组转换为二维数组。这里其实就是[-5;5]\n",
    "#第一个参数是虚线的x坐标，line是虚线y的坐标，第三个参数是虚线的样式，k表示黑色，--表示虚线，最后一个参数表示虚线的参数是1\n",
    "ax.plot(t[75]*np.ones((2,1)),line,'k--',linewidth=1) \n",
    "ax.plot(t[100]*np.ones((2,1)),line,'k--',linewidth=1)\n",
    "ax.plot(t[125]*np.ones((2,1)),line,'k--',linewidth=1)    \n",
    "\n",
    "#设置标签\n",
    "#设置ax子图的x轴的标签为t，y轴的标签为x。这里$t$和$x$是latex格式的文本，用于生成数学公式\n",
    "ax.set_xlabel('$t$')\n",
    "ax.set_ylabel('$x$')\n",
    "#设置子图ax的图例，frameon=False表示不显示图例的边框，loc='best'表示图例的位置是最佳位置，最后返回的leg是一个legend对象，表示图形的图例\n",
    "leg = ax.legend(frameon=False, loc = 'best')\n",
    "#    plt.setp(leg.get_texts(), color='w')   #用来设置图例中文本的颜色，这里是白色，取消注释后文本会变为白色\n",
    "ax.set_title('$|h(t,x)|$', fontsize = 10) #设置子图ax的标题为$|h(t,x)|$，表示latex格式的文本，用于生成数学公式，fontsize=10表示字体大小为10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####### Row 1: h(t,x) slices ##################    \n",
    "gs1 = gridspec.GridSpec(1,3) #创建一个1×3的网络，用于存放子图\n",
    "gs1.update(top=1-1/3, bottom=0, left=0.1, right=0.9, wspace=0.5) #更新该网络的参数，第一个表示子图的顶部位置为0.667，第二个参数表示子图的底部位置为0，第三个表示子图左侧的位置为0，第四个参数表示子图的右侧位置为0.9，第五个参数表示子图之间的宽度为0.5\n",
    "\n",
    "ax = plt.subplot(gs1[0,0])  #在gs1[0,0]指定的位置，也就是网格的第一行第一列，创建了一个子图，并将返回的axes对象赋值给ax。\n",
    "#绘制了两条线，一条表示精确值，一条表示预测值\n",
    "ax.plot(x,Exact_h[:,75], 'b-', linewidth = 2, label = 'Exact')      #第一个参数表示x轴上的坐标；第二个参数表示y轴上的坐标；第三个参数b-表示蓝色的实线；linewidth表示线的宽度为2；label表示线的标签\n",
    "ax.plot(x,H_pred[75,:], 'r--', linewidth = 2, label = 'Prediction') #同上\n",
    "#设置ax子图的x轴的标签为x，y轴的标签为|h(t,x)|。这里$x$和$|h(t,x)|$是latex格式的文本，用于生成数学公式\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$|h(t,x)|$')    \n",
    "#设置子图的标题，几个子图标题随着t的变化而变化，字体大小为10 \n",
    "ax.set_title('$t=%.2f$' % (t[75]), fontsize = 10)\n",
    "ax.axis('square') #设置子图的纵横比，使得x轴和y轴的单位长度相等，形成一个正方形的区域\n",
    "ax.set_xlim([-5.1,5.1]) #第一个子图的x轴范围是-5.1到5.1\n",
    "ax.set_ylim([-0.1,5.1]) #第一个子图的y轴范围是-0.1到5.1\n",
    "\n",
    "ax = plt.subplot(gs1[0, 1]) #在gs1[0,1]指定的位置，也就是网格的第一行第二列，创建了一个子图，并将返回的axes对象赋值给ax。\n",
    "#绘制了两条线，一条表示精确值，一条表示预测值\n",
    "ax.plot(x,Exact_h[:,100],'b-', linewidth = 2, label = 'Exact')        #第一个参数表示x轴上的坐标；第二个参数表示y轴上的坐标；第三个参数b-表示蓝色的实线；linewidth表示线的宽度为2；label表示线的标签\n",
    "ax.plot(x,H_pred[100,:],'r--', linewidth = 2, label = 'Prediction')   #同上\n",
    "ax.set_xlabel('$x$') #设置子图的x轴的标签为x\n",
    "ax.set_ylabel('$|h(t,x)|$') #设置子图的y轴的标签为|h(t,x)|\n",
    "ax.axis('square')   #设置子图的纵横比，使得x轴和y轴的单位长度相等，形成一个正方形的区域\n",
    "ax.set_xlim([-5.1,5.1])     #第二个子图的x轴范围是-5.1到5.1\n",
    "ax.set_ylim([-0.1,5.1])     #第二个子图的y轴范围是-0.1到5.1\n",
    "ax.set_title('$t = %.2f$' % (t[100]), fontsize = 10)        #设置第二个子图的标题，标题随着t的变化而变化，字体大小为10\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.8), ncol=5, frameon=False)  #设置第二个子图的图例，loc='upper center'表示图例的位置是上方中心，bbox_to_anchor=(0.5,-0.8)表示图例的中心位置是在子图的中间偏下方0.8的位置，ncol=5表示图例的列数是5，frameon=False表示不显示图例的边框\n",
    "\n",
    "ax = plt.subplot(gs1[0, 2]) #在gs1[0,2]指定的位置，也就是网格的第一行第三列，创建了一个子图，并将返回的axes对象赋值给ax。\n",
    "ax.plot(x,Exact_h[:,125], 'b-', linewidth = 2, label = 'Exact')        #第一个参数表示x轴上的坐标；第二个参数表示y轴上的坐标；第三个参数b-表示蓝色的实线；linewidth表示线的宽度为2；label表示线的标签\n",
    "ax.plot(x,H_pred[125,:], 'r--', linewidth = 2, label = 'Prediction')    #同上\n",
    "ax.set_xlabel('$x$') #设置子图的x轴的标签为x\n",
    "ax.set_ylabel('$|h(t,x)|$') #设置子图的y轴的标签为|h(t,x)|\n",
    "ax.axis('square')    #设置子图的纵横比，使得x轴和y轴的单位长度相等，形成一个正方形的区域\n",
    "ax.set_xlim([-5.1,5.1])    #第三个子图的x轴范围是-5.1到5.1\n",
    "ax.set_ylim([-0.1,5.1])    #第三个子图的y轴范围是-0.1到5.1\n",
    "ax.set_title('$t = %.2f$' % (t[125]), fontsize = 10)    #设置第三个子图的标题，标题随着t的变化而变化，字体大小为10\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
