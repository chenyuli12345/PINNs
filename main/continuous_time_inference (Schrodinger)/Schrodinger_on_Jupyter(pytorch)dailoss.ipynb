{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries, set the gpu and random seed\n",
    "\n",
    "#下面这行代码，是为了把自己编写的代码文件当作一共模块导入，这里是把Utilities文件夹中的plotting.py文件当作python的模块导入，对应的是下面的from plotting import newfig, savefig。路径要随着不同设备的系统做相应的修改\n",
    "import sys #导入sys模块。sys模块提供了一些变量和函数，用于与 Python解释器进行交互和访问。例如，sys.path 是一个 Python 在导入模块时会查找的路径列表，sys.argv 是一个包含命令行参数的列表，sys.exit() 函数可以用于退出 Python 程序。导入 sys 模块后，你就可以在你的程序中使用这些变量和函数了。\n",
    "sys.path.insert(0, '../../Utilities/') #在 Python的sys.path列表中插入一个新的路径。sys.path是一个 Python 在导入模块时会查找的路径列表。新的路径'../../Utilities/'相对于当前脚本的路径。当你尝试导入一个模块时，Python 会在 sys.path 列表中的路径下查找这个模块。通过在列表开始位置插入一个路径，你可以让 Python 优先在这个路径下查找模块。这在你需要导入自定义模块或者不在 Python 标准库中的模块时非常有用。\n",
    "\n",
    "import torch\n",
    "#collections是python一个内置模块，提供了一些有用的数据结构\n",
    "from collections import OrderedDict  #这个类是字典dict的一个子类，用于创建有序的字典。普通字典中元素顺序是无序的，在OrderedDict中元素的顺序是有序的，元素的顺序是按照它们被添加到字典中的顺序决定的。\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#下面的`scipy`是一个用于科学计算和技术计算的Python库，提供了许多高级的数学函数和便利的操作，包括数值积分、插值、优化、图像处理、统计等。\n",
    "import scipy.io #导入了scipy库中的io模块。scipy.io模块包含了一些用于文件输入/输出的函数，例如读取和写入.mat文件（MATLAB格式）。\n",
    "from scipy.interpolate import griddata#`scipy.interpolate`是`scipy`库中的一个模块，提供了许多插值工具，用于在给定的离散数据点之间进行插值和拟合。`griddata`是这个模块中的一个函数，用于在无规则的数据点上进行插值。它使用方法如下：\n",
    "#griddata(points, values, xi, method='linear', fill_value=nan, rescale=False)；\n",
    "   # `points`： ndarray of floats, shape (n, D)。表示数据点的坐标。`values`： ndarray of float or complex, shape (n,)。表示数据点的值。`xi`： ndarray of float, shape (M, D)。表示插值点的坐标。`method`： 插值方法，可选'linear'、'nearest'、'cubic'。默认为'linear'。\n",
    "   #`fill_value`： 在插值范围外的点的值。默认为nan。`rescale`： 是否对坐标点进行重标定，以提高数值稳定性。默认为False。\n",
    "   #返回值：ndarray，shape (M,) or (M, 1)。插值点的值。这个函数可以用于从散列的数据点创建一个连续的函数，这对于处理实际数据非常有用，因为实际数据通常是不规则或者不完整的。\n",
    "from pyDOE import lhs #`pyDOE`是一个Python库，用于设计实验。它提供了一些函数来生成各种设计，如因子设计、拉丁超立方设计等。`lhs`是库中的一个函数，全名为\"Latin Hypercube Sampling\"，拉丁超立方采样。这是一种统计方法，用于生成一个近似均匀分布的多维样本点集。它在参数空间中生成一个非常均匀的样本，这对于高维数值优化问题非常有用，因为它可以更好地覆盖参数空间。\n",
    "#`lhs`函数的基本用法如下：lhs(n, samples=1000):其中，`n`是参数的数量，`samples`是想生成的样本点的数量。这个函数会返回一个形状为(samples, n)的数组，每一行都是一个n维的样本点，所有的样本点都在[0, 1]范围内。\n",
    "from plotting_torch import newfig, savefig #从自定义的plotting.py文件中导入了newfig和savefig函数。这两个函数用于创建和保存图形。这两个函数的定义在plotting.py文件中\n",
    "from mpl_toolkits.mplot3d import Axes3D #`mpl_toolkits.mplot3d`是`matplotlib`库的一个模块，用于创建三维图形。`Axes3D`是`mpl_toolkits.mplot3d`模块中的一个类，用于创建一个三维的坐标轴。可以在这个坐标轴上绘制三维的图形，如曲线、曲面等。\n",
    "import time #一个内置模块，用于处理时间相关的操作。\n",
    "import matplotlib.gridspec as gridspec #是`matplotlib`库的一个模块，用于创建一个网格布局来放置子图。在`matplotlib`中可以创建一个或多个子图（subplot），每个子图都有自己的坐标轴，并可以在其中绘制图形。`gridspec`模块提供了一个灵活的方式来创建和放置子图。\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable #`mpl_toolkits.axes_grid1`是`matplotlib`库的一个模块，提供了一些高级的工具来控制matplotlib图形中的坐标轴和颜色条。`make_axes_locatable`是模块中的一个函数，用于创建一个可分割的坐标轴。可以在这个坐标轴的四个方向（上、下、左、右）添加新的坐标轴或颜色条。\n",
    "\n",
    "\n",
    "np.random.seed(1234) #这里有变化，仅需要设置numpy的随机数生成器的种子。设置随机数生成器的种子可以确保每次运行程序时，NumPy生成的随机数序列都是一样的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA support \n",
    "\n",
    "#设置pytorch的设备，代表了在哪里执行张量积算，设备可以是cpu或者cuda（gpu），并将这个做运算的设备对象存储在变量device中，后续张量计算回在这个设备上执行\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class DNN(torch.nn.Module):\n",
    "    #第一个方法\n",
    "    def __init__(self, layers):\n",
    "        super(DNN, self).__init__() #调用父类的__init__方法进行初始化\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1 #定义名为depth的属性，表示神经网络的深度，等于层数-1\n",
    "        \n",
    "        # set up layer order dict\n",
    "        self.activation = torch.nn.Tanh #设置激活函数为tanh\n",
    "         \n",
    "        layer_list = list() #定义一个空列表layer_list\n",
    "        for i in range(self.depth - 1):  #循环depth次\n",
    "            #将每一层（全连接层）添加到layer_list中\n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            #将每一层的激活函数添加到layer_list中\n",
    "            layer_list.append(('activation_%d' % i, self.activation()))\n",
    "\n",
    "        #循环结束后，将最后一层的线性变换添加到layer_list中（因为没有激活函数了）\n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        #然后使用OrderedDict将layer_list中的元素转换为有序字典\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers，将layerDict转换为一个神经网络模型，赋值给self.layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "    \n",
    "    #第二个方法，定义了模型的前向传播过程\n",
    "    def forward(self, x):  #接收输入x\n",
    "        out = self.layers(x) #将输入x传入神经网络模型self.layers中，得到输出out\n",
    "        return out #返回输出out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the class of PINN\n",
    "\n",
    "#定义了一个名为`PhysicsInformedNN'的类，用于实现基于物理的神经网络。\n",
    "class PhysicsInformedNN:\n",
    "    # Initialize the class\n",
    "    def __init__(self, x0, u0, v0, tb, X_f, layers, lb, ub): #这个类包含的第一个方法__init__，这是一个特殊的方法，也就是这个类的构造函数，用于初始化新创建的对象，接受了几个参数\n",
    "        \n",
    "        \n",
    "        #`numpy.concatenate`是一个用于数组拼接的函数。它可以将多个数组沿指定的轴拼接在一起，形成一个新的数组：numpy.concatenate((a1,a2, ...), axis=0)其中，`a1,a2, ...`是需要拼接的数组（只能接受数组或序列类型的参数，且参数形状必须相同），可以是多个。`axis`参数用于指定拼接的轴向，`axis=0`表示沿着第一个轴（即行）进行拼接，不指定`axis`参数默认值是0。\n",
    "        X0 = np.concatenate((x0,0*x0), 1) # [x0, 0],将x0和0*x0两个数组在第二个维度（即列）上进行了合并。0*x0会生成一个与x0形状相同，但所有元素都为0的数组。因此，X0的结果是一个新的二维数组，其中第一列是x0的值，第二列全为0\n",
    "        X_lb = np.concatenate((0*tb+lb[0],tb), 1) # [lb[0], tb],将0*tb+lb[0]和tb两个数组在第二个维度（即列）上进行了合并。0*tb+lb[0]会生成一个与tb形状相同，但所有元素都为lb[0]的数组。因此，X_lb的结果是一个新的二维数组，其中第一列全为lb[0]的值，第二列是tb的值。\n",
    "        X_ub = np.concatenate((0*tb+ub[0],tb), 1) # [ub[0], tb],同上生成一个与tb形状相同，但所有元素都为ub[0]的数组。因此，X_ub的结果是一个新的二维数组，其中第一列全为ub[0]的值，第二列是tb的值\n",
    "        \n",
    "        #Python使用self关键字来表示类的实例。当在类的方法中定义一个变量时，例如lb和ub，这些变量只在该方法内部可见，也就是说它们的作用域仅限于该方法。当方法执行完毕后，这些变量就会被销毁，无法在其他方法中访问它们。但如果希望在类的其他方法中也能访问这些变量就需要将它们保存为类的实例属性。这就是self.lb和self.ub的作用。\n",
    "            #通过将lb和ub赋值给self.lb和self.ub，就可以在类的其他方法中通过self.lb和self.ub来访问这些值。总的来说，self.lb和self.ub是类的实例属性，它们的作用域是整个类，而不仅仅是定义它们的方法。\n",
    "        self.lb = torch.tensor(lb).float().to(device) #将传入的lb和ub参数的值存储在实例中，以便后续使用。这样可以在类的其他方法中通过self.lb和self.ub来访问这些值。\n",
    "        self.ub = torch.tensor(ub).float().to(device)\n",
    "\n",
    "\n",
    "        self.x0 = torch.tensor(X0[:,0:1], requires_grad=True).float().to(device) #将X0的第一列赋值给self.x0（:表示取所有行,0：1实际上表示取第一列，因为python是左闭右开的）,将X0的第二列赋值给self.t0。这样可以在类的其他方法中通过self.x0和self.t0来访问这些值。\n",
    "        self.t0 = torch.tensor(X0[:,1:2], requires_grad=True).float().to(device) #将x0的第二列赋值给self.t0\n",
    "\n",
    "        self.x_lb = torch.tensor(X_lb[:,0:1], requires_grad=True).float().to(device) #将X_lb的第一列赋值给self.x_lb\n",
    "        self.t_lb = torch.tensor(X_lb[:,1:2], requires_grad=True).float().to(device) #将X_lb的第二列赋值给self.t_lb\n",
    "\n",
    "        self.x_ub = torch.tensor(X_ub[:,0:1], requires_grad=True).float().to(device) #将X_ub的第一列赋值给self.x_ub\n",
    "        self.t_ub = torch.tensor(X_ub[:,0:1], requires_grad=True).float().to(device) #将X_ub的第二列赋值给self.t_ub\n",
    "        \n",
    "        self.x_f = torch.tensor(X_f[:,0:1], requires_grad=True).float().to(device) #将X_f的第一列赋值给self.x_f\n",
    "        self.t_f = torch.tensor(X_f[:,1:2], requires_grad=True).float().to(device) #将X_f的第二列赋值给self.t_f\n",
    "        \n",
    "        self.u0 = torch.tensor(u0).float().to(device) #将传入的u0和v0参数的值存储在实例中，以便后续使用。这样可以在类的其他方法中通过self.u0和self.v0来访问这些值。\n",
    "        self.v0 = torch.tensor(v0).float().to(device)\n",
    "        \n",
    "        # Initialize NNs \n",
    "        self.layers = layers #将传入的layers参数的值存储在实例中，以便后续使用。这样可以在类的其他方法中通过self.layers来访问这些值。\n",
    "        \n",
    "        \n",
    "        # deep neural networks\n",
    "        self.dnn = DNN(layers).to(device) #创建一个DNN类的实例，传入layers参数来实现神经网络的初始化，然后将这个实例移动到指定的设备上\n",
    "\n",
    "\n",
    "\n",
    "        # optimizers: using the same settings，这里是使用pytorch库进行优化的部分\n",
    "        #创建优化器optimizer，使用LBFGS算法，具体每个参数意义见下方\n",
    "        self.optimizer = torch.optim.LBFGS(\n",
    "            self.dnn.parameters(), #要优化的参数，这里返回的是一个生成器，包含了self.dnn中的所有参数（神经网络权重、偏置以及两个新加的变量）\n",
    "            lr=1.0,  #学习率设置为1\n",
    "            max_iter=50000,  #最大迭代次数为50000\n",
    "            max_eval=50000,  #最大评估次数为50000\n",
    "            history_size=50, #历史大小为50，即用于计算Hessian矩阵近似的最近几步的信息\n",
    "            tolerance_grad=1e-5,  #优化的第一个停止条件，当梯度的L2范数小于1e-5时停止优化\n",
    "            tolerance_change=1.0 * np.finfo(float).eps, #优化的第二个停止条件，当优化的目标函数值的变化小于1.0 * np.finfo(float).eps时停止优化\n",
    "            line_search_fn=\"strong_wolfe\"       # 制定了用于一维搜索的方法，这里表示用强Wolfe条件\n",
    "        )\n",
    "        #创建第二个优化器，括号内为要优化的参数，使用Adam优化方法\n",
    "        self.optimizer_Adam = torch.optim.Adam(self.dnn.parameters())\n",
    "                \n",
    "\n",
    "        self.iter = 0 #记录迭代次数 \n",
    "\n",
    "        self.loss_value = [] #创建一个空列表，用于存储损失值\n",
    "\n",
    "    \n",
    "    \n",
    "    #pytorch中\n",
    "    #定义了一个名为net_u的函数/方法，用于计算神经网络的输出。这个方法接受两个参数，分别是x和t，其中x是输入数据，t是时间数据。最后返回神经网络的输出。     \n",
    "    def net_uv(self, x, t):  \n",
    "        uv = self.dnn(torch.cat([x, t], dim=1))  #（第一个参数将输入的两个参数x和t在第二个维度（列）上进行拼接，形成一个新的张量）调用DNN，根据两个参数权重和偏置，以及新得到的张量，计算神经网络的输出u\n",
    "        #将uv（是一个二维张量）的第一列赋值给u，第二列赋值给v\n",
    "        u=uv[:,0:1]\n",
    "        v=uv[:,1:2]\n",
    "\n",
    "        u_x = torch.autograd.grad(\n",
    "            u, x, \n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        v_x = torch.autograd.grad(\n",
    "            v, x, \n",
    "            grad_outputs=torch.ones_like(v),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "\n",
    "        return u,v,u_x,v_x #返回神经网络的输出u和v，以及u关于x的梯度u_x和v关于x的梯度v_x\n",
    "\n",
    "\n",
    "    #定义了一个名为net_f的函数/方法，用于计算论文中的f。这个方法接受两个参数，分别是x和t，其中x是输入数据，t是时间数据。最后返回计算得到的f。\n",
    "    def net_f_uv(self, x, t):\n",
    "        \"\"\" The pytorch autograd version of calculating residual \"\"\"\n",
    "\n",
    "        u,v,u_x,v_x=self.net_uv(x,t) #调用上面的函数/方法，计算神经网络的输出（两个）以及输出关于输入x的梯度（两个）\n",
    "        \n",
    "        #计算u关于t的梯度，也就是u关于t的导数，这里使用了pytorch的自动求导功能\n",
    "        u_t = torch.autograd.grad(\n",
    "            u, t,  #输入的张量，要计算u关于t的导数\n",
    "            grad_outputs=torch.ones_like(u), #生成一个与u形状相同，所有元素均为1的张量，这个参数用于指定向量-雅可比积的像两部分\n",
    "            retain_graph=True, #表示计算完梯度之后保留计算图若需要多次计算梯度，则需要设置改参数为True\n",
    "            create_graph=True #创建梯度的计算图，使我们能够计算高阶导数\n",
    "        )[0] #这个函数的返回值是一个元组，其中包含了每个输入张量的梯度。这里只关心第一个输入张量u的梯度，所以我们使用[0]来获取这个梯度。？？？？又说只有一个梯度\n",
    "        v_t = torch.autograd.grad(\n",
    "            v, t, \n",
    "            grad_outputs=torch.ones_like(v),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        u_xx = torch.autograd.grad(\n",
    "            u_x, x, \n",
    "            grad_outputs=torch.ones_like(u_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        v_xx = torch.autograd.grad(\n",
    "            v_x, x, \n",
    "            grad_outputs=torch.ones_like(v_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        f_u=u_t+0.5*v_xx+(u**2+v**2)*v    #计算f_u,定义见论文\n",
    "        f_v=v_t-0.5*u_xx-(u**2+v**2)*u   #计算f_v,定义见论文\n",
    "        return f_u, f_v  #返回计算得到的f_u和f_v\n",
    "\n",
    "\n",
    "    def loss_func(self):\n",
    "        self.optimizer.zero_grad() #清除之前计算的梯度（在PyTorch中，梯度会累积，所以在每次新的优化迭代之前，我们需要清除之前的梯度）\n",
    "\n",
    "        u0_pred, v0_pred, _ , _ = self.net_uv(self.x0, self.t0) #是调用net_uv函数,将self.x0_tf和self.t0_tf作为参数传入,然后将返回的前两个结果赋值给self.u0_pred和self.v0_pred。后两个_是Python惯用法，表示不关心net_uv函数返回的后两个结果。\n",
    "        u_lb_pred, v_lb_pred, u_x_lb_pred, v_x_lb_pred = self.net_uv(self.x_lb, self.t_lb) #同上，不过这里函数返回的后两个结果会赋值给self.u_x_lb_pred和self.v_x_lb_pred。\n",
    "        u_ub_pred, v_ub_pred, u_x_ub_pred, v_x_ub_pred = self.net_uv(self.x_ub, self.t_ub) #同上\n",
    "        f_u_pred, f_v_pred = self.net_f_uv(self.x_f, self.t_f) #调用net_f_uv函数,将self.x_f_tf和self.t_f_tf作为参数传入,然后将返回的结果赋值给self.f_u_pred和self.f_v_pred。\n",
    "\n",
    "        loss = torch.mean((self.u0 - u0_pred) ** 2)  + \\\n",
    "                    torch.mean((self.v0 - v0_pred) ** 2) + \\\n",
    "                    torch.mean((u_lb_pred - u_ub_pred) ** 2) + \\\n",
    "                    torch.mean((v_lb_pred - v_ub_pred) ** 2) + \\\n",
    "                    torch.mean((u_x_lb_pred - u_x_ub_pred) ** 2) + \\\n",
    "                    torch.mean((v_x_lb_pred - v_x_ub_pred) ** 2) + \\\n",
    "                    torch.mean(f_u_pred ** 2) + \\\n",
    "                    torch.mean(f_v_pred ** 2)\n",
    "        loss.backward() #被调用以计算损失函数关于神经网络参数的梯度。这个梯度将被用于优化器来更新神经网络参数\n",
    "        \n",
    "        self.iter += 1 #每调用一次损失函数，迭代次数加1\n",
    "\n",
    "\n",
    "        self.loss_value.append(loss) #将计算得到的loss值添加到self.loss_value列表中\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        if self.iter % 100 == 0:\n",
    "            print(\n",
    "                'Iter %d, Loss: %e' % \n",
    "                (\n",
    "                    self.iter,\n",
    "                    loss#这里使用了detach()方法，将lambda_2从计算图中分离出来，这样就不会计算lambda_2的梯度，只是将lambda_2的值返回？？？why\n",
    "                ) #每100次迭代，打印一次迭代次数、总的loss、loss_u和loss_f\n",
    "            )\n",
    "        return loss #返回loss\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    #定义了一个名为train的函数/方法，用于训练神经网络。这个方法接受一个参数nIter，表示训练的迭代次数。\n",
    "    def train(self, nIter):\n",
    "        self.dnn.train()#将神经网络设置为训练模式而不是评估模式\n",
    "\n",
    "        #先使用Adam优化器优化nIter次\n",
    "        for epoch in range(nIter):\n",
    "            u0_pred, v0_pred, _ , _ = self.net_uv(self.x0, self.t0) #是调用net_uv函数,将self.x0_tf和self.t0_tf作为参数传入,然后将返回的前两个结果赋值给self.u0_pred和self.v0_pred。后两个_是Python惯用法，表示不关心net_uv函数返回的后两个结果。\n",
    "            u_lb_pred, v_lb_pred, u_x_lb_pred, v_x_lb_pred = self.net_uv(self.x_lb, self.t_lb) #同上，不过这里函数返回的后两个结果会赋值给self.u_x_lb_pred和self.v_x_lb_pred。\n",
    "            u_ub_pred, v_ub_pred, u_x_ub_pred, v_x_ub_pred = self.net_uv(self.x_ub, self.t_ub) #同上\n",
    "            f_u_pred, f_v_pred = self.net_f_uv(self.x_f, self.t_f) #调用net_f_uv函数,将self.x_f_tf和self.t_f_tf作为参数传入,然后将返回的结果赋值给self.f_u_pred和self.f_v_pred。\n",
    "\n",
    "            loss = torch.mean((self.u0 - u0_pred) ** 2)  + \\\n",
    "                    torch.mean((self.v0 - v0_pred) ** 2) + \\\n",
    "                    torch.mean((u_lb_pred - u_ub_pred) ** 2) + \\\n",
    "                    torch.mean((v_lb_pred - v_ub_pred) ** 2) + \\\n",
    "                    torch.mean((u_x_lb_pred - u_x_ub_pred) ** 2) + \\\n",
    "                    torch.mean((v_x_lb_pred - v_x_ub_pred) ** 2) + \\\n",
    "                    torch.mean(f_u_pred ** 2) + \\\n",
    "                    torch.mean(f_v_pred ** 2)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            self.optimizer_Adam.zero_grad() #清除该优化器之前计算的梯度（在PyTorch中，梯度会累积，所以在每次新的优化迭代之前，我们需要清除之前的梯度）\n",
    "            loss.backward() #被调用以计算损失函数关于神经网络参数的梯度。这个梯度将被用于优化器来更新神经网络参数\n",
    "            self.optimizer_Adam.step()  #使用之前的优化器self.optimizer_Adam，调用step方法(执行一步优化算法)，传入损失函数self.loss_func，进行优化\n",
    "\n",
    "\n",
    "\n",
    "            self.loss_value.append(loss) #将计算得到的loss值添加到self.loss_value列表中\n",
    "\n",
    "\n",
    "            \n",
    "            if epoch % 100 == 0:\n",
    "                print(\n",
    "                    'It: %d, Loss: %.3e' % \n",
    "                    (\n",
    "                        epoch, \n",
    "                        loss\n",
    "                    ) #每100次迭代，打印一次迭代次数、总的loss\n",
    "                )\n",
    "\n",
    "\n",
    "        # Backward and optimize，用LBFGS优化器进行进一步优化\n",
    "        self.optimizer.step(self.loss_func)  #使用之前的优化器self.optimizer，调用step方法(执行一步优化算法)，传入计算损失函数的方法self.loss_func，进行优化   \n",
    "\n",
    "                                    \n",
    "    #定义了一个名为predict的函数/方法，用于预测神经网络的输出。这个方法接受一个参数X_star，表示输入数据。最后返回预测的两个输出和两个输出的梯度。\n",
    "    def predict(self, X):\n",
    "        x = torch.tensor(X[:, 0:1], requires_grad=True).float().to(device) #从输入中得到x和t（第一列和第二列），是张量，需要计算梯度，转换为浮点数类型，并将张量移动到指定设备上\n",
    "        t = torch.tensor(X[:, 1:2], requires_grad=True).float().to(device)\n",
    "\n",
    "        self.dnn.eval() #将神经网络切换为评估模式\n",
    "        u, v, _, _ = self.net_uv(x, t) #调用之前定义的函数得到神经网络的输出u,以及f\n",
    "        f_u, f_v = self.net_f_uv(x, t) \n",
    "\n",
    "        u = u.detach().cpu().numpy() #将张量u和v先从计算图中分离出来，然后转换为numpy数组，最后将这个数组移动到cpu上\n",
    "        v = v.detach().cpu().numpy()\n",
    "        f_u = f_u.detach().cpu().numpy()\n",
    "        f_v = f_v.detach().cpu().numpy()\n",
    "        return u, v, f_u, f_v \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0, Loss: 8.853e-01\n",
      "It: 100, Loss: 8.724e-02\n",
      "It: 200, Loss: 6.148e-02\n",
      "It: 300, Loss: 5.933e-02\n",
      "It: 400, Loss: 6.309e-02\n",
      "It: 500, Loss: 5.422e-02\n",
      "It: 600, Loss: 4.905e-02\n",
      "It: 700, Loss: 4.599e-02\n",
      "It: 800, Loss: 4.350e-02\n",
      "It: 900, Loss: 4.064e-02\n",
      "It: 1000, Loss: 3.838e-02\n",
      "It: 1100, Loss: 5.629e-02\n",
      "It: 1200, Loss: 3.498e-02\n",
      "It: 1300, Loss: 5.135e-02\n",
      "It: 1400, Loss: 3.167e-02\n",
      "It: 1500, Loss: 3.047e-02\n",
      "It: 1600, Loss: 2.959e-02\n",
      "It: 1700, Loss: 3.000e-02\n",
      "It: 1800, Loss: 2.694e-02\n",
      "It: 1900, Loss: 2.641e-02\n",
      "It: 2000, Loss: 3.779e-02\n",
      "It: 2100, Loss: 7.254e-02\n",
      "It: 2200, Loss: 2.309e-02\n",
      "It: 2300, Loss: 2.644e-02\n",
      "It: 2400, Loss: 2.280e-02\n",
      "It: 2500, Loss: 2.270e-02\n",
      "It: 2600, Loss: 1.906e-02\n",
      "It: 2700, Loss: 1.788e-02\n",
      "It: 2800, Loss: 1.855e-02\n",
      "It: 2900, Loss: 1.641e-02\n",
      "It: 3000, Loss: 1.541e-02\n",
      "It: 3100, Loss: 1.486e-02\n",
      "It: 3200, Loss: 1.436e-02\n",
      "It: 3300, Loss: 1.452e-02\n",
      "It: 3400, Loss: 1.643e-02\n",
      "It: 3500, Loss: 1.570e-02\n",
      "It: 3600, Loss: 1.206e-02\n",
      "It: 3700, Loss: 1.172e-02\n",
      "It: 3800, Loss: 1.135e-02\n",
      "It: 3900, Loss: 1.123e-02\n",
      "It: 4000, Loss: 1.055e-02\n",
      "It: 4100, Loss: 1.012e-02\n",
      "It: 4200, Loss: 9.793e-03\n",
      "It: 4300, Loss: 9.387e-03\n",
      "It: 4400, Loss: 9.128e-03\n",
      "It: 4500, Loss: 8.813e-03\n",
      "It: 4600, Loss: 1.679e-02\n",
      "It: 4700, Loss: 2.714e-02\n",
      "It: 4800, Loss: 7.940e-03\n",
      "It: 4900, Loss: 7.769e-03\n",
      "It: 5000, Loss: 7.635e-03\n",
      "It: 5100, Loss: 7.389e-03\n",
      "It: 5200, Loss: 7.264e-03\n",
      "It: 5300, Loss: 6.811e-03\n",
      "It: 5400, Loss: 6.716e-03\n",
      "It: 5500, Loss: 8.822e-03\n",
      "It: 5600, Loss: 6.365e-03\n",
      "It: 5700, Loss: 6.332e-03\n",
      "It: 5800, Loss: 6.698e-03\n",
      "It: 5900, Loss: 2.774e-02\n",
      "It: 6000, Loss: 1.192e-02\n",
      "It: 6100, Loss: 5.575e-03\n",
      "It: 6200, Loss: 6.001e-02\n",
      "It: 6300, Loss: 9.355e-03\n",
      "It: 6400, Loss: 5.120e-03\n",
      "It: 6500, Loss: 5.136e-03\n",
      "It: 6600, Loss: 4.893e-03\n",
      "It: 6700, Loss: 4.789e-03\n",
      "It: 6800, Loss: 4.957e-03\n",
      "It: 6900, Loss: 4.896e-03\n",
      "It: 7000, Loss: 4.368e-03\n",
      "It: 7100, Loss: 4.417e-03\n",
      "It: 7200, Loss: 4.171e-03\n",
      "It: 7300, Loss: 7.040e-03\n",
      "It: 7400, Loss: 4.376e-03\n",
      "It: 7500, Loss: 4.256e-03\n",
      "It: 7600, Loss: 1.402e-02\n",
      "It: 7700, Loss: 3.794e-03\n",
      "It: 7800, Loss: 3.538e-03\n",
      "It: 7900, Loss: 3.509e-03\n",
      "It: 8000, Loss: 3.610e-03\n",
      "It: 8100, Loss: 4.062e-03\n",
      "It: 8200, Loss: 3.207e-03\n",
      "It: 8300, Loss: 1.592e-02\n",
      "It: 8400, Loss: 3.047e-03\n",
      "It: 8500, Loss: 3.272e-03\n",
      "It: 8600, Loss: 3.420e-03\n",
      "It: 8700, Loss: 5.289e-03\n",
      "It: 8800, Loss: 2.800e-03\n",
      "It: 8900, Loss: 3.189e-03\n",
      "It: 9000, Loss: 2.758e-03\n",
      "It: 9100, Loss: 2.598e-03\n",
      "It: 9200, Loss: 2.634e-03\n",
      "It: 9300, Loss: 2.497e-03\n",
      "It: 9400, Loss: 2.784e-03\n",
      "It: 9500, Loss: 2.514e-03\n",
      "It: 9600, Loss: 3.931e-03\n",
      "It: 9700, Loss: 3.109e-03\n",
      "It: 9800, Loss: 3.691e-02\n",
      "It: 9900, Loss: 2.166e-03\n",
      "It: 10000, Loss: 2.358e-03\n",
      "It: 10100, Loss: 2.230e-03\n",
      "It: 10200, Loss: 2.479e-03\n",
      "It: 10300, Loss: 2.524e-03\n",
      "It: 10400, Loss: 1.929e-03\n",
      "It: 10500, Loss: 1.934e-03\n",
      "It: 10600, Loss: 2.668e-03\n",
      "It: 10700, Loss: 1.663e-02\n",
      "It: 10800, Loss: 3.523e-03\n",
      "It: 10900, Loss: 7.919e-03\n",
      "It: 11000, Loss: 1.717e-03\n",
      "It: 11100, Loss: 4.404e-03\n",
      "It: 11200, Loss: 3.108e-03\n",
      "It: 11300, Loss: 4.838e-03\n",
      "It: 11400, Loss: 1.544e-03\n",
      "It: 11500, Loss: 1.585e-03\n",
      "It: 11600, Loss: 1.493e-03\n",
      "It: 11700, Loss: 6.506e-03\n",
      "It: 11800, Loss: 1.419e-03\n",
      "It: 11900, Loss: 1.410e-03\n",
      "It: 12000, Loss: 1.424e-03\n",
      "It: 12100, Loss: 1.451e-03\n",
      "It: 12200, Loss: 4.135e-03\n",
      "It: 12300, Loss: 3.824e-02\n",
      "It: 12400, Loss: 3.160e-03\n",
      "It: 12500, Loss: 1.255e-03\n",
      "It: 12600, Loss: 1.741e-03\n",
      "It: 12700, Loss: 3.397e-03\n",
      "It: 12800, Loss: 9.014e-03\n",
      "It: 12900, Loss: 6.787e-03\n",
      "It: 13000, Loss: 4.174e-03\n",
      "It: 13100, Loss: 2.028e-03\n",
      "It: 13200, Loss: 2.876e-03\n",
      "It: 13300, Loss: 4.547e-03\n",
      "It: 13400, Loss: 1.057e-03\n",
      "It: 13500, Loss: 1.708e-03\n",
      "It: 13600, Loss: 1.326e-03\n",
      "It: 13700, Loss: 1.217e-03\n",
      "It: 13800, Loss: 2.019e-03\n",
      "It: 13900, Loss: 1.404e-03\n",
      "It: 14000, Loss: 7.967e-03\n",
      "It: 14100, Loss: 1.828e-03\n",
      "It: 14200, Loss: 9.299e-04\n",
      "It: 14300, Loss: 9.174e-04\n",
      "It: 14400, Loss: 9.119e-04\n",
      "It: 14500, Loss: 1.444e-03\n",
      "It: 14600, Loss: 8.665e-04\n",
      "It: 14700, Loss: 8.901e-04\n",
      "It: 14800, Loss: 8.595e-04\n",
      "It: 14900, Loss: 9.175e-04\n",
      "It: 15000, Loss: 1.796e-03\n",
      "It: 15100, Loss: 2.292e-02\n",
      "It: 15200, Loss: 8.003e-04\n",
      "It: 15300, Loss: 7.988e-04\n",
      "It: 15400, Loss: 8.363e-04\n",
      "It: 15500, Loss: 1.725e-03\n",
      "It: 15600, Loss: 1.738e-03\n",
      "It: 15700, Loss: 1.209e-02\n",
      "It: 15800, Loss: 3.280e-02\n",
      "It: 15900, Loss: 7.157e-04\n",
      "It: 16000, Loss: 7.386e-04\n",
      "It: 16100, Loss: 7.041e-04\n",
      "It: 16200, Loss: 7.463e-04\n",
      "It: 16300, Loss: 1.327e-03\n",
      "It: 16400, Loss: 2.909e-03\n",
      "It: 16500, Loss: 2.003e-03\n",
      "It: 16600, Loss: 3.613e-03\n",
      "It: 16700, Loss: 7.151e-04\n",
      "It: 16800, Loss: 1.038e-03\n",
      "It: 16900, Loss: 3.575e-03\n",
      "It: 17000, Loss: 8.521e-04\n",
      "It: 17100, Loss: 6.448e-04\n",
      "It: 17200, Loss: 7.666e-04\n",
      "It: 17300, Loss: 1.194e-02\n",
      "It: 17400, Loss: 4.151e-03\n",
      "It: 17500, Loss: 1.183e-02\n",
      "It: 17600, Loss: 2.752e-03\n",
      "It: 17700, Loss: 6.416e-04\n",
      "It: 17800, Loss: 2.379e-03\n",
      "It: 17900, Loss: 1.989e-03\n",
      "It: 18000, Loss: 2.100e-03\n",
      "It: 18100, Loss: 9.287e-04\n",
      "It: 18200, Loss: 7.518e-04\n",
      "It: 18300, Loss: 2.454e-03\n",
      "It: 18400, Loss: 8.641e-04\n",
      "It: 18500, Loss: 2.777e-03\n",
      "It: 18600, Loss: 6.587e-04\n",
      "It: 18700, Loss: 5.717e-04\n",
      "It: 18800, Loss: 4.967e-04\n",
      "It: 18900, Loss: 5.277e-04\n",
      "It: 19000, Loss: 3.570e-03\n",
      "It: 19100, Loss: 5.509e-04\n",
      "It: 19200, Loss: 1.711e-03\n",
      "It: 19300, Loss: 4.829e-04\n",
      "It: 19400, Loss: 1.008e-03\n",
      "It: 19500, Loss: 1.840e-03\n",
      "It: 19600, Loss: 5.685e-04\n",
      "It: 19700, Loss: 2.113e-02\n",
      "It: 19800, Loss: 9.237e-04\n",
      "It: 19900, Loss: 6.839e-04\n",
      "It: 20000, Loss: 5.068e-04\n",
      "It: 20100, Loss: 7.394e-04\n",
      "It: 20200, Loss: 4.410e-04\n",
      "It: 20300, Loss: 4.858e-04\n",
      "It: 20400, Loss: 2.012e-03\n",
      "It: 20500, Loss: 2.444e-02\n",
      "It: 20600, Loss: 9.417e-03\n",
      "It: 20700, Loss: 1.358e-02\n",
      "It: 20800, Loss: 1.344e-03\n",
      "It: 20900, Loss: 5.279e-04\n",
      "It: 21000, Loss: 1.037e-03\n",
      "It: 21100, Loss: 1.863e-03\n",
      "It: 21200, Loss: 2.542e-03\n",
      "It: 21300, Loss: 8.117e-04\n",
      "It: 21400, Loss: 4.627e-04\n",
      "It: 21500, Loss: 4.757e-04\n",
      "It: 21600, Loss: 6.229e-03\n",
      "It: 21700, Loss: 7.601e-04\n",
      "It: 21800, Loss: 2.032e-03\n",
      "It: 21900, Loss: 1.657e-03\n",
      "It: 22000, Loss: 3.105e-03\n",
      "It: 22100, Loss: 3.633e-04\n",
      "It: 22200, Loss: 3.727e-04\n",
      "It: 22300, Loss: 1.861e-03\n",
      "It: 22400, Loss: 1.580e-03\n",
      "It: 22500, Loss: 9.721e-04\n",
      "It: 22600, Loss: 3.925e-04\n",
      "It: 22700, Loss: 3.770e-03\n",
      "It: 22800, Loss: 9.870e-03\n",
      "It: 22900, Loss: 7.403e-04\n",
      "It: 23000, Loss: 3.407e-04\n",
      "It: 23100, Loss: 4.796e-04\n",
      "It: 23200, Loss: 1.771e-03\n",
      "It: 23300, Loss: 2.136e-03\n",
      "It: 23400, Loss: 3.740e-04\n",
      "It: 23500, Loss: 8.857e-04\n",
      "It: 23600, Loss: 3.073e-03\n",
      "It: 23700, Loss: 1.867e-02\n",
      "It: 23800, Loss: 3.071e-04\n",
      "It: 23900, Loss: 3.407e-04\n",
      "It: 24000, Loss: 2.395e-03\n",
      "It: 24100, Loss: 3.057e-04\n",
      "It: 24200, Loss: 3.307e-04\n",
      "It: 24300, Loss: 8.868e-04\n",
      "It: 24400, Loss: 2.930e-04\n",
      "It: 24500, Loss: 3.119e-04\n",
      "It: 24600, Loss: 3.158e-04\n",
      "It: 24700, Loss: 2.852e-04\n",
      "It: 24800, Loss: 3.179e-04\n",
      "It: 24900, Loss: 2.940e-04\n",
      "It: 25000, Loss: 3.023e-04\n",
      "It: 25100, Loss: 5.126e-03\n",
      "It: 25200, Loss: 2.866e-04\n",
      "It: 25300, Loss: 2.820e-04\n",
      "It: 25400, Loss: 2.919e-04\n",
      "It: 25500, Loss: 9.922e-03\n",
      "It: 25600, Loss: 1.090e-03\n",
      "It: 25700, Loss: 3.218e-03\n",
      "It: 25800, Loss: 6.037e-04\n",
      "It: 25900, Loss: 1.319e-02\n",
      "It: 26000, Loss: 2.830e-04\n",
      "It: 26100, Loss: 2.812e-04\n",
      "It: 26200, Loss: 2.857e-04\n",
      "It: 26300, Loss: 3.174e-04\n",
      "It: 26400, Loss: 6.182e-04\n",
      "It: 26500, Loss: 6.796e-04\n",
      "It: 26600, Loss: 5.559e-04\n",
      "It: 26700, Loss: 2.631e-04\n",
      "It: 26800, Loss: 2.750e-04\n",
      "It: 26900, Loss: 2.587e-04\n",
      "It: 27000, Loss: 7.599e-04\n",
      "It: 27100, Loss: 2.415e-04\n",
      "It: 27200, Loss: 2.496e-04\n",
      "It: 27300, Loss: 2.506e-04\n",
      "It: 27400, Loss: 2.460e-04\n",
      "It: 27500, Loss: 3.541e-04\n",
      "It: 27600, Loss: 3.454e-04\n",
      "It: 27700, Loss: 2.847e-04\n",
      "It: 27800, Loss: 2.495e-04\n",
      "It: 27900, Loss: 2.365e-04\n",
      "It: 28000, Loss: 2.713e-04\n",
      "It: 28100, Loss: 3.476e-04\n",
      "It: 28200, Loss: 2.545e-04\n",
      "It: 28300, Loss: 8.324e-03\n",
      "It: 28400, Loss: 1.140e-03\n",
      "It: 28500, Loss: 4.923e-04\n",
      "It: 28600, Loss: 5.141e-03\n",
      "It: 28700, Loss: 7.629e-04\n",
      "It: 28800, Loss: 2.622e-04\n",
      "It: 28900, Loss: 2.033e-03\n",
      "It: 29000, Loss: 4.728e-04\n",
      "It: 29100, Loss: 5.313e-04\n",
      "It: 29200, Loss: 6.707e-04\n",
      "It: 29300, Loss: 3.210e-04\n",
      "It: 29400, Loss: 7.272e-04\n",
      "It: 29500, Loss: 4.230e-03\n",
      "It: 29600, Loss: 3.902e-04\n",
      "It: 29700, Loss: 2.501e-04\n",
      "It: 29800, Loss: 3.532e-03\n",
      "It: 29900, Loss: 6.744e-03\n",
      "It: 30000, Loss: 6.490e-04\n",
      "It: 30100, Loss: 6.303e-04\n",
      "It: 30200, Loss: 1.974e-04\n",
      "It: 30300, Loss: 6.341e-04\n",
      "It: 30400, Loss: 2.242e-03\n",
      "It: 30500, Loss: 4.240e-04\n",
      "It: 30600, Loss: 5.388e-03\n",
      "It: 30700, Loss: 2.702e-03\n",
      "It: 30800, Loss: 2.191e-04\n",
      "It: 30900, Loss: 4.813e-04\n",
      "It: 31000, Loss: 5.227e-03\n",
      "It: 31100, Loss: 2.462e-04\n",
      "It: 31200, Loss: 1.913e-03\n",
      "It: 31300, Loss: 8.644e-04\n",
      "It: 31400, Loss: 9.224e-04\n",
      "It: 31500, Loss: 2.269e-04\n",
      "It: 31600, Loss: 2.475e-04\n",
      "It: 31700, Loss: 8.748e-03\n",
      "It: 31800, Loss: 4.286e-04\n",
      "It: 31900, Loss: 2.554e-04\n",
      "It: 32000, Loss: 3.494e-04\n",
      "It: 32100, Loss: 2.044e-04\n",
      "It: 32200, Loss: 1.939e-04\n",
      "It: 32300, Loss: 2.502e-04\n",
      "It: 32400, Loss: 2.281e-04\n",
      "It: 32500, Loss: 2.887e-04\n",
      "It: 32600, Loss: 2.035e-04\n",
      "It: 32700, Loss: 2.262e-04\n",
      "It: 32800, Loss: 2.313e-04\n",
      "It: 32900, Loss: 2.109e-03\n",
      "It: 33000, Loss: 1.720e-04\n",
      "It: 33100, Loss: 1.786e-04\n",
      "It: 33200, Loss: 3.776e-03\n",
      "It: 33300, Loss: 4.641e-04\n",
      "It: 33400, Loss: 8.848e-04\n",
      "It: 33500, Loss: 1.301e-02\n",
      "It: 33600, Loss: 1.636e-04\n",
      "It: 33700, Loss: 1.717e-04\n",
      "It: 33800, Loss: 3.555e-04\n",
      "It: 33900, Loss: 1.841e-03\n",
      "It: 34000, Loss: 3.291e-04\n",
      "It: 34100, Loss: 6.857e-04\n",
      "It: 34200, Loss: 1.761e-03\n",
      "It: 34300, Loss: 3.404e-04\n",
      "It: 34400, Loss: 1.754e-04\n",
      "It: 34500, Loss: 1.585e-04\n",
      "It: 34600, Loss: 1.577e-04\n",
      "It: 34700, Loss: 1.931e-04\n",
      "It: 34800, Loss: 1.928e-04\n",
      "It: 34900, Loss: 1.680e-04\n",
      "It: 35000, Loss: 9.999e-04\n",
      "It: 35100, Loss: 1.511e-04\n",
      "It: 35200, Loss: 1.602e-04\n",
      "It: 35300, Loss: 1.725e-04\n",
      "It: 35400, Loss: 1.583e-04\n",
      "It: 35500, Loss: 1.533e-04\n",
      "It: 35600, Loss: 6.561e-04\n",
      "It: 35700, Loss: 2.353e-03\n",
      "It: 35800, Loss: 8.775e-04\n",
      "It: 35900, Loss: 1.508e-04\n",
      "It: 36000, Loss: 1.199e-02\n",
      "It: 36100, Loss: 1.873e-04\n",
      "It: 36200, Loss: 4.437e-03\n",
      "It: 36300, Loss: 1.815e-04\n",
      "It: 36400, Loss: 2.872e-03\n",
      "It: 36500, Loss: 3.478e-03\n",
      "It: 36600, Loss: 2.723e-03\n",
      "It: 36700, Loss: 2.215e-04\n",
      "It: 36800, Loss: 2.102e-04\n",
      "It: 36900, Loss: 2.056e-04\n",
      "It: 37000, Loss: 2.182e-04\n",
      "It: 37100, Loss: 2.693e-04\n",
      "It: 37200, Loss: 6.362e-04\n",
      "It: 37300, Loss: 2.175e-04\n",
      "It: 37400, Loss: 4.982e-04\n",
      "It: 37500, Loss: 4.598e-04\n",
      "It: 37600, Loss: 2.870e-03\n",
      "It: 37700, Loss: 4.953e-04\n",
      "It: 37800, Loss: 1.868e-04\n",
      "It: 37900, Loss: 1.575e-04\n",
      "It: 38000, Loss: 1.387e-04\n",
      "It: 38100, Loss: 2.311e-03\n",
      "It: 38200, Loss: 9.558e-03\n",
      "It: 38300, Loss: 1.300e-04\n",
      "It: 38400, Loss: 1.387e-04\n",
      "It: 38500, Loss: 1.604e-04\n",
      "It: 38600, Loss: 3.816e-03\n",
      "It: 38700, Loss: 3.148e-04\n",
      "It: 38800, Loss: 5.261e-04\n",
      "It: 38900, Loss: 2.742e-03\n",
      "It: 39000, Loss: 2.346e-04\n",
      "It: 39100, Loss: 6.912e-04\n",
      "It: 39200, Loss: 3.268e-03\n",
      "It: 39300, Loss: 4.025e-04\n",
      "It: 39400, Loss: 3.583e-04\n",
      "It: 39500, Loss: 1.328e-04\n",
      "It: 39600, Loss: 1.511e-04\n",
      "It: 39700, Loss: 1.662e-04\n",
      "It: 39800, Loss: 2.486e-04\n",
      "It: 39900, Loss: 2.091e-04\n",
      "It: 40000, Loss: 2.951e-04\n",
      "It: 40100, Loss: 8.784e-03\n",
      "It: 40200, Loss: 1.175e-04\n",
      "It: 40300, Loss: 4.950e-04\n",
      "It: 40400, Loss: 4.016e-04\n",
      "It: 40500, Loss: 1.741e-04\n",
      "It: 40600, Loss: 2.465e-04\n",
      "It: 40700, Loss: 1.501e-03\n",
      "It: 40800, Loss: 5.893e-03\n",
      "It: 40900, Loss: 8.383e-04\n",
      "It: 41000, Loss: 3.609e-04\n",
      "It: 41100, Loss: 4.896e-04\n",
      "It: 41200, Loss: 4.914e-04\n",
      "It: 41300, Loss: 1.710e-04\n",
      "It: 41400, Loss: 1.184e-04\n",
      "It: 41500, Loss: 1.335e-04\n",
      "It: 41600, Loss: 1.723e-03\n",
      "It: 41700, Loss: 3.888e-03\n",
      "It: 41800, Loss: 3.309e-03\n",
      "It: 41900, Loss: 4.229e-04\n",
      "It: 42000, Loss: 4.728e-04\n",
      "It: 42100, Loss: 1.395e-04\n",
      "It: 42200, Loss: 1.752e-04\n",
      "It: 42300, Loss: 1.300e-03\n",
      "It: 42400, Loss: 3.173e-03\n",
      "It: 42500, Loss: 1.862e-03\n",
      "It: 42600, Loss: 2.499e-04\n",
      "It: 42700, Loss: 1.388e-04\n",
      "It: 42800, Loss: 1.103e-04\n",
      "It: 42900, Loss: 1.117e-04\n",
      "It: 43000, Loss: 1.181e-04\n",
      "It: 43100, Loss: 1.374e-04\n",
      "It: 43200, Loss: 1.499e-04\n",
      "It: 43300, Loss: 2.551e-04\n",
      "It: 43400, Loss: 7.218e-04\n",
      "It: 43500, Loss: 1.760e-04\n",
      "It: 43600, Loss: 1.293e-04\n",
      "It: 43700, Loss: 1.465e-02\n",
      "It: 43800, Loss: 6.835e-03\n",
      "It: 43900, Loss: 3.515e-04\n",
      "It: 44000, Loss: 4.336e-03\n",
      "It: 44100, Loss: 3.359e-04\n",
      "It: 44200, Loss: 2.341e-04\n",
      "It: 44300, Loss: 7.112e-04\n",
      "It: 44400, Loss: 1.064e-04\n",
      "It: 44500, Loss: 1.071e-04\n",
      "It: 44600, Loss: 1.109e-04\n",
      "It: 44700, Loss: 2.936e-03\n",
      "It: 44800, Loss: 9.899e-05\n",
      "It: 44900, Loss: 2.330e-04\n",
      "It: 45000, Loss: 6.670e-04\n",
      "It: 45100, Loss: 1.427e-04\n",
      "It: 45200, Loss: 8.944e-04\n",
      "It: 45300, Loss: 1.456e-04\n",
      "It: 45400, Loss: 6.895e-03\n",
      "It: 45500, Loss: 1.256e-04\n",
      "It: 45600, Loss: 1.208e-03\n",
      "It: 45700, Loss: 2.061e-03\n",
      "It: 45800, Loss: 3.148e-03\n",
      "It: 45900, Loss: 1.401e-02\n",
      "It: 46000, Loss: 8.092e-04\n",
      "It: 46100, Loss: 7.737e-04\n",
      "It: 46200, Loss: 2.165e-04\n",
      "It: 46300, Loss: 1.057e-04\n",
      "It: 46400, Loss: 1.854e-04\n",
      "It: 46500, Loss: 1.053e-04\n",
      "It: 46600, Loss: 9.941e-05\n",
      "It: 46700, Loss: 1.070e-04\n",
      "It: 46800, Loss: 1.149e-04\n",
      "It: 46900, Loss: 1.176e-04\n",
      "It: 47000, Loss: 1.012e-04\n",
      "It: 47100, Loss: 2.891e-03\n",
      "It: 47200, Loss: 3.725e-04\n",
      "It: 47300, Loss: 1.543e-04\n",
      "It: 47400, Loss: 2.337e-04\n",
      "It: 47500, Loss: 2.581e-04\n",
      "It: 47600, Loss: 1.463e-04\n",
      "It: 47700, Loss: 2.916e-04\n",
      "It: 47800, Loss: 4.423e-03\n",
      "It: 47900, Loss: 2.992e-04\n",
      "It: 48000, Loss: 1.216e-04\n",
      "It: 48100, Loss: 9.008e-04\n",
      "It: 48200, Loss: 1.574e-02\n",
      "It: 48300, Loss: 2.855e-04\n",
      "It: 48400, Loss: 1.565e-04\n",
      "It: 48500, Loss: 1.335e-04\n",
      "It: 48600, Loss: 4.902e-04\n",
      "It: 48700, Loss: 1.054e-04\n",
      "It: 48800, Loss: 4.103e-03\n",
      "It: 48900, Loss: 3.012e-04\n",
      "It: 49000, Loss: 8.225e-04\n",
      "It: 49100, Loss: 1.837e-04\n",
      "It: 49200, Loss: 1.547e-03\n",
      "It: 49300, Loss: 2.977e-03\n",
      "It: 49400, Loss: 1.119e-04\n",
      "It: 49500, Loss: 9.313e-03\n",
      "It: 49600, Loss: 1.803e-03\n",
      "It: 49700, Loss: 4.477e-04\n",
      "It: 49800, Loss: 6.461e-04\n",
      "It: 49900, Loss: 7.903e-04\n",
      "Iter 100, Loss: 7.338452e-05\n",
      "Iter 200, Loss: 6.101060e-05\n",
      "Iter 300, Loss: 5.118325e-05\n",
      "Iter 400, Loss: 4.413331e-05\n",
      "Iter 500, Loss: 3.857785e-05\n",
      "Iter 600, Loss: 3.380218e-05\n",
      "Iter 700, Loss: 3.015233e-05\n",
      "Iter 800, Loss: 2.689384e-05\n",
      "Iter 900, Loss: 2.427743e-05\n",
      "Iter 1000, Loss: 2.218219e-05\n",
      "Iter 1100, Loss: 2.034504e-05\n",
      "Iter 1200, Loss: 1.868474e-05\n",
      "Iter 1300, Loss: 1.728932e-05\n",
      "Iter 1400, Loss: 1.595632e-05\n",
      "Iter 1500, Loss: 1.503522e-05\n",
      "Iter 1600, Loss: 1.405433e-05\n",
      "Iter 1700, Loss: 1.326865e-05\n",
      "Iter 1800, Loss: 1.246559e-05\n",
      "Iter 1900, Loss: 1.166451e-05\n",
      "Iter 2000, Loss: 1.097871e-05\n",
      "Iter 2100, Loss: 1.041309e-05\n",
      "Iter 2200, Loss: 9.838736e-06\n",
      "Iter 2300, Loss: 9.329629e-06\n",
      "Iter 2400, Loss: 8.889790e-06\n",
      "Iter 2500, Loss: 8.448445e-06\n",
      "Iter 2600, Loss: 8.084619e-06\n",
      "Iter 2700, Loss: 7.721146e-06\n",
      "Iter 2800, Loss: 7.409813e-06\n",
      "Iter 2900, Loss: 7.126625e-06\n",
      "Iter 3000, Loss: 6.877814e-06\n",
      "Iter 3100, Loss: 6.657424e-06\n",
      "Iter 3200, Loss: 6.437142e-06\n",
      "Iter 3300, Loss: 6.255485e-06\n",
      "Iter 3400, Loss: 6.079905e-06\n",
      "Iter 3500, Loss: 5.931423e-06\n",
      "Iter 3600, Loss: 5.798844e-06\n",
      "Iter 3700, Loss: 5.675219e-06\n",
      "Iter 3800, Loss: 5.550878e-06\n",
      "Iter 3900, Loss: 5.440564e-06\n",
      "Iter 4000, Loss: 5.346316e-06\n",
      "Iter 4100, Loss: 5.253101e-06\n",
      "Iter 4200, Loss: 5.165688e-06\n",
      "Iter 4300, Loss: 5.080405e-06\n",
      "Iter 4400, Loss: 5.004789e-06\n",
      "Iter 4500, Loss: 4.932005e-06\n",
      "Iter 4600, Loss: 4.846071e-06\n",
      "Iter 4700, Loss: 4.762664e-06\n",
      "Iter 4800, Loss: 4.692680e-06\n",
      "Iter 4900, Loss: 4.629416e-06\n",
      "Iter 5000, Loss: 4.565252e-06\n",
      "Iter 5100, Loss: 4.501099e-06\n",
      "Iter 5200, Loss: 4.440705e-06\n",
      "Iter 5300, Loss: 4.376660e-06\n",
      "Iter 5400, Loss: 4.321331e-06\n",
      "Iter 5500, Loss: 4.266009e-06\n",
      "Iter 5600, Loss: 4.213840e-06\n",
      "Iter 5700, Loss: 4.165964e-06\n",
      "Iter 5800, Loss: 4.123801e-06\n",
      "Iter 5900, Loss: 4.085446e-06\n",
      "Training time: 767.6939\n",
      "Error u: 7.127588e-03\n",
      "Error v: 1.568244e-02\n",
      "Error h: 5.561791e-03\n"
     ]
    }
   ],
   "source": [
    "#设置噪声值为0 \n",
    "noise = 0.0   \n",
    "\n",
    "Adam_iter = 50000 #Adam优化器的迭代次数\n",
    "\n",
    "\n",
    "# Doman bounds，定义两个一维数组lb和ub，问题域是一个二维空间，其中 x 的范围是 -5 到 5，t 的范围是 0 到 π/2(竖着的)\n",
    "lb = np.array([-5.0, 0.0])\n",
    "ub = np.array([5.0, np.pi/2])\n",
    "#定义三个整数，分别表示初始条件点数量、边界条件点数量和在问题域内部的点的数量（这些点用于训练神经网络）\n",
    "N0 = 50\n",
    "N_b = 50\n",
    "N_f = 20000\n",
    "#定义一个列表layers，其中包含了神经网络的层数和每一层的神经元数量\n",
    "layers = [2, 100, 100, 100, 100, 2]\n",
    "#读取名为NLS.mat的Matlab文件，文件中的数据存储在data变量中。这里的路径也要随着设备的情况修改    \n",
    "data = scipy.io.loadmat('../Data/NLS.mat')\n",
    "#从data字典中取出变量tt和x的值，并转换为一维数组（flatten方法），最后tongg[:,None]将一维数组转换为二维数组\n",
    "t = data['tt'].flatten()[:,None]\n",
    "x = data['x'].flatten()[:,None]\n",
    "Exact = data['uu'] #从data字典中取出变量uu的值，并赋值给Exact\n",
    "Exact_u = np.real(Exact)  #取Exact的实部，赋值给Exact_u\n",
    "Exact_v = np.imag(Exact)  #取Exact的虚部，赋值给Exact_v\n",
    "Exact_h = np.sqrt(Exact_u**2 + Exact_v**2) #计算复数uu的|uu|\n",
    "#生成一个二位网络，X和T是输出的二维数组\n",
    "X, T = np.meshgrid(x,t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))  #X_star是一个二维数组，其中第一列是X的展平，第二列是T的展平\n",
    "u_star = Exact_u.T.flatten()[:,None] #先对Exact_u进行转置，然后使用flatten方法将其转换为一维数组，最后使用[:,None]将其转换为二维数组\n",
    "v_star = Exact_v.T.flatten()[:,None] #同上，比如Exact_v是m*n二维数组，Exact_v.T是n*m二维数组，Exact_v.T.flatten()是一个长度为n*m的一维数组，Exact_v.T.flatten()[:,None]是一个(n*m)*1的三维数组\n",
    "h_star = Exact_h.T.flatten()[:,None]\n",
    "#上面五行代码的意义见Numpy库的索引的介绍\n",
    "\n",
    "\n",
    "###########################\n",
    "\n",
    "#从0~数组x的行数(256)中随机选择N0个数，replace=False表示不允许重复选择，最后将这N0个数赋值给idx_x\n",
    "idx_x = np.random.choice(x.shape[0], N0, replace=False)\n",
    "#从x中选择N0个对应的行(idx_x对应的行)，最后将这N0行赋值给x0\n",
    "x0 = x[idx_x,:]\n",
    "#从Exact_u中选择N0个对应的行(idx_x对应的行)的第一列元素，最后将这N0个元素赋值给u0\n",
    "u0 = Exact_u[idx_x,0:1]\n",
    "v0 = Exact_v[idx_x,0:1]\n",
    "#从0~数组t的行数中随机选择N_b个数，replace=False表示不允许重复选择，最后将这N_b个数赋值给idx_t\n",
    "idx_t = np.random.choice(t.shape[0], N_b, replace=False)\n",
    "#从t中选择N_b个对应的行(idx_t对应的行)，最后将这N_b行赋值给tb\n",
    "tb = t[idx_t,:]\n",
    "\n",
    "X_f = lb + (ub-lb)*lhs(2, N_f) #lhs函数采用拉丁超采样方法，生成一个近似均匀分布的多维样本点集，返回的是一个形状为（$N_f$，2）的数组，每一行都是一个2维的样本点，所有样本点都在[0,1]范围内，并对该样本集进行缩放，把每个样本从[0,1]区间缩放到[lb,ub]区域内，即得到了指定范围内均匀分布的样本$X_f$。\n",
    "\n",
    "#创建PINN模型并输入各种参数        \n",
    "model = PhysicsInformedNN(x0, u0, v0, tb, X_f, layers, lb, ub)\n",
    "#获取当前时间并赋值给start_time          \n",
    "start_time = time.time()       \n",
    "#训练模型50000次         \n",
    "model.train(Adam_iter)\n",
    "#获取当前时间并减去start_time，得到训练时间并赋值给elapsed\n",
    "elapsed = time.time() - start_time                \n",
    "#打印训练所需时间\n",
    "print('Training time: %.4f' % (elapsed))\n",
    "\n",
    "#用训练好的模型进行预测，返回四个值（均为数组）    \n",
    "u_pred, v_pred, f_u_pred, f_v_pred = model.predict(X_star)\n",
    "#计算u_pred和v_pred的模（平方和的平方根），赋值给h_pred\n",
    "h_pred = np.sqrt(u_pred**2 + v_pred**2)\n",
    "#计算误差（基于2范数）        \n",
    "error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
    "error_v = np.linalg.norm(v_star-v_pred,2)/np.linalg.norm(v_star,2)\n",
    "error_h = np.linalg.norm(h_star-h_pred,2)/np.linalg.norm(h_star,2)\n",
    "#打印误差\n",
    "print('Error u: %e' % (error_u))\n",
    "print('Error v: %e' % (error_v))\n",
    "print('Error h: %e' % (error_h))\n",
    "\n",
    "#使用griddata函数将X_star、u_pred、v_pred和h_pred插值到网格上，得到U_pred、V_pred和H_pred\n",
    "U_pred = griddata(X_star, u_pred.flatten(), (X, T), method='cubic')\n",
    "V_pred = griddata(X_star, v_pred.flatten(), (X, T), method='cubic')\n",
    "H_pred = griddata(X_star, h_pred.flatten(), (X, T), method='cubic')\n",
    "#同上，使用griddata函数将X_star、f_u_pred和f_v_pred插值到网格上，得到FU_pred和FV_pred\n",
    "FU_pred = griddata(X_star, f_u_pred.flatten(), (X, T), method='cubic')\n",
    "FV_pred = griddata(X_star, f_v_pred.flatten(), (X, T), method='cubic')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 539.643x333.518 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#打印误差随迭代次数的变化\n",
    "trainloss = torch.stack(model.loss_value).cpu().detach().numpy()\n",
    "# print(trainloss)\n",
    "# print(trainloss.shape)\n",
    "indices=list(range(len(trainloss)))\n",
    "plt.figure()\n",
    "plt.plot(indices[:Adam_iter],trainloss[:Adam_iter],color='red')\n",
    "plt.plot(indices[Adam_iter:],trainloss[Adam_iter:],color='blue')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "# plt.yscale('log') #设置y轴为对数尺度，这样即使列表中有一些非常大的值，也不会影响其他值的可视化\n",
    "plt.xlim([0,max(indices)]) # 设置x轴的范围\n",
    "plt.ylim([0,0.2]) # 设置y轴的范围\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lcy\\AppData\\Local\\Temp\\ipykernel_145752\\2393817356.py:17: MatplotlibDeprecationWarning: Auto-removal of overlapping axes is deprecated since 3.6 and will be removed two minor releases later; explicitly call ax.remove() as needed.\n",
      "  ax = plt.subplot(gs0[:,:]) #在gs0[:,:] 指定的位置创建了一个子图，并将返回的axes对象赋值给ax。gs0[:,:]表示GridSpec对象gs0的所有行和所有列，所以这行代码创建的子图占据了整个图形。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '$t = 0.98$')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 539.643x300.166 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######################################################################\n",
    "############################# Plotting ###############################\n",
    "######################################################################    \n",
    "#调用concatenate函数拼接数组\n",
    "X0 = np.concatenate((x0, 0*x0), 1) # (x0, 0)\n",
    "X_lb = np.concatenate((0*tb + lb[0], tb), 1) # (lb[0], tb)\n",
    "X_ub = np.concatenate((0*tb + ub[0], tb), 1) # (ub[0], tb)\n",
    "X_u_train = np.vstack([X0, X_lb, X_ub])  #(X0;X_lb;X_ub)\n",
    "#调用plotting文件中的newfig函数，生成一个宽1英寸、高0.9英寸的图像fig和子图ax\n",
    "fig, ax = newfig(1.0, 0.9) #这里ax是一个axes对象，代表子图，figure是一个figure对象，是一个图形窗口，代表整个图形\n",
    "ax.axis('off') #关闭子图的轴的显示\n",
    "\n",
    "####### Row 0: h(t,x)，绘制第一个子图，展示x,t和|h(t,x)|的关系##################    \n",
    "#创建一个包含子图的网格，1行2列\n",
    "gs0 = gridspec.GridSpec(1,2)  #创建一个1×2的网络，用于存放子图\n",
    "gs0.update(top=1-0.06, bottom=1-1/3, left=0.15, right=0.85, wspace=0) #更新该网络的参数，第一个表示子图的顶部位置为0.94，第二个参数表示子图的底部位置为0.667，第三个表示子图左侧的位置为0.15，第四个参数表示子图的右侧位置为0.85，第五个参数表示子图之间的宽度，0表示子图之间没有空隙\n",
    "ax = plt.subplot(gs0[:,:]) #在gs0[:,:] 指定的位置创建了一个子图，并将返回的axes对象赋值给ax。gs0[:,:]表示GridSpec对象gs0的所有行和所有列，所以这行代码创建的子图占据了整个图形。\n",
    "\n",
    "#绘制热图\n",
    "h = ax.imshow(H_pred.T, interpolation='nearest', cmap='YlGnBu', \n",
    "                extent=[lb[1], ub[1], lb[0], ub[0]], \n",
    "                origin='lower', aspect='auto')  #imshow函数用于显示图像，接受一些参数，第一个参数是图像数据，这里是H_pred的转置；第二个参数是插值方法（用于在像素之间插入新的像素），这里是最邻近插值；\n",
    "                                                #第三个参数是颜色映射，这里是从黄色Yl到绿色Gn再到蓝色Bu；第四个参数是图像的范围，这里lb和ub分别是数据的下界和上界；第五个参数是图像的原点位置，这里表示原点在右下角；第六个参数是图像的纵横比，这里表示调整横纵比以填充整个axes对象\n",
    "                                                #最后的结果返回一个axesimage对象，也就是h，可以通过这个对象进一步设置图像的属性\n",
    "divider = make_axes_locatable(ax)  #使用 make_axes_locatable 函数创建了一个 AxesDivider 对象。这个函数接受一个 Axes 对象作为参数，返回一个 AxesDivider 对象。AxesDivider 对象可以用来管理子图的布局，特别是当你需要在一个图的旁边添加另一个图时。\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05) #使用append_axes方法在原始轴的右侧添加了一个新的轴。append_axes 方法接受三个参数：位置（\"right\"）、大小（\"5%\"）和间距（0.05）。在原始轴的右侧添加了一个新的轴，新轴的大小是原始轴的 5%，新轴与原始轴之间的间距是 0.05 英寸\n",
    "fig.colorbar(h, cax=cax) #使用colorbar方法在新轴上添加了一个颜色条。colorbar 方法接受两个参数：axesimage 对象（h）和新轴（cax）。\n",
    "\n",
    "#绘制散点图\n",
    "ax.plot(X_u_train[:,1], X_u_train[:,0], 'kx', label = 'Data (%d points)' % (X_u_train.shape[0]), markersize = 4, clip_on = False) #在ax上绘制散点图，前两个参数是散点的x坐标和y坐标；kx表示黑色的x（散点形状是x），label是散点的标签，clip_on表示散点可以绘制在轴的边界外\n",
    "\n",
    "\n",
    "#绘制三条虚线\n",
    "line = np.linspace(x.min(), x.max(), 2)[:,None] #生成了一个包含2个等间距的数值的数组，这些数值在 x.min() 到 x.max() 之间。[:,None] 是一个索引操作，用于将一维数组转换为二维数组。这里其实就是[-5;5]\n",
    "#第一个参数是虚线的x坐标，line是虚线y的坐标，第三个参数是虚线的样式，k表示黑色，--表示虚线，最后一个参数表示虚线的参数是1\n",
    "ax.plot(t[75]*np.ones((2,1)),line,'k--',linewidth=1) \n",
    "ax.plot(t[100]*np.ones((2,1)),line,'k--',linewidth=1)\n",
    "ax.plot(t[125]*np.ones((2,1)),line,'k--',linewidth=1)    \n",
    "\n",
    "#设置标签\n",
    "#设置ax子图的x轴的标签为t，y轴的标签为x。这里$t$和$x$是latex格式的文本，用于生成数学公式\n",
    "ax.set_xlabel('$t$')\n",
    "ax.set_ylabel('$x$')\n",
    "#设置子图ax的图例，frameon=False表示不显示图例的边框，loc='best'表示图例的位置是最佳位置，最后返回的leg是一个legend对象，表示图形的图例\n",
    "leg = ax.legend(frameon=False, loc = 'best')\n",
    "#    plt.setp(leg.get_texts(), color='w')   #用来设置图例中文本的颜色，这里是白色，取消注释后文本会变为白色\n",
    "ax.set_title('$|h(t,x)|$', fontsize = 10) #设置子图ax的标题为$|h(t,x)|$，表示latex格式的文本，用于生成数学公式，fontsize=10表示字体大小为10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####### Row 1: h(t,x) slices ##################    \n",
    "gs1 = gridspec.GridSpec(1,3) #创建一个1×3的网络，用于存放子图\n",
    "gs1.update(top=1-1/3, bottom=0, left=0.1, right=0.9, wspace=0.5) #更新该网络的参数，第一个表示子图的顶部位置为0.667，第二个参数表示子图的底部位置为0，第三个表示子图左侧的位置为0，第四个参数表示子图的右侧位置为0.9，第五个参数表示子图之间的宽度为0.5\n",
    "\n",
    "ax = plt.subplot(gs1[0,0])  #在gs1[0,0]指定的位置，也就是网格的第一行第一列，创建了一个子图，并将返回的axes对象赋值给ax。\n",
    "#绘制了两条线，一条表示精确值，一条表示预测值\n",
    "ax.plot(x,Exact_h[:,75], 'b-', linewidth = 2, label = 'Exact')      #第一个参数表示x轴上的坐标；第二个参数表示y轴上的坐标；第三个参数b-表示蓝色的实线；linewidth表示线的宽度为2；label表示线的标签\n",
    "ax.plot(x,H_pred[75,:], 'r--', linewidth = 2, label = 'Prediction') #同上\n",
    "#设置ax子图的x轴的标签为x，y轴的标签为|h(t,x)|。这里$x$和$|h(t,x)|$是latex格式的文本，用于生成数学公式\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$|h(t,x)|$')    \n",
    "#设置子图的标题，几个子图标题随着t的变化而变化，字体大小为10 \n",
    "ax.set_title('$t=%.2f$' % (t[75]), fontsize = 10)\n",
    "ax.axis('square') #设置子图的纵横比，使得x轴和y轴的单位长度相等，形成一个正方形的区域\n",
    "ax.set_xlim([-5.1,5.1]) #第一个子图的x轴范围是-5.1到5.1\n",
    "ax.set_ylim([-0.1,5.1]) #第一个子图的y轴范围是-0.1到5.1\n",
    "\n",
    "ax = plt.subplot(gs1[0, 1]) #在gs1[0,1]指定的位置，也就是网格的第一行第二列，创建了一个子图，并将返回的axes对象赋值给ax。\n",
    "#绘制了两条线，一条表示精确值，一条表示预测值\n",
    "ax.plot(x,Exact_h[:,100],'b-', linewidth = 2, label = 'Exact')        #第一个参数表示x轴上的坐标；第二个参数表示y轴上的坐标；第三个参数b-表示蓝色的实线；linewidth表示线的宽度为2；label表示线的标签\n",
    "ax.plot(x,H_pred[100,:],'r--', linewidth = 2, label = 'Prediction')   #同上\n",
    "ax.set_xlabel('$x$') #设置子图的x轴的标签为x\n",
    "ax.set_ylabel('$|h(t,x)|$') #设置子图的y轴的标签为|h(t,x)|\n",
    "ax.axis('square')   #设置子图的纵横比，使得x轴和y轴的单位长度相等，形成一个正方形的区域\n",
    "ax.set_xlim([-5.1,5.1])     #第二个子图的x轴范围是-5.1到5.1\n",
    "ax.set_ylim([-0.1,5.1])     #第二个子图的y轴范围是-0.1到5.1\n",
    "ax.set_title('$t = %.2f$' % (t[100]), fontsize = 10)        #设置第二个子图的标题，标题随着t的变化而变化，字体大小为10\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.8), ncol=5, frameon=False)  #设置第二个子图的图例，loc='upper center'表示图例的位置是上方中心，bbox_to_anchor=(0.5,-0.8)表示图例的中心位置是在子图的中间偏下方0.8的位置，ncol=5表示图例的列数是5，frameon=False表示不显示图例的边框\n",
    "\n",
    "ax = plt.subplot(gs1[0, 2]) #在gs1[0,2]指定的位置，也就是网格的第一行第三列，创建了一个子图，并将返回的axes对象赋值给ax。\n",
    "ax.plot(x,Exact_h[:,125], 'b-', linewidth = 2, label = 'Exact')        #第一个参数表示x轴上的坐标；第二个参数表示y轴上的坐标；第三个参数b-表示蓝色的实线；linewidth表示线的宽度为2；label表示线的标签\n",
    "ax.plot(x,H_pred[125,:], 'r--', linewidth = 2, label = 'Prediction')    #同上\n",
    "ax.set_xlabel('$x$') #设置子图的x轴的标签为x\n",
    "ax.set_ylabel('$|h(t,x)|$') #设置子图的y轴的标签为|h(t,x)|\n",
    "ax.axis('square')    #设置子图的纵横比，使得x轴和y轴的单位长度相等，形成一个正方形的区域\n",
    "ax.set_xlim([-5.1,5.1])    #第三个子图的x轴范围是-5.1到5.1\n",
    "ax.set_ylim([-0.1,5.1])    #第三个子图的y轴范围是-0.1到5.1\n",
    "ax.set_title('$t = %.2f$' % (t[125]), fontsize = 10)    #设置第三个子图的标题，标题随着t的变化而变化，字体大小为10\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
