{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries, set the gpu and random seed\n",
    "\n",
    "#下面这行代码，是为了把自己编写的代码文件当作一共模块导入，这里是把Utilities文件夹中的plotting.py文件当作python的模块导入，对应的是下面的from plotting import newfig, savefig。路径要随着不同设备的系统做相应的修改\n",
    "import sys #导入sys模块。sys模块提供了一些变量和函数，用于与 Python解释器进行交互和访问。例如，sys.path 是一个 Python 在导入模块时会查找的路径列表，sys.argv 是一个包含命令行参数的列表，sys.exit() 函数可以用于退出 Python 程序。导入 sys 模块后，你就可以在你的程序中使用这些变量和函数了。\n",
    "sys.path.insert(0, '../../Utilities/') #在 Python的sys.path列表中插入一个新的路径。sys.path是一个 Python 在导入模块时会查找的路径列表。新的路径'../../Utilities/'相对于当前脚本的路径。当你尝试导入一个模块时，Python 会在 sys.path 列表中的路径下查找这个模块。通过在列表开始位置插入一个路径，你可以让 Python 优先在这个路径下查找模块。这在你需要导入自定义模块或者不在 Python 标准库中的模块时非常有用。\n",
    "\n",
    "import torch\n",
    "#collections是python一个内置模块，提供了一些有用的数据结构\n",
    "from collections import OrderedDict  #这个类是字典dict的一个子类，用于创建有序的字典。普通字典中元素顺序是无序的，在OrderedDict中元素的顺序是有序的，元素的顺序是按照它们被添加到字典中的顺序决定的。\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#下面的`scipy`是一个用于科学计算和技术计算的Python库，提供了许多高级的数学函数和便利的操作，包括数值积分、插值、优化、图像处理、统计等。\n",
    "import scipy.io #导入了scipy库中的io模块。scipy.io模块包含了一些用于文件输入/输出的函数，例如读取和写入.mat文件（MATLAB格式）。\n",
    "from scipy.interpolate import griddata#`scipy.interpolate`是`scipy`库中的一个模块，提供了许多插值工具，用于在给定的离散数据点之间进行插值和拟合。`griddata`是这个模块中的一个函数，用于在无规则的数据点上进行插值。它使用方法如下：\n",
    "#griddata(points, values, xi, method='linear', fill_value=nan, rescale=False)；\n",
    "   # `points`： ndarray of floats, shape (n, D)。表示数据点的坐标。`values`： ndarray of float or complex, shape (n,)。表示数据点的值。`xi`： ndarray of float, shape (M, D)。表示插值点的坐标。`method`： 插值方法，可选'linear'、'nearest'、'cubic'。默认为'linear'。\n",
    "   #`fill_value`： 在插值范围外的点的值。默认为nan。`rescale`： 是否对坐标点进行重标定，以提高数值稳定性。默认为False。\n",
    "   #返回值：ndarray，shape (M,) or (M, 1)。插值点的值。这个函数可以用于从散列的数据点创建一个连续的函数，这对于处理实际数据非常有用，因为实际数据通常是不规则或者不完整的。\n",
    "from pyDOE import lhs #`pyDOE`是一个Python库，用于设计实验。它提供了一些函数来生成各种设计，如因子设计、拉丁超立方设计等。`lhs`是库中的一个函数，全名为\"Latin Hypercube Sampling\"，拉丁超立方采样。这是一种统计方法，用于生成一个近似均匀分布的多维样本点集。它在参数空间中生成一个非常均匀的样本，这对于高维数值优化问题非常有用，因为它可以更好地覆盖参数空间。\n",
    "#`lhs`函数的基本用法如下：lhs(n, samples=1000):其中，`n`是参数的数量，`samples`是想生成的样本点的数量。这个函数会返回一个形状为(samples, n)的数组，每一行都是一个n维的样本点，所有的样本点都在[0, 1]范围内。\n",
    "from plotting_torch import newfig, savefig #从自定义的plotting.py文件中导入了newfig和savefig函数。这两个函数用于创建和保存图形。这两个函数的定义在plotting.py文件中\n",
    "from mpl_toolkits.mplot3d import Axes3D #`mpl_toolkits.mplot3d`是`matplotlib`库的一个模块，用于创建三维图形。`Axes3D`是`mpl_toolkits.mplot3d`模块中的一个类，用于创建一个三维的坐标轴。可以在这个坐标轴上绘制三维的图形，如曲线、曲面等。\n",
    "import time #一个内置模块，用于处理时间相关的操作。\n",
    "import matplotlib.gridspec as gridspec #是`matplotlib`库的一个模块，用于创建一个网格布局来放置子图。在`matplotlib`中可以创建一个或多个子图（subplot），每个子图都有自己的坐标轴，并可以在其中绘制图形。`gridspec`模块提供了一个灵活的方式来创建和放置子图。\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable #`mpl_toolkits.axes_grid1`是`matplotlib`库的一个模块，提供了一些高级的工具来控制matplotlib图形中的坐标轴和颜色条。`make_axes_locatable`是模块中的一个函数，用于创建一个可分割的坐标轴。可以在这个坐标轴的四个方向（上、下、左、右）添加新的坐标轴或颜色条。\n",
    "\n",
    "\n",
    "np.random.seed(1234) #这里有变化，仅需要设置numpy的随机数生成器的种子。设置随机数生成器的种子可以确保每次运行程序时，NumPy生成的随机数序列都是一样的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA support \n",
    "\n",
    "#设置pytorch的设备，代表了在哪里执行张量积算，设备可以是cpu或者cuda（gpu），并将这个做运算的设备对象存储在变量device中，后续张量计算回在这个设备上执行\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class DNN(torch.nn.Module):\n",
    "    #第一个方法\n",
    "    def __init__(self, layers):\n",
    "        super(DNN, self).__init__() #调用父类的__init__方法进行初始化\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1 #定义名为depth的属性，表示神经网络的深度，等于层数-1\n",
    "        \n",
    "        # set up layer order dict\n",
    "        self.activation = torch.nn.Tanh #设置激活函数为tanh\n",
    "         \n",
    "        layer_list = list() #定义一个空列表layer_list\n",
    "        for i in range(self.depth - 1):  #循环depth次\n",
    "            #将每一层（全连接层）添加到layer_list中\n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            #将每一层的激活函数添加到layer_list中\n",
    "            layer_list.append(('activation_%d' % i, self.activation()))\n",
    "\n",
    "        #循环结束后，将最后一层的线性变换添加到layer_list中（因为没有激活函数了）\n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        #然后使用OrderedDict将layer_list中的元素转换为有序字典\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers，将layerDict转换为一个神经网络模型，赋值给self.layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "    \n",
    "    #第二个方法，定义了模型的前向传播过程\n",
    "    def forward(self, x):  #接收输入x\n",
    "        out = self.layers(x) #将输入x传入神经网络模型self.layers中，得到输出out\n",
    "        return out #返回输出out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the class of PINN\n",
    "\n",
    "#定义了一个名为`PhysicsInformedNN'的类，用于实现基于物理的神经网络。\n",
    "class PhysicsInformedNN:\n",
    "    # Initialize the class\n",
    "    def __init__(self, x0, u0, v0, tb, X_f, layers, lb, ub): #这个类包含的第一个方法__init__，这是一个特殊的方法，也就是这个类的构造函数，用于初始化新创建的对象，接受了几个参数\n",
    "        \n",
    "        \n",
    "        #`numpy.concatenate`是一个用于数组拼接的函数。它可以将多个数组沿指定的轴拼接在一起，形成一个新的数组：numpy.concatenate((a1,a2, ...), axis=0)其中，`a1,a2, ...`是需要拼接的数组（只能接受数组或序列类型的参数，且参数形状必须相同），可以是多个。`axis`参数用于指定拼接的轴向，`axis=0`表示沿着第一个轴（即行）进行拼接，不指定`axis`参数默认值是0。\n",
    "        X0 = np.concatenate((x0,0*x0), 1) # [x0, 0],将x0和0*x0两个数组在第二个维度（即列）上进行了合并。0*x0会生成一个与x0形状相同，但所有元素都为0的数组。因此，X0的结果是一个新的二维数组，其中第一列是x0的值，第二列全为0\n",
    "        X_lb = np.concatenate((0*tb+lb[0],tb), 1) # [lb[0], tb],将0*tb+lb[0]和tb两个数组在第二个维度（即列）上进行了合并。0*tb+lb[0]会生成一个与tb形状相同，但所有元素都为lb[0]的数组。因此，X_lb的结果是一个新的二维数组，其中第一列全为lb[0]的值，第二列是tb的值。\n",
    "        X_ub = np.concatenate((0*tb+ub[0],tb), 1) # [ub[0], tb],同上生成一个与tb形状相同，但所有元素都为ub[0]的数组。因此，X_ub的结果是一个新的二维数组，其中第一列全为ub[0]的值，第二列是tb的值\n",
    "        \n",
    "        #Python使用self关键字来表示类的实例。当在类的方法中定义一个变量时，例如lb和ub，这些变量只在该方法内部可见，也就是说它们的作用域仅限于该方法。当方法执行完毕后，这些变量就会被销毁，无法在其他方法中访问它们。但如果希望在类的其他方法中也能访问这些变量就需要将它们保存为类的实例属性。这就是self.lb和self.ub的作用。\n",
    "            #通过将lb和ub赋值给self.lb和self.ub，就可以在类的其他方法中通过self.lb和self.ub来访问这些值。总的来说，self.lb和self.ub是类的实例属性，它们的作用域是整个类，而不仅仅是定义它们的方法。\n",
    "        self.lb = torch.tensor(lb).float().to(device) #将传入的lb和ub参数的值存储在实例中，以便后续使用。这样可以在类的其他方法中通过self.lb和self.ub来访问这些值。\n",
    "        self.ub = torch.tensor(ub).float().to(device)\n",
    "\n",
    "\n",
    "        self.x0 = torch.tensor(X0[:,0:1], requires_grad=True).float().to(device) #将X0的第一列赋值给self.x0（:表示取所有行,0：1实际上表示取第一列，因为python是左闭右开的）,将X0的第二列赋值给self.t0。这样可以在类的其他方法中通过self.x0和self.t0来访问这些值。\n",
    "        self.t0 = torch.tensor(X0[:,1:2], requires_grad=True).float().to(device) #将x0的第二列赋值给self.t0\n",
    "\n",
    "        self.x_lb = torch.tensor(X_lb[:,0:1], requires_grad=True).float().to(device) #将X_lb的第一列赋值给self.x_lb\n",
    "        self.t_lb = torch.tensor(X_lb[:,1:2], requires_grad=True).float().to(device) #将X_lb的第二列赋值给self.t_lb\n",
    "\n",
    "        self.x_ub = torch.tensor(X_ub[:,0:1], requires_grad=True).float().to(device) #将X_ub的第一列赋值给self.x_ub\n",
    "        self.t_ub = torch.tensor(X_ub[:,0:1], requires_grad=True).float().to(device) #将X_ub的第二列赋值给self.t_ub\n",
    "        \n",
    "        self.x_f = torch.tensor(X_f[:,0:1], requires_grad=True).float().to(device) #将X_f的第一列赋值给self.x_f\n",
    "        self.t_f = torch.tensor(X_f[:,1:2], requires_grad=True).float().to(device) #将X_f的第二列赋值给self.t_f\n",
    "        \n",
    "        self.u0 = torch.tensor(u0).float().to(device) #将传入的u0和v0参数的值存储在实例中，以便后续使用。这样可以在类的其他方法中通过self.u0和self.v0来访问这些值。\n",
    "        self.v0 = torch.tensor(v0).float().to(device)\n",
    "        \n",
    "        # Initialize NNs \n",
    "        self.layers = layers #将传入的layers参数的值存储在实例中，以便后续使用。这样可以在类的其他方法中通过self.layers来访问这些值。\n",
    "        \n",
    "        \n",
    "        # deep neural networks\n",
    "        self.dnn = DNN(layers).to(device) #创建一个DNN类的实例，传入layers参数来实现神经网络的初始化，然后将这个实例移动到指定的设备上\n",
    "\n",
    "\n",
    "\n",
    "        # optimizers: using the same settings，这里是使用pytorch库进行优化的部分\n",
    "        #创建优化器optimizer，使用LBFGS算法，具体每个参数意义见下方\n",
    "        self.optimizer = torch.optim.LBFGS(\n",
    "            self.dnn.parameters(), #要优化的参数，这里返回的是一个生成器，包含了self.dnn中的所有参数（神经网络权重、偏置以及两个新加的变量）\n",
    "            lr=1.0,  #学习率设置为1\n",
    "            max_iter=50000,  #最大迭代次数为50000\n",
    "            max_eval=50000,  #最大评估次数为50000\n",
    "            history_size=50, #历史大小为50，即用于计算Hessian矩阵近似的最近几步的信息\n",
    "            tolerance_grad=1e-5,  #优化的第一个停止条件，当梯度的L2范数小于1e-5时停止优化\n",
    "            tolerance_change=1.0 * np.finfo(float).eps, #优化的第二个停止条件，当优化的目标函数值的变化小于1.0 * np.finfo(float).eps时停止优化\n",
    "            line_search_fn=\"strong_wolfe\"       # 制定了用于一维搜索的方法，这里表示用强Wolfe条件\n",
    "        )\n",
    "        #创建第二个优化器，括号内为要优化的参数，使用Adam优化方法\n",
    "        self.optimizer_Adam = torch.optim.Adam(self.dnn.parameters())\n",
    "                \n",
    "\n",
    "        self.iter = 0 #记录迭代次数 \n",
    "\n",
    "        self.loss_value = [] #创建一个空列表，用于存储损失值\n",
    "\n",
    "    \n",
    "    \n",
    "    #pytorch中\n",
    "    #定义了一个名为net_u的函数/方法，用于计算神经网络的输出。这个方法接受两个参数，分别是x和t，其中x是输入数据，t是时间数据。最后返回神经网络的输出。     \n",
    "    def net_uv(self, x, t):  \n",
    "        uv = self.dnn(torch.cat([x, t], dim=1))  #（第一个参数将输入的两个参数x和t在第二个维度（列）上进行拼接，形成一个新的张量）调用DNN，根据两个参数权重和偏置，以及新得到的张量，计算神经网络的输出u\n",
    "        #将uv（是一个二维张量）的第一列赋值给u，第二列赋值给v\n",
    "        u=uv[:,0:1]\n",
    "        v=uv[:,1:2]\n",
    "\n",
    "        u_x = torch.autograd.grad(\n",
    "            u, x, \n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        v_x = torch.autograd.grad(\n",
    "            v, x, \n",
    "            grad_outputs=torch.ones_like(v),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "\n",
    "        return u,v,u_x,v_x #返回神经网络的输出u和v，以及u关于x的梯度u_x和v关于x的梯度v_x\n",
    "\n",
    "\n",
    "    #定义了一个名为net_f的函数/方法，用于计算论文中的f。这个方法接受两个参数，分别是x和t，其中x是输入数据，t是时间数据。最后返回计算得到的f。\n",
    "    def net_f_uv(self, x, t):\n",
    "        \"\"\" The pytorch autograd version of calculating residual \"\"\"\n",
    "\n",
    "        u,v,u_x,v_x=self.net_uv(x,t) #调用上面的函数/方法，计算神经网络的输出（两个）以及输出关于输入x的梯度（两个）\n",
    "        \n",
    "        #计算u关于t的梯度，也就是u关于t的导数，这里使用了pytorch的自动求导功能\n",
    "        u_t = torch.autograd.grad(\n",
    "            u, t,  #输入的张量，要计算u关于t的导数\n",
    "            grad_outputs=torch.ones_like(u), #生成一个与u形状相同，所有元素均为1的张量，这个参数用于指定向量-雅可比积的像两部分\n",
    "            retain_graph=True, #表示计算完梯度之后保留计算图若需要多次计算梯度，则需要设置改参数为True\n",
    "            create_graph=True #创建梯度的计算图，使我们能够计算高阶导数\n",
    "        )[0] #这个函数的返回值是一个元组，其中包含了每个输入张量的梯度。这里只关心第一个输入张量u的梯度，所以我们使用[0]来获取这个梯度。？？？？又说只有一个梯度\n",
    "        v_t = torch.autograd.grad(\n",
    "            v, t, \n",
    "            grad_outputs=torch.ones_like(v),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        u_xx = torch.autograd.grad(\n",
    "            u_x, x, \n",
    "            grad_outputs=torch.ones_like(u_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        v_xx = torch.autograd.grad(\n",
    "            v_x, x, \n",
    "            grad_outputs=torch.ones_like(v_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        f_u=u_t+0.5*v_xx+(u**2+v**2)*v    #计算f_u,定义见论文\n",
    "        f_v=v_t-0.5*u_xx-(u**2+v**2)*u   #计算f_v,定义见论文\n",
    "        return f_u, f_v  #返回计算得到的f_u和f_v\n",
    "\n",
    "\n",
    "    def loss_func(self):\n",
    "        self.optimizer.zero_grad() #清除之前计算的梯度（在PyTorch中，梯度会累积，所以在每次新的优化迭代之前，我们需要清除之前的梯度）\n",
    "\n",
    "        u0_pred, v0_pred, _ , _ = self.net_uv(self.x0, self.t0) #是调用net_uv函数,将self.x0_tf和self.t0_tf作为参数传入,然后将返回的前两个结果赋值给self.u0_pred和self.v0_pred。后两个_是Python惯用法，表示不关心net_uv函数返回的后两个结果。\n",
    "        u_lb_pred, v_lb_pred, u_x_lb_pred, v_x_lb_pred = self.net_uv(self.x_lb, self.t_lb) #同上，不过这里函数返回的后两个结果会赋值给self.u_x_lb_pred和self.v_x_lb_pred。\n",
    "        u_ub_pred, v_ub_pred, u_x_ub_pred, v_x_ub_pred = self.net_uv(self.x_ub, self.t_ub) #同上\n",
    "        f_u_pred, f_v_pred = self.net_f_uv(self.x_f, self.t_f) #调用net_f_uv函数,将self.x_f_tf和self.t_f_tf作为参数传入,然后将返回的结果赋值给self.f_u_pred和self.f_v_pred。\n",
    "\n",
    "        loss = torch.mean((self.u0 - u0_pred) ** 2)  + \\\n",
    "                    torch.mean((self.v0 - v0_pred) ** 2) + \\\n",
    "                    torch.mean((u_lb_pred - u_ub_pred) ** 2) + \\\n",
    "                    torch.mean((v_lb_pred - v_ub_pred) ** 2) + \\\n",
    "                    torch.mean((u_x_lb_pred - u_x_ub_pred) ** 2) + \\\n",
    "                    torch.mean((v_x_lb_pred - v_x_ub_pred) ** 2) + \\\n",
    "                    torch.mean(f_u_pred ** 2) + \\\n",
    "                    torch.mean(f_v_pred ** 2)\n",
    "        loss.backward() #被调用以计算损失函数关于神经网络参数的梯度。这个梯度将被用于优化器来更新神经网络参数\n",
    "        \n",
    "        self.iter += 1 #每调用一次损失函数，迭代次数加1\n",
    "\n",
    "\n",
    "        self.loss_value.append(loss) #将计算得到的loss值添加到self.loss_value列表中\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        if self.iter % 100 == 0:\n",
    "            print(\n",
    "                'Iter %d, Loss: %e' % \n",
    "                (\n",
    "                    self.iter,\n",
    "                    loss#这里使用了detach()方法，将lambda_2从计算图中分离出来，这样就不会计算lambda_2的梯度，只是将lambda_2的值返回？？？why\n",
    "                ) #每100次迭代，打印一次迭代次数、总的loss、loss_u和loss_f\n",
    "            )\n",
    "        return loss #返回loss\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    #定义了一个名为train的函数/方法，用于训练神经网络。这个方法接受一个参数nIter，表示训练的迭代次数。\n",
    "    def train(self, nIter):\n",
    "        self.dnn.train()#将神经网络设置为训练模式而不是评估模式\n",
    "\n",
    "        #先使用Adam优化器优化nIter次\n",
    "        for epoch in range(nIter):\n",
    "            u0_pred, v0_pred, _ , _ = self.net_uv(self.x0, self.t0) #是调用net_uv函数,将self.x0_tf和self.t0_tf作为参数传入,然后将返回的前两个结果赋值给self.u0_pred和self.v0_pred。后两个_是Python惯用法，表示不关心net_uv函数返回的后两个结果。\n",
    "            u_lb_pred, v_lb_pred, u_x_lb_pred, v_x_lb_pred = self.net_uv(self.x_lb, self.t_lb) #同上，不过这里函数返回的后两个结果会赋值给self.u_x_lb_pred和self.v_x_lb_pred。\n",
    "            u_ub_pred, v_ub_pred, u_x_ub_pred, v_x_ub_pred = self.net_uv(self.x_ub, self.t_ub) #同上\n",
    "            f_u_pred, f_v_pred = self.net_f_uv(self.x_f, self.t_f) #调用net_f_uv函数,将self.x_f_tf和self.t_f_tf作为参数传入,然后将返回的结果赋值给self.f_u_pred和self.f_v_pred。\n",
    "\n",
    "            loss = torch.mean((self.u0 - u0_pred) ** 2)  + \\\n",
    "                    torch.mean((self.v0 - v0_pred) ** 2) + \\\n",
    "                    torch.mean((u_lb_pred - u_ub_pred) ** 2) + \\\n",
    "                    torch.mean((v_lb_pred - v_ub_pred) ** 2) + \\\n",
    "                    torch.mean((u_x_lb_pred - u_x_ub_pred) ** 2) + \\\n",
    "                    torch.mean((v_x_lb_pred - v_x_ub_pred) ** 2) + \\\n",
    "                    torch.mean(f_u_pred ** 2) + \\\n",
    "                    torch.mean(f_v_pred ** 2)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            self.optimizer_Adam.zero_grad() #清除该优化器之前计算的梯度（在PyTorch中，梯度会累积，所以在每次新的优化迭代之前，我们需要清除之前的梯度）\n",
    "            loss.backward() #被调用以计算损失函数关于神经网络参数的梯度。这个梯度将被用于优化器来更新神经网络参数\n",
    "            self.optimizer_Adam.step()  #使用之前的优化器self.optimizer_Adam，调用step方法(执行一步优化算法)，传入损失函数self.loss_func，进行优化\n",
    "\n",
    "\n",
    "\n",
    "            self.loss_value.append(loss) #将计算得到的loss值添加到self.loss_value列表中\n",
    "\n",
    "\n",
    "            \n",
    "            if epoch % 100 == 0:\n",
    "                print(\n",
    "                    'It: %d, Loss: %.3e' % \n",
    "                    (\n",
    "                        epoch, \n",
    "                        loss\n",
    "                    ) #每100次迭代，打印一次迭代次数、总的loss\n",
    "                )\n",
    "\n",
    "\n",
    "        # Backward and optimize，用LBFGS优化器进行进一步优化\n",
    "        self.optimizer.step(self.loss_func)  #使用之前的优化器self.optimizer，调用step方法(执行一步优化算法)，传入计算损失函数的方法self.loss_func，进行优化   \n",
    "\n",
    "                                    \n",
    "    #定义了一个名为predict的函数/方法，用于预测神经网络的输出。这个方法接受一个参数X_star，表示输入数据。最后返回预测的两个输出和两个输出的梯度。\n",
    "    def predict(self, X):\n",
    "        x = torch.tensor(X[:, 0:1], requires_grad=True).float().to(device) #从输入中得到x和t（第一列和第二列），是张量，需要计算梯度，转换为浮点数类型，并将张量移动到指定设备上\n",
    "        t = torch.tensor(X[:, 1:2], requires_grad=True).float().to(device)\n",
    "\n",
    "        self.dnn.eval() #将神经网络切换为评估模式\n",
    "        u, v, _, _ = self.net_uv(x, t) #调用之前定义的函数得到神经网络的输出u,以及f\n",
    "        f_u, f_v = self.net_f_uv(x, t) \n",
    "\n",
    "        u = u.detach().cpu().numpy() #将张量u和v先从计算图中分离出来，然后转换为numpy数组，最后将这个数组移动到cpu上\n",
    "        v = v.detach().cpu().numpy()\n",
    "        f_u = f_u.detach().cpu().numpy()\n",
    "        f_v = f_v.detach().cpu().numpy()\n",
    "        return u, v, f_u, f_v \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0, Loss: 9.899e-01\n",
      "It: 100, Loss: 9.103e-02\n",
      "It: 200, Loss: 6.458e-02\n",
      "It: 300, Loss: 6.155e-02\n",
      "It: 400, Loss: 5.794e-02\n",
      "It: 500, Loss: 5.496e-02\n",
      "It: 600, Loss: 5.253e-02\n",
      "It: 700, Loss: 6.653e-02\n",
      "It: 800, Loss: 4.947e-02\n",
      "It: 900, Loss: 4.795e-02\n",
      "It: 1000, Loss: 4.551e-02\n",
      "It: 1100, Loss: 4.366e-02\n",
      "It: 1200, Loss: 4.173e-02\n",
      "It: 1300, Loss: 3.964e-02\n",
      "It: 1400, Loss: 3.806e-02\n",
      "It: 1500, Loss: 3.669e-02\n",
      "It: 1600, Loss: 3.682e-02\n",
      "It: 1700, Loss: 3.462e-02\n",
      "It: 1800, Loss: 4.336e-02\n",
      "It: 1900, Loss: 3.151e-02\n",
      "It: 2000, Loss: 3.071e-02\n",
      "It: 2100, Loss: 3.626e-02\n",
      "It: 2200, Loss: 2.847e-02\n",
      "It: 2300, Loss: 2.764e-02\n",
      "It: 2400, Loss: 2.916e-02\n",
      "It: 2500, Loss: 3.570e-02\n",
      "It: 2600, Loss: 2.459e-02\n",
      "It: 2700, Loss: 3.364e-02\n",
      "It: 2800, Loss: 2.278e-02\n",
      "It: 2900, Loss: 2.201e-02\n",
      "It: 3000, Loss: 2.111e-02\n",
      "It: 3100, Loss: 2.045e-02\n",
      "It: 3200, Loss: 1.959e-02\n",
      "It: 3300, Loss: 1.948e-02\n",
      "It: 3400, Loss: 1.927e-02\n",
      "It: 3500, Loss: 1.769e-02\n",
      "It: 3600, Loss: 1.739e-02\n",
      "It: 3700, Loss: 1.632e-02\n",
      "It: 3800, Loss: 1.579e-02\n",
      "It: 3900, Loss: 1.844e-02\n",
      "It: 4000, Loss: 1.464e-02\n",
      "It: 4100, Loss: 1.423e-02\n",
      "It: 4200, Loss: 1.360e-02\n",
      "It: 4300, Loss: 1.328e-02\n",
      "It: 4400, Loss: 1.274e-02\n",
      "It: 4500, Loss: 1.280e-02\n",
      "It: 4600, Loss: 1.188e-02\n",
      "It: 4700, Loss: 1.165e-02\n",
      "It: 4800, Loss: 1.133e-02\n",
      "It: 4900, Loss: 1.362e-02\n",
      "It: 5000, Loss: 1.049e-02\n",
      "It: 5100, Loss: 1.107e-02\n",
      "It: 5200, Loss: 9.941e-03\n",
      "It: 5300, Loss: 9.833e-03\n",
      "It: 5400, Loss: 1.006e-02\n",
      "It: 5500, Loss: 1.594e-02\n",
      "It: 5600, Loss: 8.777e-03\n",
      "It: 5700, Loss: 8.697e-03\n",
      "It: 5800, Loss: 9.493e-03\n",
      "It: 5900, Loss: 7.435e-02\n",
      "It: 6000, Loss: 7.855e-03\n",
      "It: 6100, Loss: 3.494e-02\n",
      "It: 6200, Loss: 7.483e-03\n",
      "It: 6300, Loss: 9.633e-03\n",
      "It: 6400, Loss: 7.259e-03\n",
      "It: 6500, Loss: 8.172e-03\n",
      "It: 6600, Loss: 3.129e-02\n",
      "It: 6700, Loss: 8.614e-03\n",
      "It: 6800, Loss: 6.850e-03\n",
      "It: 6900, Loss: 6.280e-03\n",
      "It: 7000, Loss: 6.317e-03\n",
      "It: 7100, Loss: 7.410e-03\n",
      "It: 7200, Loss: 1.363e-02\n",
      "It: 7300, Loss: 7.932e-03\n",
      "It: 7400, Loss: 1.339e-02\n",
      "It: 7500, Loss: 3.797e-02\n",
      "It: 7600, Loss: 5.241e-03\n",
      "It: 7700, Loss: 3.037e-02\n",
      "It: 7800, Loss: 5.002e-03\n",
      "It: 7900, Loss: 5.064e-03\n",
      "It: 8000, Loss: 5.475e-03\n",
      "It: 8100, Loss: 5.354e-03\n",
      "It: 8200, Loss: 4.563e-03\n",
      "It: 8300, Loss: 4.414e-03\n",
      "It: 8400, Loss: 4.295e-03\n",
      "It: 8500, Loss: 4.251e-03\n",
      "It: 8600, Loss: 4.160e-03\n",
      "It: 8700, Loss: 4.434e-03\n",
      "It: 8800, Loss: 4.218e-03\n",
      "It: 8900, Loss: 5.620e-03\n",
      "It: 9000, Loss: 2.562e-02\n",
      "It: 9100, Loss: 8.980e-03\n",
      "It: 9200, Loss: 2.045e-02\n",
      "It: 9300, Loss: 3.701e-03\n",
      "It: 9400, Loss: 3.367e-03\n",
      "It: 9500, Loss: 3.421e-03\n",
      "It: 9600, Loss: 3.314e-03\n",
      "It: 9700, Loss: 3.243e-03\n",
      "It: 9800, Loss: 3.720e-03\n",
      "It: 9900, Loss: 4.556e-03\n",
      "It: 10000, Loss: 5.384e-02\n",
      "It: 10100, Loss: 2.897e-03\n",
      "It: 10200, Loss: 2.927e-03\n",
      "It: 10300, Loss: 3.134e-03\n",
      "It: 10400, Loss: 3.420e-03\n",
      "It: 10500, Loss: 5.431e-03\n",
      "It: 10600, Loss: 2.898e-02\n",
      "It: 10700, Loss: 2.525e-03\n",
      "It: 10800, Loss: 2.580e-03\n",
      "It: 10900, Loss: 2.419e-03\n",
      "It: 11000, Loss: 1.226e-02\n",
      "It: 11100, Loss: 2.113e-02\n",
      "It: 11200, Loss: 2.793e-03\n",
      "It: 11300, Loss: 9.602e-03\n",
      "It: 11400, Loss: 3.195e-03\n",
      "It: 11500, Loss: 2.448e-03\n",
      "It: 11600, Loss: 2.241e-03\n",
      "It: 11700, Loss: 2.286e-03\n",
      "It: 11800, Loss: 2.197e-03\n",
      "It: 11900, Loss: 4.518e-03\n",
      "It: 12000, Loss: 1.081e-02\n",
      "It: 12100, Loss: 5.899e-03\n",
      "It: 12200, Loss: 5.868e-03\n",
      "It: 12300, Loss: 1.915e-03\n",
      "It: 12400, Loss: 1.819e-03\n",
      "It: 12500, Loss: 1.795e-03\n",
      "It: 12600, Loss: 2.021e-03\n",
      "It: 12700, Loss: 2.860e-03\n",
      "It: 12800, Loss: 3.672e-02\n",
      "It: 12900, Loss: 1.641e-03\n",
      "It: 13000, Loss: 2.306e-03\n",
      "It: 13100, Loss: 1.729e-03\n",
      "It: 13200, Loss: 2.269e-03\n",
      "It: 13300, Loss: 1.740e-03\n",
      "It: 13400, Loss: 2.125e-03\n",
      "It: 13500, Loss: 3.503e-03\n",
      "It: 13600, Loss: 1.761e-03\n",
      "It: 13700, Loss: 1.587e-03\n",
      "It: 13800, Loss: 1.416e-03\n",
      "It: 13900, Loss: 1.451e-03\n",
      "It: 14000, Loss: 1.343e-03\n",
      "It: 14100, Loss: 2.200e-03\n",
      "It: 14200, Loss: 1.487e-03\n",
      "It: 14300, Loss: 1.324e-03\n",
      "It: 14400, Loss: 1.403e-03\n",
      "It: 14500, Loss: 1.470e-03\n",
      "It: 14600, Loss: 1.297e-03\n",
      "It: 14700, Loss: 5.321e-03\n",
      "It: 14800, Loss: 9.890e-03\n",
      "It: 14900, Loss: 2.373e-02\n",
      "It: 15000, Loss: 1.809e-03\n",
      "It: 15100, Loss: 1.525e-03\n",
      "It: 15200, Loss: 2.047e-02\n",
      "It: 15300, Loss: 1.075e-03\n",
      "It: 15400, Loss: 5.490e-03\n",
      "It: 15500, Loss: 1.769e-03\n",
      "It: 15600, Loss: 1.020e-03\n",
      "It: 15700, Loss: 1.022e-03\n",
      "It: 15800, Loss: 1.414e-03\n",
      "It: 15900, Loss: 9.772e-04\n",
      "It: 16000, Loss: 9.769e-04\n",
      "It: 16100, Loss: 1.081e-02\n",
      "It: 16200, Loss: 1.156e-03\n",
      "It: 16300, Loss: 1.066e-03\n",
      "It: 16400, Loss: 9.002e-04\n",
      "It: 16500, Loss: 1.001e-03\n",
      "It: 16600, Loss: 9.247e-04\n",
      "It: 16700, Loss: 8.629e-04\n",
      "It: 16800, Loss: 8.573e-04\n",
      "It: 16900, Loss: 1.197e-03\n",
      "It: 17000, Loss: 1.077e-03\n",
      "It: 17100, Loss: 1.047e-03\n",
      "It: 17200, Loss: 1.523e-02\n",
      "It: 17300, Loss: 1.633e-03\n",
      "It: 17400, Loss: 7.556e-04\n",
      "It: 17500, Loss: 1.024e-03\n",
      "It: 17600, Loss: 7.891e-04\n",
      "It: 17700, Loss: 7.644e-04\n",
      "It: 17800, Loss: 7.513e-04\n",
      "It: 17900, Loss: 8.090e-04\n",
      "It: 18000, Loss: 8.064e-03\n",
      "It: 18100, Loss: 4.120e-03\n",
      "It: 18200, Loss: 4.559e-03\n",
      "It: 18300, Loss: 6.716e-04\n",
      "It: 18400, Loss: 1.180e-03\n",
      "It: 18500, Loss: 7.177e-04\n",
      "It: 18600, Loss: 1.241e-03\n",
      "It: 18700, Loss: 6.460e-04\n",
      "It: 18800, Loss: 5.000e-03\n",
      "It: 18900, Loss: 6.144e-04\n",
      "It: 19000, Loss: 7.002e-04\n",
      "It: 19100, Loss: 6.274e-04\n",
      "It: 19200, Loss: 6.429e-04\n",
      "It: 19300, Loss: 8.101e-04\n",
      "It: 19400, Loss: 8.338e-04\n",
      "It: 19500, Loss: 7.620e-04\n",
      "It: 19600, Loss: 6.498e-04\n",
      "It: 19700, Loss: 2.257e-03\n",
      "It: 19800, Loss: 3.190e-03\n",
      "It: 19900, Loss: 2.517e-03\n",
      "It: 20000, Loss: 1.844e-03\n",
      "It: 20100, Loss: 7.198e-04\n",
      "It: 20200, Loss: 5.192e-04\n",
      "It: 20300, Loss: 6.109e-04\n",
      "It: 20400, Loss: 1.337e-03\n",
      "It: 20500, Loss: 5.164e-04\n",
      "It: 20600, Loss: 1.600e-03\n",
      "It: 20700, Loss: 8.373e-04\n",
      "It: 20800, Loss: 5.860e-04\n",
      "It: 20900, Loss: 5.052e-04\n",
      "It: 21000, Loss: 4.687e-04\n",
      "It: 21100, Loss: 3.228e-03\n",
      "It: 21200, Loss: 9.407e-04\n",
      "It: 21300, Loss: 4.551e-04\n",
      "It: 21400, Loss: 4.887e-04\n",
      "It: 21500, Loss: 4.403e-04\n",
      "It: 21600, Loss: 4.420e-04\n",
      "It: 21700, Loss: 7.203e-04\n",
      "It: 21800, Loss: 1.161e-03\n",
      "It: 21900, Loss: 5.247e-03\n",
      "It: 22000, Loss: 3.160e-03\n",
      "It: 22100, Loss: 4.416e-04\n",
      "It: 22200, Loss: 4.503e-04\n",
      "It: 22300, Loss: 1.085e-03\n",
      "It: 22400, Loss: 5.891e-04\n",
      "It: 22500, Loss: 4.018e-04\n",
      "It: 22600, Loss: 4.075e-04\n",
      "It: 22700, Loss: 3.849e-04\n",
      "It: 22800, Loss: 3.761e-04\n",
      "It: 22900, Loss: 5.712e-04\n",
      "It: 23000, Loss: 6.144e-04\n",
      "It: 23100, Loss: 4.605e-04\n",
      "It: 23200, Loss: 4.650e-03\n",
      "It: 23300, Loss: 6.504e-03\n",
      "It: 23400, Loss: 8.685e-04\n",
      "It: 23500, Loss: 4.088e-04\n",
      "It: 23600, Loss: 6.465e-04\n",
      "It: 23700, Loss: 1.041e-03\n",
      "It: 23800, Loss: 4.657e-04\n",
      "It: 23900, Loss: 3.306e-04\n",
      "It: 24000, Loss: 3.358e-04\n",
      "It: 24100, Loss: 3.560e-04\n",
      "It: 24200, Loss: 1.588e-03\n",
      "It: 24300, Loss: 3.243e-04\n",
      "It: 24400, Loss: 3.683e-04\n",
      "It: 24500, Loss: 3.647e-04\n",
      "It: 24600, Loss: 3.545e-04\n",
      "It: 24700, Loss: 3.028e-04\n",
      "It: 24800, Loss: 3.513e-04\n",
      "It: 24900, Loss: 2.183e-03\n",
      "It: 25000, Loss: 2.906e-04\n",
      "It: 25100, Loss: 3.190e-04\n",
      "It: 25200, Loss: 4.019e-04\n",
      "It: 25300, Loss: 4.472e-04\n",
      "It: 25400, Loss: 2.869e-04\n",
      "It: 25500, Loss: 3.063e-04\n",
      "It: 25600, Loss: 3.054e-04\n",
      "It: 25700, Loss: 9.083e-04\n",
      "It: 25800, Loss: 8.619e-03\n",
      "It: 25900, Loss: 4.461e-04\n",
      "It: 26000, Loss: 2.875e-03\n",
      "It: 26100, Loss: 5.313e-03\n",
      "It: 26200, Loss: 9.909e-03\n",
      "It: 26300, Loss: 2.780e-04\n",
      "It: 26400, Loss: 2.650e-04\n",
      "It: 26500, Loss: 2.846e-04\n",
      "It: 26600, Loss: 3.542e-04\n",
      "It: 26700, Loss: 3.023e-04\n",
      "It: 26800, Loss: 5.919e-04\n",
      "It: 26900, Loss: 3.635e-04\n",
      "It: 27000, Loss: 3.342e-04\n",
      "It: 27100, Loss: 1.185e-02\n",
      "It: 27200, Loss: 2.501e-04\n",
      "It: 27300, Loss: 2.402e-04\n",
      "It: 27400, Loss: 2.522e-04\n",
      "It: 27500, Loss: 2.533e-04\n",
      "It: 27600, Loss: 6.049e-03\n",
      "It: 27700, Loss: 1.719e-03\n",
      "It: 27800, Loss: 7.169e-04\n",
      "It: 27900, Loss: 2.574e-04\n",
      "It: 28000, Loss: 4.486e-04\n",
      "It: 28100, Loss: 4.398e-04\n",
      "It: 28200, Loss: 4.389e-03\n",
      "It: 28300, Loss: 3.927e-04\n",
      "It: 28400, Loss: 2.685e-04\n",
      "It: 28500, Loss: 5.730e-03\n",
      "It: 28600, Loss: 1.941e-03\n",
      "It: 28700, Loss: 1.551e-03\n",
      "It: 28800, Loss: 3.699e-03\n",
      "It: 28900, Loss: 5.347e-04\n",
      "It: 29000, Loss: 3.599e-03\n",
      "It: 29100, Loss: 4.308e-04\n",
      "It: 29200, Loss: 2.081e-04\n",
      "It: 29300, Loss: 1.004e-03\n",
      "It: 29400, Loss: 3.186e-04\n",
      "It: 29500, Loss: 2.430e-04\n",
      "It: 29600, Loss: 2.074e-04\n",
      "It: 29700, Loss: 2.338e-04\n",
      "It: 29800, Loss: 2.069e-04\n",
      "It: 29900, Loss: 1.550e-03\n",
      "It: 30000, Loss: 1.291e-03\n",
      "It: 30100, Loss: 4.993e-03\n",
      "It: 30200, Loss: 1.214e-03\n",
      "It: 30300, Loss: 2.160e-03\n",
      "It: 30400, Loss: 2.680e-03\n",
      "It: 30500, Loss: 6.337e-04\n",
      "It: 30600, Loss: 1.521e-03\n",
      "It: 30700, Loss: 2.798e-04\n",
      "It: 30800, Loss: 2.990e-04\n",
      "It: 30900, Loss: 1.110e-03\n",
      "It: 31000, Loss: 2.872e-04\n",
      "It: 31100, Loss: 1.312e-03\n",
      "It: 31200, Loss: 3.085e-04\n",
      "It: 31300, Loss: 1.956e-04\n",
      "It: 31400, Loss: 5.175e-04\n",
      "It: 31500, Loss: 5.458e-04\n",
      "It: 31600, Loss: 1.937e-04\n",
      "It: 31700, Loss: 2.470e-04\n",
      "It: 31800, Loss: 1.902e-04\n",
      "It: 31900, Loss: 1.216e-03\n",
      "It: 32000, Loss: 1.188e-03\n",
      "It: 32100, Loss: 1.144e-03\n",
      "It: 32200, Loss: 1.151e-03\n",
      "It: 32300, Loss: 1.609e-03\n",
      "It: 32400, Loss: 2.705e-04\n",
      "It: 32500, Loss: 1.935e-04\n",
      "It: 32600, Loss: 5.718e-04\n",
      "It: 32700, Loss: 4.421e-04\n",
      "It: 32800, Loss: 5.303e-04\n",
      "It: 32900, Loss: 2.484e-04\n",
      "It: 33000, Loss: 1.615e-04\n",
      "It: 33100, Loss: 1.776e-04\n",
      "It: 33200, Loss: 1.745e-04\n",
      "It: 33300, Loss: 3.177e-04\n",
      "It: 33400, Loss: 4.758e-04\n",
      "It: 33500, Loss: 4.876e-04\n",
      "It: 33600, Loss: 2.302e-04\n",
      "It: 33700, Loss: 2.887e-04\n",
      "It: 33800, Loss: 1.601e-03\n",
      "It: 33900, Loss: 1.539e-04\n",
      "It: 34000, Loss: 1.652e-04\n",
      "It: 34100, Loss: 1.544e-04\n",
      "It: 34200, Loss: 2.800e-04\n",
      "It: 34300, Loss: 2.390e-04\n",
      "It: 34400, Loss: 1.829e-04\n",
      "It: 34500, Loss: 1.565e-04\n",
      "It: 34600, Loss: 1.736e-04\n",
      "It: 34700, Loss: 2.487e-04\n",
      "It: 34800, Loss: 1.671e-04\n",
      "It: 34900, Loss: 4.496e-03\n",
      "It: 35000, Loss: 6.632e-04\n",
      "It: 35100, Loss: 9.408e-04\n",
      "It: 35200, Loss: 3.308e-03\n",
      "It: 35300, Loss: 2.646e-04\n",
      "It: 35400, Loss: 2.124e-04\n",
      "It: 35500, Loss: 2.035e-04\n",
      "It: 35600, Loss: 4.492e-03\n",
      "It: 35700, Loss: 3.974e-04\n",
      "It: 35800, Loss: 1.256e-03\n",
      "It: 35900, Loss: 3.643e-04\n",
      "It: 36000, Loss: 1.679e-04\n",
      "It: 36100, Loss: 1.092e-02\n",
      "It: 36200, Loss: 1.686e-03\n",
      "It: 36300, Loss: 1.847e-04\n",
      "It: 36400, Loss: 2.479e-03\n",
      "It: 36500, Loss: 2.419e-04\n",
      "It: 36600, Loss: 1.287e-03\n",
      "It: 36700, Loss: 1.470e-04\n",
      "It: 36800, Loss: 6.453e-04\n",
      "It: 36900, Loss: 9.257e-03\n",
      "It: 37000, Loss: 2.134e-04\n",
      "It: 37100, Loss: 1.331e-02\n",
      "It: 37200, Loss: 4.562e-04\n",
      "It: 37300, Loss: 1.101e-03\n",
      "It: 37400, Loss: 1.129e-02\n",
      "It: 37500, Loss: 1.377e-04\n",
      "It: 37600, Loss: 1.435e-04\n",
      "It: 37700, Loss: 1.304e-02\n",
      "It: 37800, Loss: 1.256e-04\n",
      "It: 37900, Loss: 1.470e-04\n",
      "It: 38000, Loss: 3.163e-03\n",
      "It: 38100, Loss: 1.674e-03\n",
      "It: 38200, Loss: 2.328e-03\n",
      "It: 38300, Loss: 1.648e-04\n",
      "It: 38400, Loss: 1.288e-04\n",
      "It: 38500, Loss: 4.591e-03\n",
      "It: 38600, Loss: 6.643e-04\n",
      "It: 38700, Loss: 1.716e-04\n",
      "It: 38800, Loss: 8.998e-04\n",
      "It: 38900, Loss: 1.339e-04\n",
      "It: 39000, Loss: 1.361e-04\n",
      "It: 39100, Loss: 2.073e-04\n",
      "It: 39200, Loss: 2.470e-03\n",
      "It: 39300, Loss: 2.272e-04\n",
      "It: 39400, Loss: 1.701e-04\n",
      "It: 39500, Loss: 6.138e-04\n",
      "It: 39600, Loss: 1.863e-03\n",
      "It: 39700, Loss: 1.343e-04\n",
      "It: 39800, Loss: 1.365e-04\n",
      "It: 39900, Loss: 9.787e-03\n",
      "It: 40000, Loss: 3.703e-03\n",
      "It: 40100, Loss: 4.650e-04\n",
      "It: 40200, Loss: 1.300e-04\n",
      "It: 40300, Loss: 1.631e-04\n",
      "It: 40400, Loss: 1.432e-04\n",
      "It: 40500, Loss: 1.363e-02\n",
      "It: 40600, Loss: 8.338e-04\n",
      "It: 40700, Loss: 1.312e-04\n",
      "It: 40800, Loss: 9.151e-04\n",
      "It: 40900, Loss: 1.889e-04\n",
      "It: 41000, Loss: 1.203e-02\n",
      "It: 41100, Loss: 1.557e-04\n",
      "It: 41200, Loss: 2.120e-03\n",
      "It: 41300, Loss: 2.201e-04\n",
      "It: 41400, Loss: 8.498e-04\n",
      "It: 41500, Loss: 2.003e-04\n",
      "It: 41600, Loss: 1.296e-04\n",
      "It: 41700, Loss: 3.519e-04\n",
      "It: 41800, Loss: 7.869e-04\n",
      "It: 41900, Loss: 1.836e-04\n",
      "It: 42000, Loss: 1.454e-04\n",
      "It: 42100, Loss: 1.408e-04\n",
      "It: 42200, Loss: 1.517e-04\n",
      "It: 42300, Loss: 1.327e-04\n",
      "It: 42400, Loss: 4.414e-03\n",
      "It: 42500, Loss: 1.575e-04\n",
      "It: 42600, Loss: 2.092e-03\n",
      "It: 42700, Loss: 3.091e-04\n",
      "It: 42800, Loss: 1.599e-03\n",
      "It: 42900, Loss: 8.073e-03\n",
      "It: 43000, Loss: 2.166e-04\n",
      "It: 43100, Loss: 3.351e-03\n",
      "It: 43200, Loss: 1.364e-03\n",
      "It: 43300, Loss: 1.122e-04\n",
      "It: 43400, Loss: 2.730e-04\n",
      "It: 43500, Loss: 1.924e-03\n",
      "It: 43600, Loss: 4.284e-03\n",
      "It: 43700, Loss: 2.906e-03\n",
      "It: 43800, Loss: 1.142e-03\n",
      "It: 43900, Loss: 2.186e-04\n",
      "It: 44000, Loss: 1.726e-03\n",
      "It: 44100, Loss: 6.382e-04\n",
      "It: 44200, Loss: 1.190e-04\n",
      "It: 44300, Loss: 1.276e-03\n",
      "It: 44400, Loss: 2.388e-03\n",
      "It: 44500, Loss: 2.282e-04\n",
      "It: 44600, Loss: 3.061e-04\n",
      "It: 44700, Loss: 9.900e-04\n",
      "It: 44800, Loss: 5.358e-03\n",
      "It: 44900, Loss: 1.966e-04\n",
      "It: 45000, Loss: 1.108e-04\n",
      "It: 45100, Loss: 1.152e-04\n",
      "It: 45200, Loss: 3.106e-04\n",
      "It: 45300, Loss: 2.169e-03\n",
      "It: 45400, Loss: 1.290e-04\n",
      "It: 45500, Loss: 2.724e-03\n",
      "It: 45600, Loss: 4.143e-04\n",
      "It: 45700, Loss: 9.037e-04\n",
      "It: 45800, Loss: 1.326e-04\n",
      "It: 45900, Loss: 8.350e-04\n",
      "It: 46000, Loss: 5.678e-04\n",
      "It: 46100, Loss: 2.327e-04\n",
      "It: 46200, Loss: 1.750e-03\n",
      "It: 46300, Loss: 1.295e-04\n",
      "It: 46400, Loss: 9.667e-04\n",
      "It: 46500, Loss: 2.148e-03\n",
      "It: 46600, Loss: 5.196e-04\n",
      "It: 46700, Loss: 1.790e-04\n",
      "It: 46800, Loss: 3.303e-03\n",
      "It: 46900, Loss: 3.607e-04\n",
      "It: 47000, Loss: 2.267e-04\n",
      "It: 47100, Loss: 1.139e-04\n",
      "It: 47200, Loss: 1.368e-03\n",
      "It: 47300, Loss: 2.312e-04\n",
      "It: 47400, Loss: 1.178e-04\n",
      "It: 47500, Loss: 2.825e-04\n",
      "It: 47600, Loss: 2.999e-03\n",
      "It: 47700, Loss: 1.610e-03\n",
      "It: 47800, Loss: 3.803e-04\n",
      "It: 47900, Loss: 1.131e-03\n",
      "It: 48000, Loss: 1.517e-04\n",
      "It: 48100, Loss: 1.005e-03\n",
      "It: 48200, Loss: 1.276e-04\n",
      "It: 48300, Loss: 1.265e-03\n",
      "It: 48400, Loss: 1.751e-04\n",
      "It: 48500, Loss: 1.431e-04\n",
      "It: 48600, Loss: 3.532e-04\n",
      "It: 48700, Loss: 1.070e-04\n",
      "It: 48800, Loss: 9.494e-05\n",
      "It: 48900, Loss: 5.396e-04\n",
      "It: 49000, Loss: 4.143e-04\n",
      "It: 49100, Loss: 2.555e-03\n",
      "It: 49200, Loss: 2.031e-04\n",
      "It: 49300, Loss: 1.211e-03\n",
      "It: 49400, Loss: 1.450e-04\n",
      "It: 49500, Loss: 1.080e-04\n",
      "It: 49600, Loss: 5.429e-04\n",
      "It: 49700, Loss: 5.515e-04\n",
      "It: 49800, Loss: 4.127e-04\n",
      "It: 49900, Loss: 1.413e-04\n",
      "Iter 100, Loss: 6.964611e-05\n",
      "Iter 200, Loss: 5.856062e-05\n",
      "Iter 300, Loss: 5.081085e-05\n",
      "Iter 400, Loss: 4.402758e-05\n",
      "Iter 500, Loss: 3.783892e-05\n",
      "Iter 600, Loss: 3.374451e-05\n",
      "Iter 700, Loss: 3.005248e-05\n",
      "Iter 800, Loss: 2.689813e-05\n",
      "Iter 900, Loss: 2.434574e-05\n",
      "Iter 1000, Loss: 2.180672e-05\n",
      "Iter 1100, Loss: 1.986719e-05\n",
      "Iter 1200, Loss: 1.811013e-05\n",
      "Iter 1300, Loss: 1.661535e-05\n",
      "Iter 1400, Loss: 1.538952e-05\n",
      "Iter 1500, Loss: 1.422038e-05\n",
      "Iter 1600, Loss: 1.320531e-05\n",
      "Iter 1700, Loss: 1.226607e-05\n",
      "Iter 1800, Loss: 1.156682e-05\n",
      "Iter 1900, Loss: 1.097616e-05\n",
      "Iter 2000, Loss: 1.038254e-05\n",
      "Iter 2100, Loss: 9.857762e-06\n",
      "Iter 2200, Loss: 9.431122e-06\n",
      "Iter 2300, Loss: 8.980701e-06\n",
      "Iter 2400, Loss: 8.569648e-06\n",
      "Iter 2500, Loss: 8.186846e-06\n",
      "Iter 2600, Loss: 7.794853e-06\n",
      "Iter 2700, Loss: 7.403976e-06\n",
      "Iter 2800, Loss: 7.073485e-06\n",
      "Iter 2900, Loss: 6.773107e-06\n",
      "Iter 3000, Loss: 6.505769e-06\n",
      "Iter 3100, Loss: 6.268289e-06\n",
      "Iter 3200, Loss: 6.035697e-06\n",
      "Iter 3300, Loss: 5.822883e-06\n",
      "Iter 3400, Loss: 5.623263e-06\n",
      "Iter 3500, Loss: 5.422309e-06\n",
      "Iter 3600, Loss: 5.260453e-06\n",
      "Iter 3700, Loss: 5.107698e-06\n",
      "Iter 3800, Loss: 4.947488e-06\n",
      "Iter 3900, Loss: 4.842641e-06\n",
      "Iter 4000, Loss: 4.722942e-06\n",
      "Iter 4100, Loss: 4.591784e-06\n",
      "Iter 4200, Loss: 4.476363e-06\n",
      "Iter 4300, Loss: 4.381360e-06\n",
      "Iter 4400, Loss: 4.281605e-06\n",
      "Iter 4500, Loss: 4.191515e-06\n",
      "Iter 4600, Loss: 4.108250e-06\n",
      "Iter 4700, Loss: 4.042601e-06\n",
      "Iter 4800, Loss: 3.977561e-06\n",
      "Iter 4900, Loss: 3.913465e-06\n",
      "Iter 5000, Loss: 3.855727e-06\n",
      "Iter 5100, Loss: 3.812002e-06\n",
      "Iter 5200, Loss: 3.766753e-06\n",
      "Iter 5300, Loss: 3.720369e-06\n",
      "Iter 5400, Loss: 3.678336e-06\n",
      "Iter 5500, Loss: 3.636421e-06\n",
      "Training time: 707.7611\n",
      "Error u: 7.054615e-03\n",
      "Error v: 1.565766e-02\n",
      "Error h: 5.492619e-03\n"
     ]
    }
   ],
   "source": [
    "#设置噪声值为0 \n",
    "noise = 0.0   \n",
    "\n",
    "Adam_iter = 50000 #Adam优化器的迭代次数\n",
    "\n",
    "\n",
    "# Doman bounds，定义两个一维数组lb和ub，问题域是一个二维空间，其中 x 的范围是 -5 到 5，t 的范围是 0 到 π/2(竖着的)\n",
    "lb = np.array([-5.0, 0.0])\n",
    "ub = np.array([5.0, np.pi/2])\n",
    "#定义三个整数，分别表示初始条件点数量、边界条件点数量和在问题域内部的点的数量（这些点用于训练神经网络）\n",
    "N0 = 50\n",
    "N_b = 50\n",
    "N_f = 20000\n",
    "#定义一个列表layers，其中包含了神经网络的层数和每一层的神经元数量\n",
    "layers = [2, 100, 100, 100, 100, 2]\n",
    "#读取名为NLS.mat的Matlab文件，文件中的数据存储在data变量中。这里的路径也要随着设备的情况修改    \n",
    "data = scipy.io.loadmat('../Data/NLS.mat')\n",
    "#从data字典中取出变量tt和x的值，并转换为一维数组（flatten方法），最后tongg[:,None]将一维数组转换为二维数组\n",
    "t = data['tt'].flatten()[:,None]\n",
    "x = data['x'].flatten()[:,None]\n",
    "Exact = data['uu'] #从data字典中取出变量uu的值，并赋值给Exact\n",
    "Exact_u = np.real(Exact)  #取Exact的实部，赋值给Exact_u\n",
    "Exact_v = np.imag(Exact)  #取Exact的虚部，赋值给Exact_v\n",
    "Exact_h = np.sqrt(Exact_u**2 + Exact_v**2) #计算复数uu的|uu|\n",
    "#生成一个二位网络，X和T是输出的二维数组\n",
    "X, T = np.meshgrid(x,t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))  #X_star是一个二维数组，其中第一列是X的展平，第二列是T的展平\n",
    "u_star = Exact_u.T.flatten()[:,None] #先对Exact_u进行转置，然后使用flatten方法将其转换为一维数组，最后使用[:,None]将其转换为二维数组\n",
    "v_star = Exact_v.T.flatten()[:,None] #同上，比如Exact_v是m*n二维数组，Exact_v.T是n*m二维数组，Exact_v.T.flatten()是一个长度为n*m的一维数组，Exact_v.T.flatten()[:,None]是一个(n*m)*1的三维数组\n",
    "h_star = Exact_h.T.flatten()[:,None]\n",
    "#上面五行代码的意义见Numpy库的索引的介绍\n",
    "\n",
    "\n",
    "###########################\n",
    "\n",
    "#从0~数组x的行数(256)中随机选择N0个数，replace=False表示不允许重复选择，最后将这N0个数赋值给idx_x\n",
    "idx_x = np.random.choice(x.shape[0], N0, replace=False)\n",
    "#从x中选择N0个对应的行(idx_x对应的行)，最后将这N0行赋值给x0\n",
    "x0 = x[idx_x,:]\n",
    "#从Exact_u中选择N0个对应的行(idx_x对应的行)的第一列元素，最后将这N0个元素赋值给u0\n",
    "u0 = Exact_u[idx_x,0:1]\n",
    "v0 = Exact_v[idx_x,0:1]\n",
    "#从0~数组t的行数中随机选择N_b个数，replace=False表示不允许重复选择，最后将这N_b个数赋值给idx_t\n",
    "idx_t = np.random.choice(t.shape[0], N_b, replace=False)\n",
    "#从t中选择N_b个对应的行(idx_t对应的行)，最后将这N_b行赋值给tb\n",
    "tb = t[idx_t,:]\n",
    "\n",
    "X_f = lb + (ub-lb)*lhs(2, N_f) #lhs函数采用拉丁超采样方法，生成一个近似均匀分布的多维样本点集，返回的是一个形状为（$N_f$，2）的数组，每一行都是一个2维的样本点，所有样本点都在[0,1]范围内，并对该样本集进行缩放，把每个样本从[0,1]区间缩放到[lb,ub]区域内，即得到了指定范围内均匀分布的样本$X_f$。\n",
    "\n",
    "#创建PINN模型并输入各种参数        \n",
    "model = PhysicsInformedNN(x0, u0, v0, tb, X_f, layers, lb, ub)\n",
    "#获取当前时间并赋值给start_time          \n",
    "start_time = time.time()       \n",
    "#训练模型50000次         \n",
    "model.train(Adam_iter)\n",
    "#获取当前时间并减去start_time，得到训练时间并赋值给elapsed\n",
    "elapsed = time.time() - start_time                \n",
    "#打印训练所需时间\n",
    "print('Training time: %.4f' % (elapsed))\n",
    "\n",
    "#用训练好的模型进行预测，返回四个值（均为数组）    \n",
    "u_pred, v_pred, f_u_pred, f_v_pred = model.predict(X_star)\n",
    "#计算u_pred和v_pred的模（平方和的平方根），赋值给h_pred\n",
    "h_pred = np.sqrt(u_pred**2 + v_pred**2)\n",
    "#计算误差（基于2范数）        \n",
    "error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
    "error_v = np.linalg.norm(v_star-v_pred,2)/np.linalg.norm(v_star,2)\n",
    "error_h = np.linalg.norm(h_star-h_pred,2)/np.linalg.norm(h_star,2)\n",
    "#打印误差\n",
    "print('Error u: %e' % (error_u))\n",
    "print('Error v: %e' % (error_v))\n",
    "print('Error h: %e' % (error_h))\n",
    "\n",
    "#使用griddata函数将X_star、u_pred、v_pred和h_pred插值到网格上，得到U_pred、V_pred和H_pred\n",
    "U_pred = griddata(X_star, u_pred.flatten(), (X, T), method='cubic')\n",
    "V_pred = griddata(X_star, v_pred.flatten(), (X, T), method='cubic')\n",
    "H_pred = griddata(X_star, h_pred.flatten(), (X, T), method='cubic')\n",
    "#同上，使用griddata函数将X_star、f_u_pred和f_v_pred插值到网格上，得到FU_pred和FV_pred\n",
    "FU_pred = griddata(X_star, f_u_pred.flatten(), (X, T), method='cubic')\n",
    "FV_pred = griddata(X_star, f_v_pred.flatten(), (X, T), method='cubic')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 539.643x333.518 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#打印误差随迭代次数的变化\n",
    "trainloss = torch.stack(model.loss_value).cpu().detach().numpy()\n",
    "# print(trainloss)\n",
    "# print(trainloss.shape)\n",
    "indices=list(range(len(trainloss)))\n",
    "plt.figure()\n",
    "plt.plot(indices[:Adam_iter],trainloss[:Adam_iter],color='red')\n",
    "plt.plot(indices[Adam_iter:],trainloss[Adam_iter:],color='blue')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "# plt.yscale('log') #设置y轴为对数尺度，这样即使列表中有一些非常大的值，也不会影响其他值的可视化\n",
    "plt.xlim([0,max(indices)]) # 设置x轴的范围\n",
    "plt.ylim([0,0.2]) # 设置y轴的范围\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lcy\\AppData\\Local\\Temp\\ipykernel_116408\\115286073.py:17: MatplotlibDeprecationWarning: Auto-removal of overlapping axes is deprecated since 3.6 and will be removed two minor releases later; explicitly call ax.remove() as needed.\n",
      "  ax = plt.subplot(gs0[:,:]) #在gs0[:,:] 指定的位置创建了一个子图，并将返回的axes对象赋值给ax。gs0[:,:]表示GridSpec对象gs0的所有行和所有列，所以这行代码创建的子图占据了整个图形。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '$t = 0.98$')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 539.643x300.166 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######################################################################\n",
    "############################# Plotting ###############################\n",
    "######################################################################    \n",
    "#调用concatenate函数拼接数组\n",
    "X0 = np.concatenate((x0, 0*x0), 1) # (x0, 0)\n",
    "X_lb = np.concatenate((0*tb + lb[0], tb), 1) # (lb[0], tb)\n",
    "X_ub = np.concatenate((0*tb + ub[0], tb), 1) # (ub[0], tb)\n",
    "X_u_train = np.vstack([X0, X_lb, X_ub])  #(X0;X_lb;X_ub)\n",
    "#调用plotting文件中的newfig函数，生成一个宽1英寸、高0.9英寸的图像fig和子图ax\n",
    "fig, ax = newfig(1.0, 0.9) #这里ax是一个axes对象，代表子图，figure是一个figure对象，是一个图形窗口，代表整个图形\n",
    "ax.axis('off') #关闭子图的轴的显示\n",
    "\n",
    "####### Row 0: h(t,x)，绘制第一个子图，展示x,t和|h(t,x)|的关系##################    \n",
    "#创建一个包含子图的网格，1行2列\n",
    "gs0 = gridspec.GridSpec(1,2)  #创建一个1×2的网络，用于存放子图\n",
    "gs0.update(top=1-0.06, bottom=1-1/3, left=0.15, right=0.85, wspace=0) #更新该网络的参数，第一个表示子图的顶部位置为0.94，第二个参数表示子图的底部位置为0.667，第三个表示子图左侧的位置为0.15，第四个参数表示子图的右侧位置为0.85，第五个参数表示子图之间的宽度，0表示子图之间没有空隙\n",
    "ax = plt.subplot(gs0[:,:]) #在gs0[:,:] 指定的位置创建了一个子图，并将返回的axes对象赋值给ax。gs0[:,:]表示GridSpec对象gs0的所有行和所有列，所以这行代码创建的子图占据了整个图形。\n",
    "\n",
    "#绘制热图\n",
    "h = ax.imshow(H_pred.T, interpolation='nearest', cmap='YlGnBu', \n",
    "                extent=[lb[1], ub[1], lb[0], ub[0]], \n",
    "                origin='lower', aspect='auto')  #imshow函数用于显示图像，接受一些参数，第一个参数是图像数据，这里是H_pred的转置；第二个参数是插值方法（用于在像素之间插入新的像素），这里是最邻近插值；\n",
    "                                                #第三个参数是颜色映射，这里是从黄色Yl到绿色Gn再到蓝色Bu；第四个参数是图像的范围，这里lb和ub分别是数据的下界和上界；第五个参数是图像的原点位置，这里表示原点在右下角；第六个参数是图像的纵横比，这里表示调整横纵比以填充整个axes对象\n",
    "                                                #最后的结果返回一个axesimage对象，也就是h，可以通过这个对象进一步设置图像的属性\n",
    "divider = make_axes_locatable(ax)  #使用 make_axes_locatable 函数创建了一个 AxesDivider 对象。这个函数接受一个 Axes 对象作为参数，返回一个 AxesDivider 对象。AxesDivider 对象可以用来管理子图的布局，特别是当你需要在一个图的旁边添加另一个图时。\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05) #使用append_axes方法在原始轴的右侧添加了一个新的轴。append_axes 方法接受三个参数：位置（\"right\"）、大小（\"5%\"）和间距（0.05）。在原始轴的右侧添加了一个新的轴，新轴的大小是原始轴的 5%，新轴与原始轴之间的间距是 0.05 英寸\n",
    "fig.colorbar(h, cax=cax) #使用colorbar方法在新轴上添加了一个颜色条。colorbar 方法接受两个参数：axesimage 对象（h）和新轴（cax）。\n",
    "\n",
    "#绘制散点图\n",
    "ax.plot(X_u_train[:,1], X_u_train[:,0], 'kx', label = 'Data (%d points)' % (X_u_train.shape[0]), markersize = 4, clip_on = False) #在ax上绘制散点图，前两个参数是散点的x坐标和y坐标；kx表示黑色的x（散点形状是x），label是散点的标签，clip_on表示散点可以绘制在轴的边界外\n",
    "\n",
    "\n",
    "#绘制三条虚线\n",
    "line = np.linspace(x.min(), x.max(), 2)[:,None] #生成了一个包含2个等间距的数值的数组，这些数值在 x.min() 到 x.max() 之间。[:,None] 是一个索引操作，用于将一维数组转换为二维数组。这里其实就是[-5;5]\n",
    "#第一个参数是虚线的x坐标，line是虚线y的坐标，第三个参数是虚线的样式，k表示黑色，--表示虚线，最后一个参数表示虚线的参数是1\n",
    "ax.plot(t[75]*np.ones((2,1)),line,'k--',linewidth=1) \n",
    "ax.plot(t[100]*np.ones((2,1)),line,'k--',linewidth=1)\n",
    "ax.plot(t[125]*np.ones((2,1)),line,'k--',linewidth=1)    \n",
    "\n",
    "#设置标签\n",
    "#设置ax子图的x轴的标签为t，y轴的标签为x。这里$t$和$x$是latex格式的文本，用于生成数学公式\n",
    "ax.set_xlabel('$t$')\n",
    "ax.set_ylabel('$x$')\n",
    "#设置子图ax的图例，frameon=False表示不显示图例的边框，loc='best'表示图例的位置是最佳位置，最后返回的leg是一个legend对象，表示图形的图例\n",
    "leg = ax.legend(frameon=False, loc = 'best')\n",
    "#    plt.setp(leg.get_texts(), color='w')   #用来设置图例中文本的颜色，这里是白色，取消注释后文本会变为白色\n",
    "ax.set_title('$|h(t,x)|$', fontsize = 10) #设置子图ax的标题为$|h(t,x)|$，表示latex格式的文本，用于生成数学公式，fontsize=10表示字体大小为10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####### Row 1: h(t,x) slices ##################    \n",
    "gs1 = gridspec.GridSpec(1,3) #创建一个1×3的网络，用于存放子图\n",
    "gs1.update(top=1-1/3, bottom=0, left=0.1, right=0.9, wspace=0.5) #更新该网络的参数，第一个表示子图的顶部位置为0.667，第二个参数表示子图的底部位置为0，第三个表示子图左侧的位置为0，第四个参数表示子图的右侧位置为0.9，第五个参数表示子图之间的宽度为0.5\n",
    "\n",
    "ax = plt.subplot(gs1[0,0])  #在gs1[0,0]指定的位置，也就是网格的第一行第一列，创建了一个子图，并将返回的axes对象赋值给ax。\n",
    "#绘制了两条线，一条表示精确值，一条表示预测值\n",
    "ax.plot(x,Exact_h[:,75], 'b-', linewidth = 2, label = 'Exact')      #第一个参数表示x轴上的坐标；第二个参数表示y轴上的坐标；第三个参数b-表示蓝色的实线；linewidth表示线的宽度为2；label表示线的标签\n",
    "ax.plot(x,H_pred[75,:], 'r--', linewidth = 2, label = 'Prediction') #同上\n",
    "#设置ax子图的x轴的标签为x，y轴的标签为|h(t,x)|。这里$x$和$|h(t,x)|$是latex格式的文本，用于生成数学公式\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$|h(t,x)|$')    \n",
    "#设置子图的标题，几个子图标题随着t的变化而变化，字体大小为10 \n",
    "ax.set_title('$t=%.2f$' % (t[75]), fontsize = 10)\n",
    "ax.axis('square') #设置子图的纵横比，使得x轴和y轴的单位长度相等，形成一个正方形的区域\n",
    "ax.set_xlim([-5.1,5.1]) #第一个子图的x轴范围是-5.1到5.1\n",
    "ax.set_ylim([-0.1,5.1]) #第一个子图的y轴范围是-0.1到5.1\n",
    "\n",
    "ax = plt.subplot(gs1[0, 1]) #在gs1[0,1]指定的位置，也就是网格的第一行第二列，创建了一个子图，并将返回的axes对象赋值给ax。\n",
    "#绘制了两条线，一条表示精确值，一条表示预测值\n",
    "ax.plot(x,Exact_h[:,100],'b-', linewidth = 2, label = 'Exact')        #第一个参数表示x轴上的坐标；第二个参数表示y轴上的坐标；第三个参数b-表示蓝色的实线；linewidth表示线的宽度为2；label表示线的标签\n",
    "ax.plot(x,H_pred[100,:],'r--', linewidth = 2, label = 'Prediction')   #同上\n",
    "ax.set_xlabel('$x$') #设置子图的x轴的标签为x\n",
    "ax.set_ylabel('$|h(t,x)|$') #设置子图的y轴的标签为|h(t,x)|\n",
    "ax.axis('square')   #设置子图的纵横比，使得x轴和y轴的单位长度相等，形成一个正方形的区域\n",
    "ax.set_xlim([-5.1,5.1])     #第二个子图的x轴范围是-5.1到5.1\n",
    "ax.set_ylim([-0.1,5.1])     #第二个子图的y轴范围是-0.1到5.1\n",
    "ax.set_title('$t = %.2f$' % (t[100]), fontsize = 10)        #设置第二个子图的标题，标题随着t的变化而变化，字体大小为10\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.8), ncol=5, frameon=False)  #设置第二个子图的图例，loc='upper center'表示图例的位置是上方中心，bbox_to_anchor=(0.5,-0.8)表示图例的中心位置是在子图的中间偏下方0.8的位置，ncol=5表示图例的列数是5，frameon=False表示不显示图例的边框\n",
    "\n",
    "ax = plt.subplot(gs1[0, 2]) #在gs1[0,2]指定的位置，也就是网格的第一行第三列，创建了一个子图，并将返回的axes对象赋值给ax。\n",
    "ax.plot(x,Exact_h[:,125], 'b-', linewidth = 2, label = 'Exact')        #第一个参数表示x轴上的坐标；第二个参数表示y轴上的坐标；第三个参数b-表示蓝色的实线；linewidth表示线的宽度为2；label表示线的标签\n",
    "ax.plot(x,H_pred[125,:], 'r--', linewidth = 2, label = 'Prediction')    #同上\n",
    "ax.set_xlabel('$x$') #设置子图的x轴的标签为x\n",
    "ax.set_ylabel('$|h(t,x)|$') #设置子图的y轴的标签为|h(t,x)|\n",
    "ax.axis('square')    #设置子图的纵横比，使得x轴和y轴的单位长度相等，形成一个正方形的区域\n",
    "ax.set_xlim([-5.1,5.1])    #第三个子图的x轴范围是-5.1到5.1\n",
    "ax.set_ylim([-0.1,5.1])    #第三个子图的y轴范围是-0.1到5.1\n",
    "ax.set_title('$t = %.2f$' % (t[125]), fontsize = 10)    #设置第三个子图的标题，标题随着t的变化而变化，字体大小为10\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
